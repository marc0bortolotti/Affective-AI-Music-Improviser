{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code start from the raw recordings and separate data into the classes of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.loader import load_data, unicorn_fs\n",
    "\n",
    "unicorn_channels = [\"Fz\", \"C3\", \"Cz\", \"C4\", \"Pz\", \"PO7\", \"Oz\", \"PO8\", \"acc_x\", \"acc_y\", \"acc_z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. RECORDING 28_03_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recording is 6 minutes and 44 seconds long\n"
     ]
    }
   ],
   "source": [
    "path_recording = 'data/recordings/recordings_28_03_2024'\n",
    "path_dataset = 'data/dataset'\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "recording_type = 'listening'\n",
    "music_type = 'relax'\n",
    "\n",
    "'''\n",
    "RECORDING INFO:\n",
    "1 minute silence\n",
    "1 minute listening song_1\n",
    "30 seconds silence\n",
    "1 minute listening song_2\n",
    "30 seconds silence\n",
    "1 minute listening song_3\n",
    "30 seconds silence\n",
    "1 minute listening song_4\n",
    "TOT: 6 minutes and 30 seconds\n",
    "'''\n",
    "\n",
    "# Path\n",
    "path_data = os.path.join(path_recording, recording_type, music_type)\n",
    "files = [f for f in os.listdir(path_data) if f.endswith('.csv')]\n",
    "path_file = os.path.join(path_data, files[0])\n",
    "\n",
    "# Load data\n",
    "eeg, trigger, dataframe = load_data(path_file, header=False, fs=unicorn_fs, skiprows=0, names = unicorn_channels)\n",
    "\n",
    "# Duration in minutes and seconds of the recording\n",
    "duration = eeg.shape[0] / unicorn_fs\n",
    "minutes = int(duration / 60)\n",
    "seconds = int(duration % 60)\n",
    "print(f'The recording is {minutes} minutes and {seconds} seconds long')\n",
    "\n",
    "# 1 minute silence \n",
    "silence1 = eeg[unicorn_fs*5:unicorn_fs*60, :]\n",
    "# 1 minute listening song_1\n",
    "song1 = eeg[unicorn_fs*60:unicorn_fs*120, :]\n",
    "# 30 seconds silence\n",
    "silence2 = eeg[unicorn_fs*120:unicorn_fs*150, :]\n",
    "# 1 minute listening song_2\n",
    "song2 = eeg[unicorn_fs*150:unicorn_fs*210, :]\n",
    "# 30 seconds silence\n",
    "silence3 = eeg[unicorn_fs*210:unicorn_fs*240, :]\n",
    "# 1 minute listening song_3\n",
    "song3 = eeg[unicorn_fs*240:unicorn_fs*300, :]\n",
    "# 30 seconds silence\n",
    "silence4 = eeg[unicorn_fs*300:unicorn_fs*330, :]\n",
    "# 1 minute listening song_4\n",
    "song4 = eeg[unicorn_fs*330:unicorn_fs*390, :]\n",
    "\n",
    "\n",
    "# concatenate silences and songs\n",
    "silence = np.concatenate((silence1, silence2, silence3, silence4), axis=0)\n",
    "songs = np.concatenate((song1, song2, song3, song4), axis=0)\n",
    "\n",
    "# convert to dataframes \n",
    "silence_df = pd.DataFrame(silence)\n",
    "songs_df = pd.DataFrame(songs)\n",
    "\n",
    "# save dataframes\n",
    "baseline_file_name = 'baseline_' + recording_type + '_' + music_type + '.csv'\n",
    "signal_file_name = 'song_' + recording_type + '_' + music_type + '.csv'\n",
    "\n",
    "path_baseline = os.path.join(path_dataset, recording_type, 'baseline', baseline_file_name)\n",
    "path_signal = os.path.join(path_dataset, recording_type, music_type, signal_file_name)\n",
    "\n",
    "silence_df.to_csv(path_baseline, index=False, header=False)\n",
    "songs_df.to_csv(path_signal, index=False, header=False)\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "recording_type = 'listening'\n",
    "music_type = 'excited'\n",
    "\n",
    "'''\n",
    "RECORDING INFO:\n",
    "1 minute listening song_1\n",
    "30 seconds silence\n",
    "1 minute listening song_2\n",
    "30 seconds silence\n",
    "1 minute listening song_3\n",
    "30 seconds silence\n",
    "1 minute listening song_4\n",
    "'''\n",
    "\n",
    "# Path\n",
    "path_data = os.path.join(path_recording, recording_type, music_type)\n",
    "files = [f for f in os.listdir(path_data) if f.endswith('.csv')]\n",
    "path_file = os.path.join(path_data, files[0])\n",
    "\n",
    "# Load data\n",
    "eeg, trigger, dataframe = load_data(path_file, header=False, fs=unicorn_fs, skiprows=0, names = unicorn_channels)\n",
    "\n",
    "# Duration in minutes and seconds of the recording\n",
    "duration = eeg.shape[0] / unicorn_fs\n",
    "minutes = int(duration / 60)\n",
    "seconds = int(duration % 60)\n",
    "print(f'The recording is {minutes} minutes and {seconds} seconds long')\n",
    "\n",
    "# 1 minute listening song_1\n",
    "song1 = eeg[unicorn_fs*5:unicorn_fs*60, :]\n",
    "# 30 seconds silence\n",
    "silence2 = eeg[unicorn_fs*60:unicorn_fs*90, :]\n",
    "# 1 minute listening song_2\n",
    "song2 = eeg[unicorn_fs*90:unicorn_fs*150, :]\n",
    "# 30 seconds silence\n",
    "silence3 = eeg[unicorn_fs*150:unicorn_fs*180, :]\n",
    "# 1 minute listening song_3\n",
    "song3 = eeg[unicorn_fs*180:unicorn_fs*240, :]\n",
    "# 30 seconds silence\n",
    "silence4 = eeg[unicorn_fs*240:unicorn_fs*270, :]\n",
    "# 1 minute listening song_4\n",
    "song4 = eeg[unicorn_fs*270:unicorn_fs*330, :]\n",
    "\n",
    "# concatenate silences and songs\n",
    "silence = np.concatenate((silence2, silence3, silence4), axis=0)\n",
    "songs = np.concatenate((song1, song2, song3, song4), axis=0)\n",
    "\n",
    "# convert to dataframes\n",
    "silence_df = pd.DataFrame(silence)\n",
    "songs_df = pd.DataFrame(songs)\n",
    "\n",
    "# save dataframes\n",
    "baseline_file_name = 'baseline_' + recording_type + '_' + music_type + '.csv'\n",
    "signal_file_name = 'song_' + recording_type + '_' + music_type + '.csv'\n",
    "\n",
    "path_baseline = os.path.join(path_dataset, recording_type, 'baseline', baseline_file_name)\n",
    "path_signal = os.path.join(path_dataset, recording_type, music_type, signal_file_name)\n",
    "\n",
    "\n",
    "silence_df.to_csv(path_baseline, index=False, header=False)\n",
    "songs_df.to_csv(path_signal, index=False, header=False)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "recording_type = 'playing_listening' \n",
    "music_type = 'relax'\n",
    "\n",
    "'''\n",
    "RECORDING INFO:\n",
    "30 seconds silence\n",
    "1 minute listening song_1\n",
    "30 seconds silence\n",
    "1 minute listening song_2\n",
    "30 seconds silence\n",
    "1 minute listening song_3\n",
    "30 seconds silence\n",
    "1 minute listening song_4\n",
    "'''\n",
    "\n",
    "# Path\n",
    "path_data = os.path.join(path_recording, recording_type, music_type)\n",
    "files = [f for f in os.listdir(path_data) if f.endswith('.csv')]\n",
    "path_file = os.path.join(path_data, files[0])\n",
    "\n",
    "# Load data\n",
    "eeg, trigger, dataframe = load_data(path_file, header=False, fs=unicorn_fs, skiprows=0, names = unicorn_channels)\n",
    "\n",
    "# Duration in minutes and seconds of the recording\n",
    "duration = eeg.shape[0] / unicorn_fs\n",
    "minutes = int(duration / 60)\n",
    "seconds = int(duration % 60)\n",
    "print(f'The recording is {minutes} minutes and {seconds} seconds long')\n",
    "\n",
    "# 30 seconds silence\n",
    "silence1 = eeg[unicorn_fs*5:unicorn_fs*30, :]\n",
    "# 1 minute listening song_1\n",
    "song1 = eeg[unicorn_fs*30:unicorn_fs*90, :]\n",
    "# 30 seconds silence\n",
    "silence2 = eeg[unicorn_fs*90:unicorn_fs*120, :]\n",
    "# 1 minute listening song_2\n",
    "song2 = eeg[unicorn_fs*120:unicorn_fs*180, :]\n",
    "# 30 seconds silence\n",
    "silence3 = eeg[unicorn_fs*180:unicorn_fs*210, :]\n",
    "# 1 minute listening song_3\n",
    "song3 = eeg[unicorn_fs*210:unicorn_fs*270, :]\n",
    "# 30 seconds silence\n",
    "silence4 = eeg[unicorn_fs*270:unicorn_fs*300, :]\n",
    "# 1 minute listening song_4\n",
    "song4 = eeg[unicorn_fs*300:unicorn_fs*360, :]\n",
    "\n",
    "# convert to dataframes\n",
    "silence1 = pd.DataFrame(silence1)\n",
    "song1 = pd.DataFrame(song1)\n",
    "silence2 = pd.DataFrame(silence2)\n",
    "song2 = pd.DataFrame(song2)\n",
    "silence3 = pd.DataFrame(silence3)\n",
    "song3 = pd.DataFrame(song3)\n",
    "silence4 = pd.DataFrame(silence4)\n",
    "song4 = pd.DataFrame(song4)\n",
    "\n",
    "\n",
    "# save dataframes\n",
    "baseline_file_name = 'baseline_' + recording_type + '_' + music_type + '.csv'\n",
    "signal_file_name = 'song_' + recording_type + '_' + music_type + '.csv'\n",
    "\n",
    "path_baseline = os.path.join(path_dataset, recording_type, 'baseline', baseline_file_name)\n",
    "path_signal = os.path.join(path_dataset, recording_type, music_type, signal_file_name)\n",
    "\n",
    "silence_df.to_csv(path_baseline, index=False, header=False)\n",
    "songs_df.to_csv(path_signal, index=False, header=False)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "recording_type = 'playing_listening' \n",
    "music_type = 'excited'\n",
    "\n",
    "'''\n",
    "RECORDING INFO:\n",
    "30 seconds silence\n",
    "1 minute listening song_1\n",
    "30 seconds silence\n",
    "1 minute listening song_2\n",
    "30 seconds silence\n",
    "1 minute listening song_3\n",
    "30 seconds silence\n",
    "1 minute listening song_4\n",
    "'''\n",
    "\n",
    "# Path\n",
    "path_data = os.path.join(path_recording, recording_type, music_type)\n",
    "files = [f for f in os.listdir(path_data) if f.endswith('.csv')]\n",
    "path_file = os.path.join(path_data, files[0])\n",
    "\n",
    "# Load data\n",
    "eeg, trigger, dataframe = load_data(path_file, header=False, fs=unicorn_fs, skiprows=0, names = unicorn_channels)\n",
    "\n",
    "# Duration in minutes and seconds of the recording\n",
    "duration = eeg.shape[0] / unicorn_fs\n",
    "minutes = int(duration / 60)\n",
    "seconds = int(duration % 60)\n",
    "print(f'The recording is {minutes} minutes and {seconds} seconds long')\n",
    "\n",
    "# 30 seconds silence\n",
    "silence1 = eeg[unicorn_fs*5:unicorn_fs*30, :]\n",
    "# 1 minute listening song_1\n",
    "song1 = eeg[unicorn_fs*30:unicorn_fs*90, :]\n",
    "# 30 seconds silence\n",
    "silence2 = eeg[unicorn_fs*90:unicorn_fs*120, :]\n",
    "# 1 minute listening song_2\n",
    "song2 = eeg[unicorn_fs*120:unicorn_fs*180, :]\n",
    "# 30 seconds silence\n",
    "silence3 = eeg[unicorn_fs*180:unicorn_fs*210, :]\n",
    "# 1 minute listening song_3\n",
    "song3 = eeg[unicorn_fs*210:unicorn_fs*270, :]\n",
    "# 30 seconds silence\n",
    "silence4 = eeg[unicorn_fs*270:unicorn_fs*300, :]\n",
    "# 1 minute listening song_4\n",
    "song4 = eeg[unicorn_fs*300:unicorn_fs*360, :]\n",
    "\n",
    "# convert to dataframes\n",
    "silence1 = pd.DataFrame(silence1)\n",
    "song1 = pd.DataFrame(song1)\n",
    "silence2 = pd.DataFrame(silence2)\n",
    "song2 = pd.DataFrame(song2)\n",
    "silence3 = pd.DataFrame(silence3)\n",
    "song3 = pd.DataFrame(song3)\n",
    "silence4 = pd.DataFrame(silence4)\n",
    "song4 = pd.DataFrame(song4)\n",
    "\n",
    "\n",
    "# save dataframes\n",
    "baseline_file_name = 'baseline_' + recording_type + '_' + music_type + '.csv'\n",
    "signal_file_name = 'song_' + recording_type + '_' + music_type + '.csv'\n",
    "\n",
    "path_baseline = os.path.join(path_dataset, recording_type, 'baseline', baseline_file_name)\n",
    "path_signal = os.path.join(path_dataset, recording_type, music_type, signal_file_name)\n",
    "\n",
    "# create directories if they do not exist\n",
    "if not os.path.exists(os.path.join(path_dataset, recording_type, 'baseline')):\n",
    "    os.makedirs(os.path.join(path_dataset, recording_type, 'baseline'))\n",
    "if not os.path.exists(os.path.join(path_dataset, recording_type, music_type)):\n",
    "    os.makedirs(os.path.join(path_dataset, recording_type, music_type))\n",
    "\n",
    "\n",
    "silence_df.to_csv(path_baseline, index=False, header=False)\n",
    "songs_df.to_csv(path_signal, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. RECORDINGS 04_04_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_recording = 'data/recordings/recordings_04_04_2024_OSCAR'\n",
    "path_dataset = 'data/dataset/dataset_04_04_2024_OSCAR'\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "recording_type = ['listening', 'playing_listening']\n",
    "music_type = ['relax', 'excited']\n",
    "\n",
    "\n",
    "'''\n",
    "4 EEG and accellerometers recordings all the possible combinations of:\n",
    "\n",
    "- recording type: [listening, playing_listening]\n",
    "- song types (labels): [relax, excited]\n",
    "\n",
    "A recording is done as the following:\n",
    "\n",
    "1. 5 seconds to stabilize the signal \n",
    "2. 30 second baseline\n",
    "3. song 1\n",
    "4. 30 second baseline\n",
    "5. song 2\n",
    "6. 30 second baseline\n",
    "7. song 3\n",
    "8. 30 second baseline\n",
    "9. song 4\n",
    "\n",
    "total: 6 minutes and 5 seconds per recording\n",
    "\n",
    "'''\n",
    "\n",
    "for rec_type in recording_type:\n",
    "    for mus_type in music_type:\n",
    "        \n",
    "        # Path\n",
    "        path_data = os.path.join(path_recording, rec_type, mus_type)\n",
    "        files = [f for f in os.listdir(path_data) if f.endswith('.csv')]\n",
    "        path_file = os.path.join(path_data, files[0])\n",
    "\n",
    "        # Load data\n",
    "        skip_seconds = 5\n",
    "        eeg, trigger, dataframe = load_data(path_file, header=False, fs=unicorn_fs, skiprows=skip_seconds, names = unicorn_channels)\n",
    "\n",
    "        # Duration in minutes and seconds of the recording\n",
    "        duration = eeg.shape[0] / unicorn_fs\n",
    "        minutes = int(duration / 60)\n",
    "        seconds = int(duration % 60)\n",
    "        print(f'The recording is {minutes} minutes and {seconds} seconds long')\n",
    "\n",
    "        print(f'Processing file: {path_file}')\n",
    "\n",
    "        # 30 seconds silence\n",
    "        silence1 = eeg[:unicorn_fs*30, :]\n",
    "        # 1 minute listening song_1\n",
    "        song1 = eeg[unicorn_fs*30:unicorn_fs*90, :]\n",
    "        # 30 seconds silence\n",
    "        silence2 = eeg[unicorn_fs*90:unicorn_fs*120, :]\n",
    "        # 1 minute listening song_2\n",
    "        song2 = eeg[unicorn_fs*120:unicorn_fs*180, :]\n",
    "        # 30 seconds silence\n",
    "        silence3 = eeg[unicorn_fs*180:unicorn_fs*210, :]\n",
    "        # 1 minute listening song_3\n",
    "        song3 = eeg[unicorn_fs*210:unicorn_fs*270, :]\n",
    "        # 30 seconds silence\n",
    "        silence4 = eeg[unicorn_fs*270:unicorn_fs*300, :]\n",
    "        # 1 minute listening song_4\n",
    "        song4 = eeg[unicorn_fs*300:unicorn_fs*360, :]\n",
    "\n",
    "        # concatenate silences and songs\n",
    "        silence = np.concatenate((silence1, silence2, silence3, silence4), axis=0)\n",
    "        songs = np.concatenate((song1, song2, song3, song4), axis=0)\n",
    "\n",
    "        # convert to dataframes\n",
    "        silence_df = pd.DataFrame(silence)\n",
    "        songs_df = pd.DataFrame(songs)\n",
    "\n",
    "        # save dataframes\n",
    "        baseline_file_name = 'baseline_' + rec_type + '_' + mus_type + '.csv'\n",
    "        signal_file_name = 'song_' + rec_type + '_' + mus_type + '.csv'\n",
    "\n",
    "        path_baseline_folder = os.path.join(path_dataset, rec_type, 'baseline')\n",
    "        path_signal_folder = os.path.join(path_dataset, rec_type, mus_type)\n",
    "\n",
    "        if not os.path.exists(path_baseline_folder):\n",
    "            os.makedirs(path_baseline_folder)\n",
    "        if not os.path.exists(path_signal_folder):\n",
    "            os.makedirs(path_signal_folder)\n",
    "\n",
    "        path_baseline = os.path.join(path_baseline_folder, baseline_file_name)\n",
    "        path_signal = os.path.join(path_signal_folder, signal_file_name)\n",
    "\n",
    "        silence_df.to_csv(path_baseline, index=False, header=False)\n",
    "        songs_df.to_csv(path_signal, index=False, header=False)\n",
    "\n",
    "        print(f'Files saved in:\\t{path_baseline}\\n\\t\\t{path_signal}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
