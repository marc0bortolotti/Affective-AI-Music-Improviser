{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from pretty_midi_tokenization import notes_to_midi\n",
    "import os\n",
    "import pretty_midi\n",
    "import collections\n",
    "\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',504)\n",
    "pd.set_option('display.width',1000)\n",
    "\n",
    "\n",
    "DRUM_MIDI_DICT = {    \n",
    "    36: 'Kick',\n",
    "    38: 'Snare',\n",
    "    42: 'Closed Hi-Hat',\n",
    "    43: 'Floor Tom',\n",
    "    44: 'Pedal Hi-Hat',\n",
    "    46: 'Open Hi-Hat',\n",
    "    47: 'Tom 2',\n",
    "    48: 'Tom 1',\n",
    "    49: 'Crash',\n",
    "    51: 'Ride'}\n",
    "\n",
    "DIRECTORY_PATH = '..'\n",
    "DATASET_PATH = os.path.join(DIRECTORY_PATH, 'dataset')\n",
    "CHECKPOINTS_PATH = os.path.join(DIRECTORY_PATH, 'training_checkpoints')\n",
    "\n",
    "# Model parameters\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 50 \n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# MIDI parameters\n",
    "BPM = 120\n",
    "BEATS_PER_BAR = 4\n",
    "TICKS_PER_BEAT = 12\n",
    "BAR_DURATION = BEATS_PER_BAR * (60 / BPM)\n",
    "\n",
    "# Tokenization parameters\n",
    "BAR_LENGTH = BEATS_PER_BAR * TICKS_PER_BEAT\n",
    "SEQ_LENGTH = BAR_LENGTH * 4 # 4 bars\n",
    "VELOCITY_RANGES = {'p': (0, 64), 'f': (65, 127)}\n",
    "NOTE_START_TOKEN = 'S'\n",
    "SILENCE_TOKEN = 'O'\n",
    "BCI_TOKEN = 'BCI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_ticks(time: float):\n",
    "    pm = pretty_midi.PrettyMIDI(midi_file=None, resolution=TICKS_PER_BEAT, initial_tempo=BPM)\n",
    "    return pm.time_to_tick(time)\n",
    "\n",
    "def new_note(pitch, velocity, start, end, bar, convert_to_ticks = True):\n",
    "\n",
    "    # NB: start and end are relative to the bar they are in\n",
    "    if convert_to_ticks:\n",
    "        start = convert_time_to_ticks(start - bar*BAR_DURATION)\n",
    "        end = convert_time_to_ticks(end - bar*BAR_DURATION)\n",
    "\n",
    "    new_note = {\n",
    "        'pitch': pitch,\n",
    "        'velocity': velocity,\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "        'bar': bar\n",
    "    }\n",
    "    \n",
    "    return new_note\n",
    "\n",
    "\n",
    "def append_note_to_notes_dict(notes: pd.DataFrame, note: dict):\n",
    "    for key, value in note.items():\n",
    "        notes[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_tokens(midi_file_path: str, bpm = BPM, beats_per_bar = BEATS_PER_BAR) -> pd.DataFrame:\n",
    "\n",
    "  pm = pretty_midi.PrettyMIDI(midi_file_path)\n",
    "  instrument = pm.instruments[0]\n",
    "  notes = collections.defaultdict(list) # Dictionary with values as list\n",
    "  bar_duration = (60/bpm) * beats_per_bar\n",
    "\n",
    "  ticks_per_beat = pm.resolution\n",
    "\n",
    "  # Sort the notes by start time\n",
    "  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "\n",
    "  for note in sorted_notes:\n",
    "\n",
    "    pitch = note.pitch\n",
    "    velocity = note.velocity\n",
    "    start = note.start\n",
    "    end = note.end\n",
    "    # step = start - prev_start\n",
    "    duration = end - start\n",
    "    bar = int(start // bar_duration) # integer part of the division\n",
    "\n",
    "    # split the note in two if it spans multiple bars\n",
    "    if start + duration > (bar + 1) * bar_duration: \n",
    "\n",
    "      # update the current note to end at the end of the bar and update its duration\n",
    "      note = new_note(pitch, velocity, start, (bar + 1) * bar_duration, bar)\n",
    "      append_note_to_notes_dict(notes, note)\n",
    "\n",
    "      # create new note in the succeeding bar with the remaining duration\n",
    "      note = new_note(pitch, velocity, (bar + 1) * bar_duration, end, bar + 1)\n",
    "      append_note_to_notes_dict(notes, note)\n",
    "\n",
    "    else:\n",
    "      note = new_note(pitch, velocity, start, end, bar)\n",
    "      append_note_to_notes_dict(notes, note)\n",
    "\n",
    "  # create a dataframe from the notes dictionary\n",
    "  notes_df = pd.DataFrame({name: np.array(value) for name, value in notes.items()})\n",
    "\n",
    "\n",
    "  # split notes into bars and convert notes ticks into a time serie of strings\n",
    "  bars_time_series = []\n",
    "  for bar_id in notes_df['bar'].unique():\n",
    "    bar_df = notes_df[notes_df['bar'] == bar_id]\n",
    "    bar_df = bar_df.reset_index(drop=True)\n",
    "\n",
    "    # fill the beginning and end of each bar with empty notes if necessary\n",
    "    if bar_df.loc[len(bar_df) - 1, 'end'] != BAR_LENGTH:\n",
    "      note = new_note(pitch = 0,\n",
    "                      velocity = 0,\n",
    "                      start = bar_df.loc[len(bar_df) - 1, 'end'],\n",
    "                      end = BAR_LENGTH,\n",
    "                      bar = bar,\n",
    "                      convert_to_ticks = False)\n",
    "      bar_df = bar_df.append(note, ignore_index=True)\n",
    "\n",
    "    if bar_df.at[0, 'start'] != 0:\n",
    "      note = new_note(pitch = 0,\n",
    "                      velocity = 0,\n",
    "                      start = 0,\n",
    "                      end = bar_df.at[0, 'start'],\n",
    "                      bar = bar,\n",
    "                      convert_to_ticks = False)\n",
    "      bar_df = bar_df.append(note, ignore_index=True) \n",
    "      bar_df = bar_df.sort_values(by=['start']) \n",
    "      bar_df = bar_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # convert note ticks into a time serie of strings \n",
    "    bar_time_serie = np.empty((BAR_LENGTH), dtype=object)\n",
    "    bar_time_serie[:] = SILENCE_TOKEN\n",
    "    for i in range(len(bar_df)):\n",
    "      note = bar_df.loc[i, 'pitch']\n",
    "      if note != 0:\n",
    "        start = bar_df.loc[i, 'start']\n",
    "        end = bar_df.loc[i, 'end']\n",
    "        bar_time_serie[start] = str(note)+NOTE_START_TOKEN\n",
    "        bar_time_serie[start+1:end] = str(note)\n",
    "    bars_time_series.append(bar_time_serie)\n",
    "\n",
    "\n",
    "  # flat bars and extract the string vocabulary\n",
    "  flatten_time_series = np.concatenate(bars_time_series)\n",
    "  token_list = list(set(flatten_time_series))\n",
    "\n",
    "\n",
    "  # add the token related to the BCI classification (start) to the input sequences vocabulary\n",
    "  if 'input' in midi_file_path:\n",
    "    token_list.append(BCI_TOKEN)\n",
    "\n",
    "\n",
    "  # convert strings tokens to integer tokens and make sequences shifted of 1 bar per time step\n",
    "  STRINGS_TO_TOKENS_VOCAB = {}\n",
    "  for i in range(0, len(token_list)):\n",
    "      STRINGS_TO_TOKENS_VOCAB[token_list[i]] = i\n",
    "\n",
    "  TOKENS_TO_STRING_VOCAB = {}\n",
    "  for i in range(0, len(token_list)):\n",
    "      TOKENS_TO_STRING_VOCAB[i] = token_list[i]\n",
    "\n",
    "\n",
    "  sequences=[]\n",
    "  num_sequences = len(flatten_time_series) - SEQ_LENGTH\n",
    "  for i in range(0, num_sequences, BAR_LENGTH):\n",
    "    seq = flatten_time_series[i:(i+SEQ_LENGTH)].copy() # NB: copy is necessary to avoid modifying the original array\n",
    "\n",
    "    # add the BCI token to the input sequences at each time step\n",
    "    if 'input' in midi_file_path:\n",
    "      seq = np.concatenate(([BCI_TOKEN], seq[:-1]))\n",
    "\n",
    "    for i in range(len(seq)):\n",
    "      seq[i] = STRINGS_TO_TOKENS_VOCAB[seq[i]] \n",
    "\n",
    "      # normalize the input sequence \n",
    "      if 'input' in midi_file_path:\n",
    "        seq[i] = seq[i]/len(STRINGS_TO_TOKENS_VOCAB)\n",
    "\n",
    "    sequences.append(seq)\n",
    "\n",
    "  return sequences, TOKENS_TO_STRING_VOCAB, notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input files: 1\n",
      "Number of output files: 1\n",
      "\n",
      "\n",
      "1: drum_excited.MID -> bass_example.MID\n",
      "\n",
      "Number of input bars: 24\n",
      "Number of input sequences: 20\n",
      "Input sequence length: 192\n",
      "Input vocabulars size: 13\n",
      "\n",
      "Number of output bars: 11\n",
      "Number of output sequences: 7\n",
      "Output sequence length: 192\n",
      "Output vocabulars size: 30\n",
      "\n",
      "Number of sequences after truncation: 7, 7\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Assumptions:\n",
    "Sequences described as input_#.mid and output_#.mid in the corresponding folders\n",
    "'''\n",
    "\n",
    "input_filenames = glob.glob(os.path.join(DATASET_PATH, 'input/*.MID'))\n",
    "print('Number of input files:', len(input_filenames))\n",
    "\n",
    "output_filenames = glob.glob(os.path.join(DATASET_PATH, 'output/*.MID'))\n",
    "print('Number of output files:', len(output_filenames))\n",
    "\n",
    "for i, (in_file, out_file) in enumerate(zip(input_filenames, output_filenames)):\n",
    "\n",
    "    in_file_name = os.path.basename(in_file)\n",
    "    out_file_name = os.path.basename(out_file)\n",
    "    print(f'\\n\\n{i + 1}: {in_file_name} -> {out_file_name}')\n",
    "\n",
    "    input_sequences, INPUT_TOKENS_TO_STRING_VOCAB, input_notes_df = midi_to_tokens(in_file)\n",
    "    n_bar = len(input_notes_df['bar'].unique())\n",
    "    IN_VOCAB_SIZE = len(INPUT_TOKENS_TO_STRING_VOCAB)\n",
    "    print(f'\\nNumber of input bars: {n_bar}')\n",
    "    print(f'Number of input sequences: {len(input_sequences)}')\n",
    "    print(f'Input sequence length: {len(input_sequences[0])}')\n",
    "    print(f'Input vocabulars size: {IN_VOCAB_SIZE}')\n",
    "\n",
    "    output_sequences, OUTPUT_TOKENS_TO_STRING_VOCAB, output_notes_df = midi_to_tokens(out_file)\n",
    "    n_bar = len(output_notes_df['bar'].unique())\n",
    "    OUT_VOCAB_SIZE = len(OUTPUT_TOKENS_TO_STRING_VOCAB)\n",
    "    print(f'\\nNumber of output bars: {n_bar}')\n",
    "    print(f'Number of output sequences: {len(output_sequences)}')\n",
    "    print(f'Output sequence length: {len(output_sequences[0])}')\n",
    "    print(f'Output vocabulars size: {OUT_VOCAB_SIZE}')\n",
    "\n",
    "    min_length = min(len(input_sequences), len(output_sequences))\n",
    "    input_sequences = input_sequences[:min_length]\n",
    "    output_sequences = output_sequences[:min_length]\n",
    "    print(f'\\nNumber of sequences after truncation: {len(input_sequences)}, {len(output_sequences)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(input_sequences, output_sequences, batch_size = BATCH_SIZE):\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_sequences).to(device),\n",
    "                               torch.LongTensor(output_sequences).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return train_dataloader\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
