{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tokens and vocabulary**\n",
    "A token is a distinct element, part of a sequence of tokens. In natural language, a token can be a character, a subword or a word. A sentence can then be tokenized into a sequence of tokens representing the words and punctuation. For symbolic music, tokens can represent the values of the note attributes (pitch, valocity, duration) or time events. These are the “basic” tokens, that can be compared to the characters in natural language. With Byte Pair Encoding (BPE), tokens can represent successions of these basic tokens. A token can take three forms, which we name by convention:\n",
    "\n",
    "- **Token** (string): the form describing it, e.g. Pitch_50.\n",
    "- **Id** (int): an unique associated integer, used as an index.\n",
    "- **Byte** (string): an unique associated byte, used internally for Byte Pair Encoding (BPE).\n",
    "\n",
    "MidiTok works with TokSequence objects to output token sequences of represented by these three forms.\n",
    "\n",
    "#### **Vocabulary**\n",
    "The vocabulary of a tokenizer acts as a lookup table, linking tokens (string / byte) to their ids (integer). The vocabulary is an attribute of the tokenizer and can be accessed with tokenizer.vocab. The vocabulary is a Python dictionary binding tokens (keys) to their ids (values). For tokenizations with embedding pooling (e.g. CPWord or Octuple), tokenizer.vocab will be a list of Vocabulary objects, and the tokenizer.is_multi_vocab property will be True.\n",
    "\n",
    "With **Byte Pair Encoding (BPE)**: tokenizer.vocab holds all the basic tokens describing the note and time attributes of music. By analogy with text, these tokens can be seen as unique characters. After training a tokenizer with BPE, a new vocabulary is built with newly created tokens from pairs of basic tokens. This vocabulary can be accessed with tokenizer.vocab_bpe, and binds tokens as bytes (string) to their associated ids (int). This is the vocabulary of the tokenizers BPE model.\n",
    "\n",
    "#### **TokSequence**\n",
    "The methods of MidiTok use miditok.TokSequence objects as input and outputs. A miditok.TokSequence holds tokens as the three forms described in Byte Pair Encoding (BPE). TokSequences are subscriptable and implement __ len __ (you can run tok_seq[id] and len(tok_seq)).\n",
    "\n",
    "You can use the miditok.MIDITokenizer.complete_sequence() method to automatically fill the non-initialized attributes of a miditok.TokSequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples\\bass_example.MID\n",
      "[TokSequence(tokens=['Bar_None', 'Position_0', 'Tempo_100.0', 'Pitch_43', 'Velocity_127', 'Duration_0.1.16', 'Position_1', 'Pitch_43', 'Velocity_127', 'Duration_0.8.16', 'Position_12', 'Pitch_43', 'Velocity_127', 'Duration_0.4.16', 'Position_17', 'Pitch_47', 'Velocity_127', 'Duration_0.8.16', 'Position_27', 'Pitch_47', 'Velocity_127', 'Duration_0.4.16', 'Position_32', 'Pitch_50', 'Velocity_127', 'Duration_0.8.16', 'Position_43', 'Pitch_50', 'Velocity_127', 'Duration_0.4.16', 'Position_49', 'Pitch_53', 'Velocity_127', 'Duration_0.4.16', 'Position_54', 'Pitch_52', 'Velocity_127', 'Duration_0.3.16', 'Position_60', 'Pitch_50', 'Velocity_127', 'Duration_0.4.16', 'Bar_None', 'Position_1', 'Pitch_43', 'Velocity_127', 'Duration_0.9.16', 'Position_12', 'Pitch_43', 'Velocity_127', 'Duration_0.4.16', 'Position_18', 'Pitch_47', 'Velocity_127', 'Duration_0.9.16', 'Position_28', 'Pitch_47', 'Velocity_127', 'Duration_0.4.16', 'Position_34', 'Pitch_50', 'Velocity_127', 'Duration_0.7.16', 'Position_45', 'Pitch_50', 'Velocity_127', 'Duration_0.3.16', 'Position_50', 'Pitch_53', 'Velocity_127', 'Duration_0.4.16', 'Position_55', 'Pitch_52', 'Velocity_127', 'Duration_0.4.16', 'Position_60', 'Pitch_50', 'Velocity_127', 'Duration_0.5.16', 'Bar_None', 'Position_2', 'Pitch_43', 'Velocity_127', 'Duration_0.7.16', 'Position_12', 'Pitch_43', 'Velocity_127', 'Duration_0.4.16', 'Position_17', 'Pitch_47', 'Velocity_127', 'Duration_0.7.16', 'Position_27', 'Pitch_47', 'Velocity_127', 'Duration_0.3.16', 'Position_33', 'Pitch_50', 'Velocity_127', 'Duration_0.8.16', 'Position_43', 'Pitch_50', 'Velocity_127', 'Duration_0.4.16', 'Position_49', 'Pitch_53', 'Velocity_127', 'Duration_0.4.16', 'Position_54', 'Pitch_52', 'Velocity_127', 'Duration_0.4.16', 'Position_59', 'Pitch_50', 'Velocity_127', 'Duration_0.3.16', 'Bar_None', 'Position_0', 'Pitch_43', 'Velocity_127', 'Duration_0.9.16', 'Position_11', 'Pitch_43', 'Velocity_127', 'Duration_0.3.16', 'Position_16', 'Pitch_47', 'Velocity_127', 'Duration_0.9.16', 'Position_27', 'Pitch_47', 'Velocity_127', 'Duration_0.4.16', 'Position_32', 'Pitch_50', 'Velocity_127', 'Duration_0.8.16', 'Position_42', 'Pitch_45', 'Velocity_127', 'Duration_0.5.16', 'Position_47', 'Pitch_53', 'Velocity_127', 'Duration_0.4.16', 'Position_53', 'Pitch_52', 'Velocity_127', 'Duration_0.2.16', 'Position_57', 'Pitch_50', 'Velocity_127', 'Duration_0.4.16', 'Position_63', 'Pitch_48', 'Velocity_127', 'Duration_0.1.16'], ids=[4, 365, 504, 27, 124, 125, 366, 27, 124, 132, 377, 27, 124, 128, 382, 31, 124, 132, 392, 31, 124, 128, 397, 34, 124, 132, 408, 34, 124, 128, 414, 37, 124, 128, 419, 36, 124, 127, 425, 34, 124, 128, 4, 366, 27, 124, 133, 377, 27, 124, 128, 383, 31, 124, 133, 393, 31, 124, 128, 399, 34, 124, 131, 410, 34, 124, 127, 415, 37, 124, 128, 420, 36, 124, 128, 425, 34, 124, 129, 4, 367, 27, 124, 131, 377, 27, 124, 128, 382, 31, 124, 131, 392, 31, 124, 127, 398, 34, 124, 132, 408, 34, 124, 128, 414, 37, 124, 128, 419, 36, 124, 128, 424, 34, 124, 127, 4, 365, 27, 124, 133, 376, 27, 124, 127, 381, 31, 124, 133, 392, 31, 124, 128, 397, 34, 124, 132, 407, 29, 124, 129, 412, 37, 124, 128, 418, 36, 124, 126, 422, 34, 124, 128, 428, 32, 124, 125], bytes=None, events=[Event(type=Bar, value=None, time=0, desc=0), Event(type=Position, value=0, time=0, desc=0), Event(type=Tempo, value=100.0, time=0, desc=100.0), Event(type=Pitch, value=43, time=0, desc=1), Event(type=Velocity, value=127, time=0, desc=127), Event(type=Duration, value=0.1.16, time=0, desc=1 ticks), Event(type=Position, value=1, time=1, desc=1), Event(type=Pitch, value=43, time=1, desc=9), Event(type=Velocity, value=127, time=1, desc=127), Event(type=Duration, value=0.8.16, time=1, desc=8 ticks), Event(type=Position, value=12, time=12, desc=12), Event(type=Pitch, value=43, time=12, desc=16), Event(type=Velocity, value=127, time=12, desc=127), Event(type=Duration, value=0.4.16, time=12, desc=4 ticks), Event(type=Position, value=17, time=17, desc=17), Event(type=Pitch, value=47, time=17, desc=25), Event(type=Velocity, value=127, time=17, desc=127), Event(type=Duration, value=0.8.16, time=17, desc=8 ticks), Event(type=Position, value=27, time=27, desc=27), Event(type=Pitch, value=47, time=27, desc=31), Event(type=Velocity, value=127, time=27, desc=127), Event(type=Duration, value=0.4.16, time=27, desc=4 ticks), Event(type=Position, value=32, time=32, desc=32), Event(type=Pitch, value=50, time=32, desc=40), Event(type=Velocity, value=127, time=32, desc=127), Event(type=Duration, value=0.8.16, time=32, desc=8 ticks), Event(type=Position, value=43, time=43, desc=43), Event(type=Pitch, value=50, time=43, desc=47), Event(type=Velocity, value=127, time=43, desc=127), Event(type=Duration, value=0.4.16, time=43, desc=4 ticks), Event(type=Position, value=49, time=49, desc=49), Event(type=Pitch, value=53, time=49, desc=53), Event(type=Velocity, value=127, time=49, desc=127), Event(type=Duration, value=0.4.16, time=49, desc=4 ticks), Event(type=Position, value=54, time=54, desc=54), Event(type=Pitch, value=52, time=54, desc=57), Event(type=Velocity, value=127, time=54, desc=127), Event(type=Duration, value=0.3.16, time=54, desc=3 ticks), Event(type=Position, value=60, time=60, desc=60), Event(type=Pitch, value=50, time=60, desc=64), Event(type=Velocity, value=127, time=60, desc=127), Event(type=Duration, value=0.4.16, time=60, desc=4 ticks), Event(type=Bar, value=None, time=64, desc=0), Event(type=Position, value=1, time=65, desc=65), Event(type=Pitch, value=43, time=65, desc=74), Event(type=Velocity, value=127, time=65, desc=127), Event(type=Duration, value=0.9.16, time=65, desc=9 ticks), Event(type=Position, value=12, time=76, desc=76), Event(type=Pitch, value=43, time=76, desc=80), Event(type=Velocity, value=127, time=76, desc=127), Event(type=Duration, value=0.4.16, time=76, desc=4 ticks), Event(type=Position, value=18, time=82, desc=82), Event(type=Pitch, value=47, time=82, desc=91), Event(type=Velocity, value=127, time=82, desc=127), Event(type=Duration, value=0.9.16, time=82, desc=9 ticks), Event(type=Position, value=28, time=92, desc=92), Event(type=Pitch, value=47, time=92, desc=96), Event(type=Velocity, value=127, time=92, desc=127), Event(type=Duration, value=0.4.16, time=92, desc=4 ticks), Event(type=Position, value=34, time=98, desc=98), Event(type=Pitch, value=50, time=98, desc=105), Event(type=Velocity, value=127, time=98, desc=127), Event(type=Duration, value=0.7.16, time=98, desc=7 ticks), Event(type=Position, value=45, time=109, desc=109), Event(type=Pitch, value=50, time=109, desc=112), Event(type=Velocity, value=127, time=109, desc=127), Event(type=Duration, value=0.3.16, time=109, desc=3 ticks), Event(type=Position, value=50, time=114, desc=114), Event(type=Pitch, value=53, time=114, desc=118), Event(type=Velocity, value=127, time=114, desc=127), Event(type=Duration, value=0.4.16, time=114, desc=4 ticks), Event(type=Position, value=55, time=119, desc=119), Event(type=Pitch, value=52, time=119, desc=123), Event(type=Velocity, value=127, time=119, desc=127), Event(type=Duration, value=0.4.16, time=119, desc=4 ticks), Event(type=Position, value=60, time=124, desc=124), Event(type=Pitch, value=50, time=124, desc=129), Event(type=Velocity, value=127, time=124, desc=127), Event(type=Duration, value=0.5.16, time=124, desc=5 ticks), Event(type=Bar, value=None, time=128, desc=0), Event(type=Position, value=2, time=130, desc=130), Event(type=Pitch, value=43, time=130, desc=137), Event(type=Velocity, value=127, time=130, desc=127), Event(type=Duration, value=0.7.16, time=130, desc=7 ticks), Event(type=Position, value=12, time=140, desc=140), Event(type=Pitch, value=43, time=140, desc=144), Event(type=Velocity, value=127, time=140, desc=127), Event(type=Duration, value=0.4.16, time=140, desc=4 ticks), Event(type=Position, value=17, time=145, desc=145), Event(type=Pitch, value=47, time=145, desc=152), Event(type=Velocity, value=127, time=145, desc=127), Event(type=Duration, value=0.7.16, time=145, desc=7 ticks), Event(type=Position, value=27, time=155, desc=155), Event(type=Pitch, value=47, time=155, desc=158), Event(type=Velocity, value=127, time=155, desc=127), Event(type=Duration, value=0.3.16, time=155, desc=3 ticks), Event(type=Position, value=33, time=161, desc=161), Event(type=Pitch, value=50, time=161, desc=169), Event(type=Velocity, value=127, time=161, desc=127), Event(type=Duration, value=0.8.16, time=161, desc=8 ticks), Event(type=Position, value=43, time=171, desc=171), Event(type=Pitch, value=50, time=171, desc=175), Event(type=Velocity, value=127, time=171, desc=127), Event(type=Duration, value=0.4.16, time=171, desc=4 ticks), Event(type=Position, value=49, time=177, desc=177), Event(type=Pitch, value=53, time=177, desc=181), Event(type=Velocity, value=127, time=177, desc=127), Event(type=Duration, value=0.4.16, time=177, desc=4 ticks), Event(type=Position, value=54, time=182, desc=182), Event(type=Pitch, value=52, time=182, desc=186), Event(type=Velocity, value=127, time=182, desc=127), Event(type=Duration, value=0.4.16, time=182, desc=4 ticks), Event(type=Position, value=59, time=187, desc=187), Event(type=Pitch, value=50, time=187, desc=190), Event(type=Velocity, value=127, time=187, desc=127), Event(type=Duration, value=0.3.16, time=187, desc=3 ticks), Event(type=Bar, value=None, time=192, desc=0), Event(type=Position, value=0, time=192, desc=192), Event(type=Pitch, value=43, time=192, desc=201), Event(type=Velocity, value=127, time=192, desc=127), Event(type=Duration, value=0.9.16, time=192, desc=9 ticks), Event(type=Position, value=11, time=203, desc=203), Event(type=Pitch, value=43, time=203, desc=206), Event(type=Velocity, value=127, time=203, desc=127), Event(type=Duration, value=0.3.16, time=203, desc=3 ticks), Event(type=Position, value=16, time=208, desc=208), Event(type=Pitch, value=47, time=208, desc=217), Event(type=Velocity, value=127, time=208, desc=127), Event(type=Duration, value=0.9.16, time=208, desc=9 ticks), Event(type=Position, value=27, time=219, desc=219), Event(type=Pitch, value=47, time=219, desc=223), Event(type=Velocity, value=127, time=219, desc=127), Event(type=Duration, value=0.4.16, time=219, desc=4 ticks), Event(type=Position, value=32, time=224, desc=224), Event(type=Pitch, value=50, time=224, desc=232), Event(type=Velocity, value=127, time=224, desc=127), Event(type=Duration, value=0.8.16, time=224, desc=8 ticks), Event(type=Position, value=42, time=234, desc=234), Event(type=Pitch, value=45, time=234, desc=239), Event(type=Velocity, value=127, time=234, desc=127), Event(type=Duration, value=0.5.16, time=234, desc=5 ticks), Event(type=Position, value=47, time=239, desc=239), Event(type=Pitch, value=53, time=239, desc=243), Event(type=Velocity, value=127, time=239, desc=127), Event(type=Duration, value=0.4.16, time=239, desc=4 ticks), Event(type=Position, value=53, time=245, desc=245), Event(type=Pitch, value=52, time=245, desc=247), Event(type=Velocity, value=127, time=245, desc=127), Event(type=Duration, value=0.2.16, time=245, desc=2 ticks), Event(type=Position, value=57, time=249, desc=249), Event(type=Pitch, value=50, time=249, desc=253), Event(type=Velocity, value=127, time=249, desc=127), Event(type=Duration, value=0.4.16, time=249, desc=4 ticks), Event(type=Position, value=63, time=255, desc=255), Event(type=Pitch, value=48, time=255, desc=256), Event(type=Velocity, value=127, time=255, desc=127), Event(type=Duration, value=0.1.16, time=255, desc=1 ticks)], ids_bpe_encoded=False, _ids_no_bpe=None)]\n",
      "157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gianni\\AppData\\Local\\Temp\\ipykernel_21600\\469154161.py:32: UserWarning: vocab_size (157) need to be higher than the size of thecurrent vocabulary (505). Skipping BPE training.\n",
      "  tokenizer.learn_bpe(vocab_size=len(tokens[0]), files_paths='examples/bass_example.MID')\n"
     ]
    }
   ],
   "source": [
    "from miditok import REMI, TokenizerConfig  # here we choose to use REMI\n",
    "\n",
    "# Our parameters\n",
    "TOKENIZER_PARAMS = {\n",
    "    \"pitch_range\": (21, 109),\n",
    "    \"beat_res\": {(0, 15): 16},\n",
    "    \"num_velocities\": 32,\n",
    "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\", \"MASK\"],\n",
    "    \"use_chords\": True,\n",
    "    \"use_rests\": False,\n",
    "    \"use_tempos\": True,\n",
    "    \"use_time_signatures\": False,\n",
    "    \"use_programs\": False,\n",
    "    \"num_tempos\": 1,  # number of tempo bins\n",
    "    \"tempo_range\": (100, 100),  # (min, max)\n",
    "}\n",
    "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
    "\n",
    "# Creates the tokenizer\n",
    "tokenizer = REMI(config)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Tokenize a MIDI file\n",
    "midi_path = list(Path(\"examples\").glob(\"**/*.mid\")) [0]\n",
    "print(midi_path)\n",
    "tokens = tokenizer(midi_path)  # automatically detects Score objects, paths, tokens\n",
    "\n",
    "print(tokens)\n",
    "print(len(tokens[0]))\n",
    "\n",
    "tokenizer.learn_bpe(vocab_size=len(tokens[0]), files_paths='examples/bass_example.MID')\n",
    "\n",
    "# Convert to MIDI and save it\n",
    "generated_midi = tokenizer(tokens)  # MidiTok can handle PyTorch/Numpy/Tensorflow tensors\n",
    "generated_midi.dump_midi(Path(\"decoded_midi.MID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trains a tokenizer with BPE\n",
    "Here we train the tokenizer with Byte Pair Encoding (BPE). BPE allows to reduce the lengths of the sequences of tokens, in turn model efficiency, while improving the results quality/model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok import REMI\n",
    "from pathlib import Path\n",
    "\n",
    "# Creates the tokenizer and list the file paths\n",
    "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
    "midi_paths = list(Path(\"examples\").glob(\"**/*.mid\"))\n",
    "\n",
    "# Builds the vocabulary with BPE\n",
    "tokenizer.learn_bpe(vocab_size=30000, files_paths=midi_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creates a Dataset and collator for training\n",
    "Creates a Dataset and a collator to be used with a PyTorch DataLoader to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting MIDIs (output\\midi_chunks):   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Split MIDIs into smaller chunks for training\u001b[39;00m\n\u001b[0;32m     32\u001b[0m dataset_chunks_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmidi_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m \u001b[43msplit_midis_for_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmidi_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_chunks_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Create a Dataset, a DataLoader and a collator to train a model\u001b[39;00m\n\u001b[0;32m     41\u001b[0m dataset \u001b[38;5;241m=\u001b[39m DatasetMIDI(\n\u001b[0;32m     42\u001b[0m     files_paths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(dataset_chunks_dir\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**/*.mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m     43\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     eos_token_id\u001b[38;5;241m=\u001b[39mtokenizer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEOS_None\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     47\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\miditok\\pytorch_data\\split_midi_utils.py:118\u001b[0m, in \u001b[0;36msplit_midis_for_training\u001b[1;34m(files_paths, tokenizer, save_dir, max_seq_len, average_num_tokens_per_note, num_overlap_bars, min_seq_len)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Split per note density\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ti, midi_to_split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(midis):\n\u001b[1;32m--> 118\u001b[0m     midi_splits \u001b[38;5;241m=\u001b[39m \u001b[43msplit_midi_per_note_density\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmidi_to_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_num_tokens_per_note\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_overlap_bars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# Save them\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _i, midi_to_save \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(midi_splits):\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;66;03m# Skip it if there are no notes, this can happen with\u001b[39;00m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# portions of tracks with no notes but tempo/signature\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;66;03m# changes happening later\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\miditok\\pytorch_data\\split_midi_utils.py:203\u001b[0m, in \u001b[0;36msplit_midi_per_note_density\u001b[1;34m(midi, max_seq_len, average_num_tokens_per_note, num_overlap_bars, min_seq_len)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_seq_len \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     min_seq_len \u001b[38;5;241m=\u001b[39m max_seq_len \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m--> 203\u001b[0m bar_ticks \u001b[38;5;241m=\u001b[39m \u001b[43mget_bars_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmidi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m num_notes_per_bar \u001b[38;5;241m=\u001b[39m get_num_notes_per_bar(midi)\n\u001b[0;32m    205\u001b[0m num_tokens_per_bar \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    206\u001b[0m     npb \u001b[38;5;241m*\u001b[39m average_num_tokens_per_note \u001b[38;5;28;01mfor\u001b[39;00m npb \u001b[38;5;129;01min\u001b[39;00m num_notes_per_bar\n\u001b[0;32m    207\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\miditok\\utils\\utils.py:668\u001b[0m, in \u001b[0;36mget_bars_ticks\u001b[1;34m(midi)\u001b[0m\n\u001b[0;32m    666\u001b[0m time_sigs \u001b[38;5;241m=\u001b[39m copy(midi\u001b[38;5;241m.\u001b[39mtime_signatures)\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m# Mock the last one to cover the last section in the loop below\u001b[39;00m\n\u001b[1;32m--> 668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtime_sigs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m!=\u001b[39m max_tick:\n\u001b[0;32m    669\u001b[0m     time_sigs\u001b[38;5;241m.\u001b[39mappend(TimeSignature(max_tick, \u001b[38;5;241m*\u001b[39mTIME_SIGNATURE))\n\u001b[0;32m    671\u001b[0m \u001b[38;5;66;03m# Section from tick 0 to first time sig is 4/4 if first time sig time is not 0\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator, split_midis_for_training\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Creating a multitrack tokenizer configuration, read the doc to explore other parameters\n",
    "TOKENIZER_PARAMS = {\n",
    "    \"pitch_range\": (21, 109),\n",
    "    \"beat_res\": {(0, 15): 16},\n",
    "    \"num_velocities\": 32,\n",
    "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\", \"MASK\"],\n",
    "    \"use_chords\": True,\n",
    "    \"use_rests\": False,\n",
    "    \"use_tempos\": True,\n",
    "    \"use_time_signatures\": False,\n",
    "    \"use_programs\": False,\n",
    "    \"num_tempos\": 1,  # number of tempo bins\n",
    "    \"tempo_range\": (100, 100),  # (min, max)\n",
    "}\n",
    "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
    "\n",
    "# Creates the tokenizer\n",
    "tokenizer = REMI(config)\n",
    "\n",
    "# Train the tokenizer with Byte Pair Encoding (BPE)\n",
    "midi_paths = list(Path(\"examples\").glob(\"**/*.mid\"))\n",
    "tokenizer.learn_bpe(vocab_size=30000, files_paths=midi_paths)\n",
    "tokenizer.save_params(Path('output', \"tokenizer.json\"))\n",
    "\n",
    "# Split MIDIs into smaller chunks for training\n",
    "dataset_chunks_dir = Path(\"output\", \"midi_chunks\")\n",
    "split_midis_for_training(\n",
    "    files_paths=midi_paths,\n",
    "    tokenizer=tokenizer,\n",
    "    save_dir=dataset_chunks_dir,\n",
    "    max_seq_len=50,\n",
    ")\n",
    "\n",
    "# Create a Dataset, a DataLoader and a collator to train a model\n",
    "dataset = DatasetMIDI(\n",
    "    files_paths=list(dataset_chunks_dir.glob(\"**/*.mid\")),\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "collator = DataCollator(tokenizer[\"PAD_None\"])\n",
    "dataloader = DataLoader(dataset, batch_size=64, collate_fn=collator)\n",
    "\n",
    "# Iterate over the dataloader to train a model\n",
    "for batch in dataloader:\n",
    "    print(\"Train your model on this batch...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize a dataset \n",
    "Here we tokenize a whole dataset into JSON files storing the tokens ids. We also perform data augmentation on the pitch, velocity and duration dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok import REMI\n",
    "from miditok.data_augmentation import augment_midi_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "# Creates the tokenizer and list the file paths\n",
    "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
    "data_path = Path(\"path\", \"to\", \"dataset\")\n",
    "\n",
    "# A validation method to discard MIDIs we do not want\n",
    "# It can also be used for custom pre-processing, for instance if you want to merge\n",
    "# some tracks before tokenizing a MIDI file\n",
    "def midi_valid(midi) -> bool:\n",
    "    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
    "        return False  # time signature different from 4/*, 4 beats per bar\n",
    "    return True\n",
    "\n",
    "# Performs data augmentation on one pitch octave (up and down), velocities and\n",
    "# durations\n",
    "midi_aug_path = Path(\"to\", \"new\", \"location\", \"augmented\")\n",
    "augment_midi_dataset(\n",
    "    data_path,\n",
    "    pitch_offsets=[-12, 12],\n",
    "    velocity_offsets=[-4, 5],\n",
    "    duration_offsets=[-0.5, 1],\n",
    "    out_path=midi_aug_path,\n",
    ")\n",
    "tokenizer.tokenize_midi_dataset(        # 2 velocity and 1 duration values\n",
    "    data_path,\n",
    "    Path(\"path\", \"to\", \"tokens\"),\n",
    "    midi_valid,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
