{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tokens and vocabulary**\n",
    "A token is a distinct element, part of a sequence of tokens. In natural language, a token can be a character, a subword or a word. A sentence can then be tokenized into a sequence of tokens representing the words and punctuation. For symbolic music, tokens can represent the values of the note attributes (pitch, valocity, duration) or time events. These are the “basic” tokens, that can be compared to the characters in natural language. With Byte Pair Encoding (BPE), tokens can represent successions of these basic tokens. A token can take three forms, which we name by convention:\n",
    "\n",
    "- **Token** (string): the form describing it, e.g. Pitch_50.\n",
    "- **Id** (int): an unique associated integer, used as an index.\n",
    "- **Byte** (string): an unique associated byte, used internally for Byte Pair Encoding (BPE).\n",
    "\n",
    "MidiTok works with TokSequence objects to output token sequences of represented by these three forms.\n",
    "\n",
    "#### **Vocabulary**\n",
    "The vocabulary of a tokenizer acts as a lookup table, linking tokens (string / byte) to their ids (integer). The vocabulary is an attribute of the tokenizer and can be accessed with tokenizer.vocab. The vocabulary is a Python dictionary binding tokens (keys) to their ids (values). For tokenizations with embedding pooling (e.g. CPWord or Octuple), tokenizer.vocab will be a list of Vocabulary objects, and the tokenizer.is_multi_vocab property will be True.\n",
    "\n",
    "With **Byte Pair Encoding (BPE)**: tokenizer.vocab holds all the basic tokens describing the note and time attributes of music. By analogy with text, these tokens can be seen as unique characters. After training a tokenizer with BPE, a new vocabulary is built with newly created tokens from pairs of basic tokens. This vocabulary can be accessed with tokenizer.vocab_bpe, and binds tokens as bytes (string) to their associated ids (int). This is the vocabulary of the tokenizers BPE model.\n",
    "BPE allows to reduce the lengths of the sequences of tokens, in turn model efficiency, while improving the results quality/model performance.\n",
    "\n",
    "#### **TokSequence**\n",
    "The methods of MidiTok use miditok.TokSequence objects as input and outputs. A miditok.TokSequence holds tokens as the three forms described in Byte Pair Encoding (BPE). TokSequences are subscriptable and implement __ len __ (you can run tok_seq[id] and len(tok_seq)).\n",
    "\n",
    "You can use the miditok.MIDITokenizer.complete_sequence() method to automatically fill the non-initialized attributes of a miditok.TokSequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples\\bass_example.MID\n",
      "[TokSequence(tokens=['Bar_None', 'Position_0', 'Tempo_120.0', 'Pitch_43', 'Velocity_127', 'Duration_0.1.16', 'Position_1', 'Pitch_43', 'Velocity_127', 'Duration_0.8.16', 'Position_12', 'Pitch_43', 'Velocity_127', 'Duration_0.4.16', 'Position_17', 'Pitch_47', 'Velocity_127', 'Duration_0.8.16', 'Position_27', 'Pitch_47', 'Velocity_127', 'Duration_0.4.16', 'Position_32', 'Pitch_50', 'Velocity_127', 'Duration_0.8.16', 'Position_43', 'Pitch_50', 'Velocity_127', 'Duration_0.4.16', 'Position_49', 'Pitch_53', 'Velocity_127', 'Duration_0.4.16', 'Position_54', 'Pitch_52', 'Velocity_127', 'Duration_0.3.16', 'Position_60', 'Pitch_50', 'Velocity_127', 'Duration_0.4.16', 'Bar_None', 'Position_1', 'Pitch_43', 'Velocity_127', 'Duration_0.9.16', 'Position_12', 'Pitch_43', 'Velocity_127', 'Duration_0.4.16', 'Position_18', 'Pitch_47', 'Velocity_127', 'Duration_0.9.16', 'Position_28', 'Pitch_47', 'Velocity_127', 'Duration_0.4.16', 'Position_34', 'Pitch_50', 'Velocity_127', 'Duration_0.7.16', 'Position_45', 'Pitch_50', 'Velocity_127', 'Duration_0.3.16', 'Position_50', 'Pitch_53', 'Velocity_127', 'Duration_0.4.16', 'Position_55', 'Pitch_52', 'Velocity_127', 'Duration_0.4.16', 'Position_60', 'Pitch_50', 'Velocity_127', 'Duration_0.5.16', 'Bar_None', 'Position_2', 'Pitch_43', 'Velocity_127', 'Duration_0.7.16', 'Position_12', 'Pitch_43', 'Velocity_127', 'Duration_0.4.16', 'Position_17', 'Pitch_47', 'Velocity_127', 'Duration_0.7.16', 'Position_27', 'Pitch_47', 'Velocity_127', 'Duration_0.3.16', 'Position_33', 'Pitch_50', 'Velocity_127', 'Duration_0.8.16', 'Position_43', 'Pitch_50', 'Velocity_127', 'Duration_0.4.16', 'Position_49', 'Pitch_53', 'Velocity_127', 'Duration_0.4.16', 'Position_54', 'Pitch_52', 'Velocity_127', 'Duration_0.4.16', 'Position_59', 'Pitch_50', 'Velocity_127', 'Duration_0.3.16', 'Bar_None', 'Position_0', 'Pitch_43', 'Velocity_127', 'Duration_0.9.16', 'Position_11', 'Pitch_43', 'Velocity_127', 'Duration_0.3.16', 'Position_16', 'Pitch_47', 'Velocity_127', 'Duration_0.9.16', 'Position_27', 'Pitch_47', 'Velocity_127', 'Duration_0.4.16', 'Position_32', 'Pitch_50', 'Velocity_127', 'Duration_0.8.16', 'Position_42', 'Pitch_45', 'Velocity_127', 'Duration_0.5.16', 'Position_47', 'Pitch_53', 'Velocity_127', 'Duration_0.4.16', 'Position_53', 'Pitch_52', 'Velocity_127', 'Duration_0.2.16', 'Position_57', 'Pitch_50', 'Velocity_127', 'Duration_0.4.16', 'Position_63', 'Pitch_48', 'Velocity_127', 'Duration_0.1.16'], ids=[4, 365, 504, 27, 124, 125, 366, 27, 124, 132, 377, 27, 124, 128, 382, 31, 124, 132, 392, 31, 124, 128, 397, 34, 124, 132, 408, 34, 124, 128, 414, 37, 124, 128, 419, 36, 124, 127, 425, 34, 124, 128, 4, 366, 27, 124, 133, 377, 27, 124, 128, 383, 31, 124, 133, 393, 31, 124, 128, 399, 34, 124, 131, 410, 34, 124, 127, 415, 37, 124, 128, 420, 36, 124, 128, 425, 34, 124, 129, 4, 367, 27, 124, 131, 377, 27, 124, 128, 382, 31, 124, 131, 392, 31, 124, 127, 398, 34, 124, 132, 408, 34, 124, 128, 414, 37, 124, 128, 419, 36, 124, 128, 424, 34, 124, 127, 4, 365, 27, 124, 133, 376, 27, 124, 127, 381, 31, 124, 133, 392, 31, 124, 128, 397, 34, 124, 132, 407, 29, 124, 129, 412, 37, 124, 128, 418, 36, 124, 126, 422, 34, 124, 128, 428, 32, 124, 125], bytes=None, events=[Event(type=Bar, value=None, time=0, desc=0), Event(type=Position, value=0, time=0, desc=0), Event(type=Tempo, value=120.0, time=0, desc=120.0), Event(type=Pitch, value=43, time=0, desc=1), Event(type=Velocity, value=127, time=0, desc=127), Event(type=Duration, value=0.1.16, time=0, desc=1 ticks), Event(type=Position, value=1, time=1, desc=1), Event(type=Pitch, value=43, time=1, desc=9), Event(type=Velocity, value=127, time=1, desc=127), Event(type=Duration, value=0.8.16, time=1, desc=8 ticks), Event(type=Position, value=12, time=12, desc=12), Event(type=Pitch, value=43, time=12, desc=16), Event(type=Velocity, value=127, time=12, desc=127), Event(type=Duration, value=0.4.16, time=12, desc=4 ticks), Event(type=Position, value=17, time=17, desc=17), Event(type=Pitch, value=47, time=17, desc=25), Event(type=Velocity, value=127, time=17, desc=127), Event(type=Duration, value=0.8.16, time=17, desc=8 ticks), Event(type=Position, value=27, time=27, desc=27), Event(type=Pitch, value=47, time=27, desc=31), Event(type=Velocity, value=127, time=27, desc=127), Event(type=Duration, value=0.4.16, time=27, desc=4 ticks), Event(type=Position, value=32, time=32, desc=32), Event(type=Pitch, value=50, time=32, desc=40), Event(type=Velocity, value=127, time=32, desc=127), Event(type=Duration, value=0.8.16, time=32, desc=8 ticks), Event(type=Position, value=43, time=43, desc=43), Event(type=Pitch, value=50, time=43, desc=47), Event(type=Velocity, value=127, time=43, desc=127), Event(type=Duration, value=0.4.16, time=43, desc=4 ticks), Event(type=Position, value=49, time=49, desc=49), Event(type=Pitch, value=53, time=49, desc=53), Event(type=Velocity, value=127, time=49, desc=127), Event(type=Duration, value=0.4.16, time=49, desc=4 ticks), Event(type=Position, value=54, time=54, desc=54), Event(type=Pitch, value=52, time=54, desc=57), Event(type=Velocity, value=127, time=54, desc=127), Event(type=Duration, value=0.3.16, time=54, desc=3 ticks), Event(type=Position, value=60, time=60, desc=60), Event(type=Pitch, value=50, time=60, desc=64), Event(type=Velocity, value=127, time=60, desc=127), Event(type=Duration, value=0.4.16, time=60, desc=4 ticks), Event(type=Bar, value=None, time=64, desc=0), Event(type=Position, value=1, time=65, desc=65), Event(type=Pitch, value=43, time=65, desc=74), Event(type=Velocity, value=127, time=65, desc=127), Event(type=Duration, value=0.9.16, time=65, desc=9 ticks), Event(type=Position, value=12, time=76, desc=76), Event(type=Pitch, value=43, time=76, desc=80), Event(type=Velocity, value=127, time=76, desc=127), Event(type=Duration, value=0.4.16, time=76, desc=4 ticks), Event(type=Position, value=18, time=82, desc=82), Event(type=Pitch, value=47, time=82, desc=91), Event(type=Velocity, value=127, time=82, desc=127), Event(type=Duration, value=0.9.16, time=82, desc=9 ticks), Event(type=Position, value=28, time=92, desc=92), Event(type=Pitch, value=47, time=92, desc=96), Event(type=Velocity, value=127, time=92, desc=127), Event(type=Duration, value=0.4.16, time=92, desc=4 ticks), Event(type=Position, value=34, time=98, desc=98), Event(type=Pitch, value=50, time=98, desc=105), Event(type=Velocity, value=127, time=98, desc=127), Event(type=Duration, value=0.7.16, time=98, desc=7 ticks), Event(type=Position, value=45, time=109, desc=109), Event(type=Pitch, value=50, time=109, desc=112), Event(type=Velocity, value=127, time=109, desc=127), Event(type=Duration, value=0.3.16, time=109, desc=3 ticks), Event(type=Position, value=50, time=114, desc=114), Event(type=Pitch, value=53, time=114, desc=118), Event(type=Velocity, value=127, time=114, desc=127), Event(type=Duration, value=0.4.16, time=114, desc=4 ticks), Event(type=Position, value=55, time=119, desc=119), Event(type=Pitch, value=52, time=119, desc=123), Event(type=Velocity, value=127, time=119, desc=127), Event(type=Duration, value=0.4.16, time=119, desc=4 ticks), Event(type=Position, value=60, time=124, desc=124), Event(type=Pitch, value=50, time=124, desc=129), Event(type=Velocity, value=127, time=124, desc=127), Event(type=Duration, value=0.5.16, time=124, desc=5 ticks), Event(type=Bar, value=None, time=128, desc=0), Event(type=Position, value=2, time=130, desc=130), Event(type=Pitch, value=43, time=130, desc=137), Event(type=Velocity, value=127, time=130, desc=127), Event(type=Duration, value=0.7.16, time=130, desc=7 ticks), Event(type=Position, value=12, time=140, desc=140), Event(type=Pitch, value=43, time=140, desc=144), Event(type=Velocity, value=127, time=140, desc=127), Event(type=Duration, value=0.4.16, time=140, desc=4 ticks), Event(type=Position, value=17, time=145, desc=145), Event(type=Pitch, value=47, time=145, desc=152), Event(type=Velocity, value=127, time=145, desc=127), Event(type=Duration, value=0.7.16, time=145, desc=7 ticks), Event(type=Position, value=27, time=155, desc=155), Event(type=Pitch, value=47, time=155, desc=158), Event(type=Velocity, value=127, time=155, desc=127), Event(type=Duration, value=0.3.16, time=155, desc=3 ticks), Event(type=Position, value=33, time=161, desc=161), Event(type=Pitch, value=50, time=161, desc=169), Event(type=Velocity, value=127, time=161, desc=127), Event(type=Duration, value=0.8.16, time=161, desc=8 ticks), Event(type=Position, value=43, time=171, desc=171), Event(type=Pitch, value=50, time=171, desc=175), Event(type=Velocity, value=127, time=171, desc=127), Event(type=Duration, value=0.4.16, time=171, desc=4 ticks), Event(type=Position, value=49, time=177, desc=177), Event(type=Pitch, value=53, time=177, desc=181), Event(type=Velocity, value=127, time=177, desc=127), Event(type=Duration, value=0.4.16, time=177, desc=4 ticks), Event(type=Position, value=54, time=182, desc=182), Event(type=Pitch, value=52, time=182, desc=186), Event(type=Velocity, value=127, time=182, desc=127), Event(type=Duration, value=0.4.16, time=182, desc=4 ticks), Event(type=Position, value=59, time=187, desc=187), Event(type=Pitch, value=50, time=187, desc=190), Event(type=Velocity, value=127, time=187, desc=127), Event(type=Duration, value=0.3.16, time=187, desc=3 ticks), Event(type=Bar, value=None, time=192, desc=0), Event(type=Position, value=0, time=192, desc=192), Event(type=Pitch, value=43, time=192, desc=201), Event(type=Velocity, value=127, time=192, desc=127), Event(type=Duration, value=0.9.16, time=192, desc=9 ticks), Event(type=Position, value=11, time=203, desc=203), Event(type=Pitch, value=43, time=203, desc=206), Event(type=Velocity, value=127, time=203, desc=127), Event(type=Duration, value=0.3.16, time=203, desc=3 ticks), Event(type=Position, value=16, time=208, desc=208), Event(type=Pitch, value=47, time=208, desc=217), Event(type=Velocity, value=127, time=208, desc=127), Event(type=Duration, value=0.9.16, time=208, desc=9 ticks), Event(type=Position, value=27, time=219, desc=219), Event(type=Pitch, value=47, time=219, desc=223), Event(type=Velocity, value=127, time=219, desc=127), Event(type=Duration, value=0.4.16, time=219, desc=4 ticks), Event(type=Position, value=32, time=224, desc=224), Event(type=Pitch, value=50, time=224, desc=232), Event(type=Velocity, value=127, time=224, desc=127), Event(type=Duration, value=0.8.16, time=224, desc=8 ticks), Event(type=Position, value=42, time=234, desc=234), Event(type=Pitch, value=45, time=234, desc=239), Event(type=Velocity, value=127, time=234, desc=127), Event(type=Duration, value=0.5.16, time=234, desc=5 ticks), Event(type=Position, value=47, time=239, desc=239), Event(type=Pitch, value=53, time=239, desc=243), Event(type=Velocity, value=127, time=239, desc=127), Event(type=Duration, value=0.4.16, time=239, desc=4 ticks), Event(type=Position, value=53, time=245, desc=245), Event(type=Pitch, value=52, time=245, desc=247), Event(type=Velocity, value=127, time=245, desc=127), Event(type=Duration, value=0.2.16, time=245, desc=2 ticks), Event(type=Position, value=57, time=249, desc=249), Event(type=Pitch, value=50, time=249, desc=253), Event(type=Velocity, value=127, time=249, desc=127), Event(type=Duration, value=0.4.16, time=249, desc=4 ticks), Event(type=Position, value=63, time=255, desc=255), Event(type=Pitch, value=48, time=255, desc=256), Event(type=Velocity, value=127, time=255, desc=127), Event(type=Duration, value=0.1.16, time=255, desc=1 ticks)], ids_bpe_encoded=False, _ids_no_bpe=None)]\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "from miditok import REMI, TokenizerConfig  # here we choose to use REMI\n",
    "\n",
    "# Our parameters\n",
    "TOKENIZER_PARAMS = {\n",
    "    \"pitch_range\": (21, 109),\n",
    "    \"beat_res\": {(0, 15): 16},\n",
    "    \"num_velocities\": 32,\n",
    "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\", \"MASK\"],\n",
    "    \"use_chords\": True,\n",
    "    \"use_rests\": False,\n",
    "    \"use_tempos\": True,\n",
    "    \"use_time_signatures\": False,\n",
    "    \"use_programs\": False,\n",
    "    \"num_tempos\": 1,  # number of tempo bins\n",
    "    \"tempo_range\": (120, 120),  # (min, max)\n",
    "}\n",
    "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
    "\n",
    "# Creates the tokenizer\n",
    "tokenizer = REMI(config)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Tokenize a MIDI file\n",
    "midi_path = list(Path(\"examples\").glob(\"**/*.mid\")) [0]\n",
    "print(midi_path)\n",
    "tokens = tokenizer(midi_path)  # automatically detects Score objects, paths, tokens\n",
    "\n",
    "print(tokens)\n",
    "print(len(tokens[0]))\n",
    "\n",
    "# tokenizer.learn_bpe(vocab_size=len(tokens[0]), files_paths='examples/bass_example.MID')\n",
    "\n",
    "# Convert to MIDI and save it\n",
    "generated_midi = tokenizer(tokens)  # MidiTok can handle PyTorch/Numpy/Tensorflow tensors\n",
    "generated_midi.dump_midi(Path(\"output/decoded_midi.MID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creates a Dataset and collator for training\n",
    "Creates a Dataset and a collator to be used with a PyTorch DataLoader to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('examples/bass_example.MID')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gianni\\AppData\\Local\\Temp\\ipykernel_19084\\724419351.py:34: UserWarning: These MIDI have already been split in the saving directory (output\\midi_chunks). Skipping MIDI splitting.\n",
      "  split_midis_for_training(\n"
     ]
    }
   ],
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator, split_midis_for_training\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "# Creating a multitrack tokenizer configuration, read the doc to explore other parameters\n",
    "TOKENIZER_PARAMS = {\n",
    "    \"pitch_range\": (21, 109),\n",
    "    \"beat_res\": {(0, 15): 16},\n",
    "    \"num_velocities\": 32,\n",
    "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\", \"MASK\"],\n",
    "    \"use_chords\": True,\n",
    "    \"use_rests\": False,\n",
    "    \"use_tempos\": True,\n",
    "    \"use_time_signatures\": False,\n",
    "    \"use_programs\": False,\n",
    "    \"num_tempos\": 1,  # number of tempo bins\n",
    "    \"tempo_range\": (100, 100),  # (min, max)\n",
    "}\n",
    "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
    "\n",
    "# Creates the tokenizer\n",
    "tokenizer = REMI(config)\n",
    "\n",
    "# Train the tokenizer with Byte Pair Encoding (BPE)\n",
    "midi_paths = list(Path(\"examples\").glob(\"**/*.mid\"))\n",
    "midi_paths = [midi_paths[0]]\n",
    "print(midi_paths)\n",
    "tokenizer.learn_bpe(vocab_size=30000, files_paths=midi_paths)\n",
    "tokenizer.save_params(Path('output', \"tokenizer.json\"))\n",
    "\n",
    "\n",
    "# Create a Dataset, a DataLoader and a collator to train a model\n",
    "dataset = DatasetMIDI(\n",
    "    files_paths= list(dataset_chunks_dir.glob(\"**/*.mid\")),\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=32,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"], # beginning-of-sequence \n",
    "    eos_token_id=tokenizer[\"EOS_None\"], # end-of-sequence\n",
    ")\n",
    "collator = DataCollator(tokenizer[\"PAD_None\"])\n",
    "dataloader = DataLoader(dataset, batch_size=2, collate_fn=collator)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../TCN')\n",
    "from tcn import TemporalConvNet\n",
    "\n",
    "model = TemporalConvNet(num_inputs=1, num_channels=[10, 10, 10, 10, 10], kernel_size=3, dropout=0.2)\n",
    "\n",
    "# Iterate over the dataloader to train a model\n",
    "for i, batch in enumerate(dataloader):\n",
    "    tokens = batch['input_ids']\n",
    "    print(f'\\nBatch_{i}, Length={len(tokens[0])}')\n",
    "    print(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            # print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "            #                             epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    # showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize a dataset \n",
    "Here we tokenize a whole dataset into JSON files storing the tokens ids. We also perform data augmentation on the pitch, velocity and duration dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing data augmentation: 0it [00:00, ?it/s]\n",
      "Tokenizing MIDIs (to/tokens): 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from miditok import REMI\n",
    "from miditok.data_augmentation import augment_midi_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "# Creates the tokenizer and list the file paths\n",
    "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
    "data_path = Path(\"path\", \"to\", \"dataset\")\n",
    "\n",
    "# A validation method to discard MIDIs we do not want\n",
    "# It can also be used for custom pre-processing, for instance if you want to merge\n",
    "# some tracks before tokenizing a MIDI file\n",
    "def midi_valid(midi) -> bool:\n",
    "    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
    "        return False  # time signature different from 4/*, 4 beats per bar\n",
    "    return True\n",
    "\n",
    "# Performs data augmentation on one pitch octave (up and down), velocities and\n",
    "# durations\n",
    "midi_aug_path = Path(\"to\", \"new\", \"location\", \"augmented\")\n",
    "augment_midi_dataset(\n",
    "    data_path,\n",
    "    pitch_offsets=[-12, 12],\n",
    "    velocity_offsets=[-4, 5],\n",
    "    duration_offsets=[-0.5, 1],\n",
    "    out_path=midi_aug_path,\n",
    ")\n",
    "tokenizer.tokenize_midi_dataset(        # 2 velocity and 1 duration values\n",
    "    data_path,\n",
    "    Path(\"path\", \"to\", \"tokens\"),\n",
    "    midi_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SYMUSIC Library\n",
    "\n",
    "Read MIDI and add time_signature if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note_num:  3887\n",
      "start_time:  0\n",
      "end_time:  78494\n",
      "symusic.core.TempoTickList([Tempo(time=0, qpm=135.000135000135, mspq=444444)])\n",
      "symusic.core.KeySignatureTickList([KeySignature(time=0, key=3, tonality=0, degree=3)])\n",
      "symusic.core.TimeSignatureTickList([TimeSignature(time=0, numerator=4, denominator=4), TimeSignature(time=37632, numerator=2, denominator=4), TimeSignature(time=38016, numerator=3, denominator=8), TimeSignature(time=38880, numerator=5, denominator=8), TimeSignature(time=39360, numerator=4, denominator=4), TimeSignature(time=40128, numerator=2, denominator=4), TimeSignature(time=40512, numerator=3, denominator=8), TimeSignature(time=41376, numerator=5, denominator=8), TimeSignature(time=41856, numerator=4, denominator=4), TimeSignature(time=42624, numerator=2, denominator=4), TimeSignature(time=43008, numerator=3, denominator=8), TimeSignature(time=43872, numerator=5, denominator=8), TimeSignature(time=44352, numerator=4, denominator=4), TimeSignature(time=45120, numerator=2, denominator=4), TimeSignature(time=45504, numerator=3, denominator=8), TimeSignature(time=46368, numerator=5, denominator=8), TimeSignature(time=46848, numerator=4, denominator=4), TimeSignature(time=47616, numerator=2, denominator=4), TimeSignature(time=48000, numerator=3, denominator=8), TimeSignature(time=48864, numerator=5, denominator=8), TimeSignature(time=49344, numerator=4, denominator=4), TimeSignature(time=50112, numerator=2, denominator=4), TimeSignature(time=50496, numerator=3, denominator=8), TimeSignature(time=51360, numerator=5, denominator=8), TimeSignature(time=51840, numerator=4, denominator=4)])\n",
      "symusic.core.TimeSignatureTickList([TimeSignature(time=0, numerator=4, denominator=4)])\n"
     ]
    }
   ],
   "source": [
    "from symusic import Score, TimeSignature\n",
    "from symusic.core import TimeSignatureTickList\n",
    "score = Score(\"examples/bass_example_copy.mid\")\n",
    "score = Score(\"examples/HereComesTheSun.mid\")\n",
    "print(\"note_num: \", score.note_num())\n",
    "print(\"start_time: \", score.start())\n",
    "print(\"end_time: \", score.end())\n",
    "print(score.tempos)\n",
    "print(score.key_signatures)\n",
    "print(score.time_signatures)\n",
    "\n",
    "score.time_signatures = TimeSignatureTickList([TimeSignature(time=0, numerator=4, denominator=4)])\n",
    "\n",
    "print(score.time_signatures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
