{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6405,"status":"ok","timestamp":1720350493956,"user":{"displayName":"Marco Bortolotti","userId":"16205829590380891051"},"user_tz":-120},"id":"em9mWQxF-fCK","outputId":"b6f25bad-6d9a-45d9-aa52-7468830a096d"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n","c:\\Users\\Gianni\\Desktop\\MARCO\\UNI\\Magistrale\\TESI\\Code\\TCN\n"]}],"source":["import glob\n","import numpy as np\n","import pandas as pd\n","import os\n","import time\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import numpy as np\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, random_split\n","import matplotlib.pyplot as plt\n","import yaml\n","import sys\n","sys.path.append('..')\n","from APPLICATION.model.tokenization import PrettyMidiTokenizer, BCI_TOKENS\n","from APPLICATION.model.model import TCN\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","pd.set_option('display.max_rows',500)\n","pd.set_option('display.max_columns',504)\n","pd.set_option('display.width',1000)\n","\n","\n","# MODEL PARAMETERS\n","EPOCHS = 500 # 500\n","LEARNING_RATE = 1 # 4\n","BATCH_SIZE = 4 # 16\n","TRAIN_MODEL = True\n","FEEDBACK = False\n","EMPHASIZE_EEG = True\n","EARLY_STOP = True\n","\n","pwd = os.getcwd()\n","print(pwd)\n","\n","DIRECTORY_PATH = ''\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6673,"status":"ok","timestamp":1720350500624,"user":{"displayName":"Marco Bortolotti","userId":"16205829590380891051"},"user_tz":-120},"id":"q-xf9JjP-fCM","outputId":"106f73f2-f24a-4b1b-e086-67277f52054b"},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset\n","Number of input files: 6\n","Number of output files: 6 \n","\n","1: 0_Drum_HardRock_EXCITED.mid -> 0_Bass_HardRock_EXCITED.mid\n","Input sequence length: 26\n","Emotion token: C\n","\n","2: 1_Drum_HardRock_EXCITED.mid -> 1_Bass_HardRock_EXCITED.mid\n","Input sequence length: 32\n","Emotion token: C\n","\n","3: 2_Drum_Blues_EXCITED.mid -> 2_Bass_Blues_EXCITED.mid\n","Input sequence length: 20\n","Emotion token: C\n","\n","4: 3_Drum_Blues_EXCITED.mid -> 3_Bass_Blues_EXCITED.mid\n","Input sequence length: 20\n","Emotion token: C\n","\n","5: 4_Drum_PopRock_RELAX.mid -> 4_Bass_PopRock_RELAX.mid\n","Input sequence length: 35\n","Emotion token: R\n","\n","6: 5_Drum_PopRock_RELAX.mid -> 5_Bass_PopRock_RELAX.mid\n","Input sequence length: 23\n","Emotion token: R\n","\n","\n","Number of input sequences: 171\n","Input sequence length: 192\n","Input vocabulars size: 102\n","\n","Number of output sequences: 171\n","Output sequence length: 192\n","Output vocabulars size: 87\n","\n","Input vocab: {'O': 0, 'R': 1, 'C': 2, '36fS': 3, '36f': 4, '36f_42pS': 5, '38fS': 6, '38f': 7, '38f_42pS': 8, '36fS_42fS': 9, '38fS_42fS': 10, '38f_42fS': 11, '38f_42f': 12, '36f_36fS_42pS': 13, '38f_42p': 14, '36f_42f': 15, '36fS_42f_42pS': 16, '36f_42f_42p': 17, '38f_42f_42pS': 18, '42f_42pS': 19, '42f_42p': 20, '36f_42fS': 21, '42pS': 22, '42p': 23, '36fS_42f': 24, '36f_42p': 25, '38fS_42p': 26, '38f_42fS_42p': 27, '36f_36fS': 28, '36f_36f_42pS': 29, '36f_42f_42pS': 30, '36fS_38f_42pS': 31, '36f_38fS_42fS': 32, '42f_42fS': 33, '42f_42f': 34, '38fS_42f_42fS': 35, '38f_42f_42f': 36, '36fS_38f': 37, '36f_38f_42pS': 38, '36fS_42p': 39, '36f_38fS_42f_42fS': 40, '36fS_42pS': 41, '38f_42f_42fS': 42, '42fS': 43, '42f': 44, '36fS_42f_42fS': 45, '36f_42f_42fS': 46, '36f_36fS_42fS': 47, '36fS_38f_42f_42fS': 48, '36f_38f_42f_42f': 49, '38pS_42fS': 50, '38p_42f': 51, '36fS_38f_42f': 52, '36f_38f_42f_42pS': 53, '36fS_38f_42f_42pS': 54, '38fS_42pS': 55, '36pS': 56, '36p': 57, '36p_36pS': 58, '36p_36p': 59, '36pS_42pS': 60, '36f_36f': 61, '36p_38fS_42pS': 62, '36f_36fS_42p': 63, '36f_36f_42p_42pS': 64, '36fS_36p': 65, '38pS': 66, '38p': 67, '38pS_42pS': 68, '36f_36fS_42f': 69, '36f_38fS_42p': 70, '36f_38fS': 71, '36f_38f_42fS': 72, '42fS_42p': 73, '36f_36fS_42f_42pS': 74, '36fS_42fS_42p': 75, '38pS_42p': 76, '38p_42fS_42p': 77, '38p_42pS': 78, '36f_36f_42fS': 79, '36f_42fS_42p': 80, '38f_42f_42p': 81, '38fS_42fS_42p': 82, '38fS_42f': 83, '36f_38fS_42fS_42p': 84, '36f_38f_42f_42p': 85, '36f_38f_42fS_42p': 86, '36f_42f_42f': 87, '36f_38fS_42f': 88, '36f_38f_42f_42fS': 89, '36f_38f': 90, '38pS_42fS_42p': 91, '38p_42f_42p': 92, '36f_38pS_42fS': 93, '36f_38p_42f': 94, '36fS_42p_42pS': 95, '36f_42p_42p': 96, '36f_38f_42f': 97, '38f_38pS_42f': 98, '38f_38p_42f': 99, '38f_38p_42f_42pS': 100, '38p_42p': 101}\n","Output vocab: {'O': 0, '52fS': 1, '52f': 2, '55fS': 3, '55f': 4, '45fS': 5, '45f': 6, '48fS': 7, '48f': 8, '47fS': 9, '47f': 10, '43fS': 11, '43f': 12, '57fS': 13, '57f': 14, '50fS': 15, '50f': 16, '40fS': 17, '40f': 18, '52pS': 19, '52p': 20, '48pS': 21, '48p': 22, '43pS': 23, '43p': 24, '47pS': 25, '47p': 26, '67pS': 27, '67p': 28, '50pS': 29, '50p': 30, '40pS': 31, '40p': 32, '55pS': 33, '55p': 34, '59pS': 35, '59p': 36, '62pS': 37, '62p': 38, '60pS': 39, '60p': 40, '57pS': 41, '57p': 42, '53pS': 43, '53p': 44, '64pS': 45, '64p': 46, '45pS': 47, '45p': 48, '56fS': 49, '56f': 50, '59fS': 51, '59f': 52, '49fS': 53, '49f': 54, '51fS': 55, '51f': 56, '54fS': 57, '54f': 58, '58fS': 59, '58f': 60, '63fS': 61, '63f': 62, '64fS': 63, '64f': 64, '66fS': 65, '66f': 66, '61fS': 67, '61f': 68, '62fS': 69, '62f': 70, '56pS': 71, '56p': 72, '49pS': 73, '49p': 74, '51pS': 75, '51p': 76, '54pS': 77, '54p': 78, '58pS': 79, '58p': 80, '63pS': 81, '63p': 82, '66pS': 83, '66p': 84, '61pS': 85, '61p': 86}\n"]}],"source":["'''\n","Assumptions:\n","Sequences described as input_#.mid and output_#.mid in the corresponding folders\n","'''\n","DATASET_PATH = os.path.join(DIRECTORY_PATH, 'dataset')\n","\n","print(DATASET_PATH)\n","\n","input_filenames = sorted(glob.glob(os.path.join(DATASET_PATH, 'input/*.mid')))\n","print('Number of input files:', len(input_filenames))\n","\n","output_filenames = sorted(glob.glob(os.path.join(DATASET_PATH, 'output/*.mid')))\n","print('Number of output files:', len(output_filenames), '\\n')\n","\n","\n","INPUT_TOK = PrettyMidiTokenizer(eeg = True)\n","OUTPUT_TOK = PrettyMidiTokenizer()\n","\n","for i, (in_file, out_file) in enumerate(zip(input_filenames, output_filenames)):\n","\n","    in_file_name = os.path.basename(in_file)\n","    out_file_name = os.path.basename(out_file)\n","    print(f'{i + 1}: {in_file_name} -> {out_file_name}')\n","\n","    if 'RELAX' in in_file_name:\n","        emotion_token = BCI_TOKENS['relaxed']\n","    elif 'EXCITED' in in_file_name:\n","        emotion_token = BCI_TOKENS['concentrated']\n","    else:\n","        raise Exception('Emotion not found in file name. Please add the emotion to the file name.')\n","\n","    in_seq, in_df = INPUT_TOK.midi_to_tokens(in_file, update_vocab=True, update_sequences=True, emotion_token = emotion_token)\n","    out_seq, out_df = OUTPUT_TOK.midi_to_tokens(out_file, update_vocab=True, update_sequences=True)\n","\n","    print(f'Input sequence length: {len(in_seq)}')\n","    print(f'Emotion token: {emotion_token}\\n')\n","\n","print(f'\\nNumber of input sequences: {len(INPUT_TOK.sequences)}')\n","print(f'Input sequence length: {len(INPUT_TOK.sequences[0])}')\n","print(f'Input vocabulars size: {len(INPUT_TOK.VOCAB)}')\n","print(f'\\nNumber of output sequences: {len(OUTPUT_TOK.sequences)}')\n","print(f'Output sequence length: {len(OUTPUT_TOK.sequences[0])}')\n","print(f'Output vocabulars size: {len(OUTPUT_TOK.VOCAB)}')\n","\n","print('\\nInput vocab:', INPUT_TOK.VOCAB.word2idx)\n","print('Output vocab:', OUTPUT_TOK.VOCAB.word2idx)\n","\n","with open('training_seq.txt', 'w') as f:    \n","    for seq in INPUT_TOK.sequences:\n","        for tok in seq[:48]:\n","            f.write('\\\"' + INPUT_TOK.VOCAB.idx2word[tok] + '\\\", ')\n","        f.write('\\n')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1720350500625,"user":{"displayName":"Marco Bortolotti","userId":"16205829590380891051"},"user_tz":-120},"id":"R3Tzfm6bUu-Q","outputId":"2e05dd2d-456d-4468-c135-969c2c0074ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Number of input sequences after data augmentation: 1197\n","Number of output sequences after data augmentation: 1197\n"]}],"source":["# Perform data augmentation\n","input_shifts = [-3, -2, -1, 1, 2, 3]\n","output_shifts = list(np.zeros(len(input_shifts)))\n","\n","INPUT_TOK.data_augmentation_shift(input_shifts)\n","OUTPUT_TOK.data_augmentation_shift(output_shifts)\n","\n","print(f'\\nNumber of input sequences after data augmentation: {len(INPUT_TOK.sequences)}')\n","print(f'Number of output sequences after data augmentation: {len(OUTPUT_TOK.sequences)}')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":539,"status":"ok","timestamp":1720350501148,"user":{"displayName":"Marco Bortolotti","userId":"16205829590380891051"},"user_tz":-120},"id":"TZ_LJL_F-fCN","outputId":"8031d1db-eddd-4add-9a47-b05fd05b2d2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set size: 958\n","Evaluation set size: 120\n","Test set size: 119\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Gianni\\AppData\\Local\\Temp\\ipykernel_15220\\1239450841.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n","  dataset = TensorDataset(torch.LongTensor(INPUT_TOK.sequences).to(device),\n"]}],"source":["# Create the dataset\n","dataset = TensorDataset(torch.LongTensor(INPUT_TOK.sequences).to(device),\n","                        torch.LongTensor(OUTPUT_TOK.sequences).to(device))\n","\n","# Split the dataset into training, evaluation and test sets\n","train_set, eval_set, test_set = random_split(dataset, [0.8, 0.1, 0.1])\n","\n","def initialize_dataset():\n","\n","  # Create the dataloaders\n","  train_sampler = RandomSampler(train_set)\n","  train_dataloader = DataLoader(train_set, sampler=train_sampler, batch_size=BATCH_SIZE)\n","\n","  eval_sampler = RandomSampler(eval_set)\n","  eval_dataloader = DataLoader(eval_set, sampler=eval_sampler, batch_size=BATCH_SIZE)\n","\n","  test_sampler = RandomSampler(test_set)\n","  test_dataloader = DataLoader(test_set, sampler=test_sampler, batch_size=BATCH_SIZE)\n","\n","  return train_dataloader, eval_dataloader, test_dataloader\n","\n","train_dataloader, eval_dataloader, test_dataloader = initialize_dataset()\n","\n","print(f'Train set size: {len(train_set)}')\n","print(f'Evaluation set size: {len(eval_set)}')\n","print(f'Test set size: {len(test_set)}')\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3117,"status":"ok","timestamp":1720350504263,"user":{"displayName":"Marco Bortolotti","userId":"16205829590380891051"},"user_tz":-120},"id":"BIzI5qkM-fCO","outputId":"7de9c3de-a426-4484-8487-c62ae3855b99"},"outputs":[{"name":"stdout","output_type":"stream","text":["O: 0.7447054982185364\n","52fS: 0.9925934672355652\n","52f: 0.9568337202072144\n","55fS: 0.9973382949829102\n","55f: 0.9865756034851074\n","45fS: 0.9981483817100525\n","45f: 0.9897002577781677\n","48fS: 0.9946765303611755\n","48f: 0.9550977945327759\n","47fS: 0.9942136406898499\n","47f: 0.9685221910476685\n","43fS: 0.9954866170883179\n","43f: 0.9571808576583862\n","57fS: 0.997569739818573\n","57f: 0.9818308353424072\n","50fS: 0.9929406046867371\n","50f: 0.9333410263061523\n","40fS: 0.9968753457069397\n","40f: 0.9849554300308228\n","52pS: 0.9897002577781677\n","52p: 0.9525517821311951\n","48pS: 0.9937507510185242\n","48p: 0.9606527090072632\n","43pS: 0.9950237274169922\n","43p: 0.9653975367546082\n","47pS: 0.9960652589797974\n","47p: 0.9798634648323059\n","67pS: 0.9990741610527039\n","67p: 0.9974539875984192\n","50pS: 0.9946765303611755\n","50p: 0.9538248181343079\n","40pS: 0.9986112713813782\n","40p: 0.9906260967254639\n","55pS: 0.9962967038154602\n","55p: 0.9863441586494446\n","59pS: 0.9961810111999512\n","59p: 0.9812521934509277\n","62pS: 0.9982640743255615\n","62p: 0.9930563569068909\n","60pS: 0.998842716217041\n","60p: 0.9958338141441345\n","57pS: 0.9966439008712769\n","57p: 0.9781275391578674\n","53pS: 0.9998842477798462\n","53p: 0.9998842477798462\n","64pS: 0.9995371103286743\n","64p: 0.997685432434082\n","45pS: 0.9983798265457153\n","45p: 0.990394651889801\n","56fS: 0.9984955191612244\n","56f: 0.9853026270866394\n","59fS: 0.9980326294898987\n","59f: 0.9880800843238831\n","49fS: 0.9993056654930115\n","49f: 0.9935192465782166\n","51fS: 0.9991899132728577\n","51f: 0.994097888469696\n","54fS: 0.9997685551643372\n","54f: 0.997685432434082\n","58fS: 0.9998842477798462\n","58f: 0.9989584684371948\n","63fS: 0.9997685551643372\n","63f: 0.997685432434082\n","64fS: 0.9997685551643372\n","64f: 0.9983798265457153\n","66fS: 0.9998842477798462\n","66f: 0.9993056654930115\n","61fS: 0.9998842477798462\n","61f: 0.998842716217041\n","62fS: 0.9998842477798462\n","62f: 0.998842716217041\n","56pS: 0.9984955191612244\n","56p: 0.9853026270866394\n","49pS: 0.9993056654930115\n","49p: 0.9935192465782166\n","51pS: 0.9991899132728577\n","51p: 0.994097888469696\n","54pS: 0.9998842477798462\n","54p: 0.9989584684371948\n","58pS: 0.9998842477798462\n","58p: 0.9989584684371948\n","63pS: 0.9997685551643372\n","63p: 0.997685432434082\n","66pS: 0.9998842477798462\n","66p: 0.9993056654930115\n","61pS: 0.9998842477798462\n","61p: 0.998842716217041\n","\n","Model created: TCN(\n","  (encoder): Embedding(102, 20, padding_idx=0)\n","  (tcn): TemporalConvNet(\n","    (network): Sequential(\n","      (0): TemporalBlock(\n","        (conv1): Conv1d(20, 192, kernel_size=(3,), stride=(1,), padding=(2,))\n","        (chomp1): Chomp1d()\n","        (relu1): ReLU()\n","        (dropout1): Dropout(p=0.45, inplace=False)\n","        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(2,))\n","        (chomp2): Chomp1d()\n","        (relu2): ReLU()\n","        (dropout2): Dropout(p=0.45, inplace=False)\n","        (net): Sequential(\n","          (0): Conv1d(20, 192, kernel_size=(3,), stride=(1,), padding=(2,))\n","          (1): Chomp1d()\n","          (2): ReLU()\n","          (3): Dropout(p=0.45, inplace=False)\n","          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(2,))\n","          (5): Chomp1d()\n","          (6): ReLU()\n","          (7): Dropout(p=0.45, inplace=False)\n","        )\n","        (downsample): Conv1d(20, 192, kernel_size=(1,), stride=(1,))\n","        (relu): ReLU()\n","      )\n","      (1): TemporalBlock(\n","        (conv1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n","        (chomp1): Chomp1d()\n","        (relu1): ReLU()\n","        (dropout1): Dropout(p=0.45, inplace=False)\n","        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n","        (chomp2): Chomp1d()\n","        (relu2): ReLU()\n","        (dropout2): Dropout(p=0.45, inplace=False)\n","        (net): Sequential(\n","          (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n","          (1): Chomp1d()\n","          (2): ReLU()\n","          (3): Dropout(p=0.45, inplace=False)\n","          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n","          (5): Chomp1d()\n","          (6): ReLU()\n","          (7): Dropout(p=0.45, inplace=False)\n","        )\n","        (relu): ReLU()\n","      )\n","      (2): TemporalBlock(\n","        (conv1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n","        (chomp1): Chomp1d()\n","        (relu1): ReLU()\n","        (dropout1): Dropout(p=0.45, inplace=False)\n","        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n","        (chomp2): Chomp1d()\n","        (relu2): ReLU()\n","        (dropout2): Dropout(p=0.45, inplace=False)\n","        (net): Sequential(\n","          (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n","          (1): Chomp1d()\n","          (2): ReLU()\n","          (3): Dropout(p=0.45, inplace=False)\n","          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n","          (5): Chomp1d()\n","          (6): ReLU()\n","          (7): Dropout(p=0.45, inplace=False)\n","        )\n","        (relu): ReLU()\n","      )\n","      (3): TemporalBlock(\n","        (conv1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n","        (chomp1): Chomp1d()\n","        (relu1): ReLU()\n","        (dropout1): Dropout(p=0.45, inplace=False)\n","        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n","        (chomp2): Chomp1d()\n","        (relu2): ReLU()\n","        (dropout2): Dropout(p=0.45, inplace=False)\n","        (net): Sequential(\n","          (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n","          (1): Chomp1d()\n","          (2): ReLU()\n","          (3): Dropout(p=0.45, inplace=False)\n","          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n","          (5): Chomp1d()\n","          (6): ReLU()\n","          (7): Dropout(p=0.45, inplace=False)\n","        )\n","        (relu): ReLU()\n","      )\n","      (4): TemporalBlock(\n","        (conv1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n","        (chomp1): Chomp1d()\n","        (relu1): ReLU()\n","        (dropout1): Dropout(p=0.45, inplace=False)\n","        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n","        (chomp2): Chomp1d()\n","        (relu2): ReLU()\n","        (dropout2): Dropout(p=0.45, inplace=False)\n","        (net): Sequential(\n","          (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n","          (1): Chomp1d()\n","          (2): ReLU()\n","          (3): Dropout(p=0.45, inplace=False)\n","          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n","          (5): Chomp1d()\n","          (6): ReLU()\n","          (7): Dropout(p=0.45, inplace=False)\n","        )\n","        (relu): ReLU()\n","      )\n","      (5): TemporalBlock(\n","        (conv1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n","        (chomp1): Chomp1d()\n","        (relu1): ReLU()\n","        (dropout1): Dropout(p=0.45, inplace=False)\n","        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n","        (chomp2): Chomp1d()\n","        (relu2): ReLU()\n","        (dropout2): Dropout(p=0.45, inplace=False)\n","        (net): Sequential(\n","          (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n","          (1): Chomp1d()\n","          (2): ReLU()\n","          (3): Dropout(p=0.45, inplace=False)\n","          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n","          (5): Chomp1d()\n","          (6): ReLU()\n","          (7): Dropout(p=0.45, inplace=False)\n","        )\n","        (relu): ReLU()\n","      )\n","      (6): TemporalBlock(\n","        (conv1): Conv1d(192, 20, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n","        (chomp1): Chomp1d()\n","        (relu1): ReLU()\n","        (dropout1): Dropout(p=0.45, inplace=False)\n","        (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n","        (chomp2): Chomp1d()\n","        (relu2): ReLU()\n","        (dropout2): Dropout(p=0.45, inplace=False)\n","        (net): Sequential(\n","          (0): Conv1d(192, 20, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n","          (1): Chomp1d()\n","          (2): ReLU()\n","          (3): Dropout(p=0.45, inplace=False)\n","          (4): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n","          (5): Chomp1d()\n","          (6): ReLU()\n","          (7): Dropout(p=0.45, inplace=False)\n","        )\n","        (downsample): Conv1d(192, 20, kernel_size=(1,), stride=(1,))\n","        (relu): ReLU()\n","      )\n","    )\n","  )\n","  (decoder): Linear(in_features=20, out_features=87, bias=True)\n","  (drop): Dropout(p=0.25, inplace=False)\n",")\n","tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n","        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n","        0.1000, 0.1000], grad_fn=<SelectBackward0>)\n"]}],"source":["# Set the hyperparameters\n","SEED = 1111\n","torch.manual_seed(SEED)\n","\n","'''\n","IMPORTANT:\n","to cover all the sequence of tokens k * d must be >= hidden units (see the paper)\n","k = kernel_size\n","d = dilation = 2 ^ (n_levels - 1)\n","'''\n","\n","OUTPUT_SIZE = len(OUTPUT_TOK.VOCAB)\n","\n","if FEEDBACK:\n","    INPUT_SIZE = len(INPUT_TOK.VOCAB) + OUTPUT_SIZE\n","    LEVELS = 8\n","    HIDDEN_UNITS = INPUT_TOK.SEQ_LENGTH * 2 # 192 * 2 = 384\n","else:\n","    INPUT_SIZE = len(INPUT_TOK.VOCAB)\n","    LEVELS = 7\n","    HIDDEN_UNITS = INPUT_TOK.SEQ_LENGTH # 192\n","\n","\n","EMBEDDING_SIZE = 20 # size of word embeddings -> Embedding() is used to encode input token into [192, 20] real value vectors (see model.py)\n","NUM_CHANNELS = [HIDDEN_UNITS] * (LEVELS - 1) + [EMBEDDING_SIZE] # [192, 192, 192, 192, 192, 192, 20]\n","GRADIENT_CLIP = 0.35\n","\n","\n","# balance the loss function by assigning a weight to each token related to its frequency\n","LOSS_WEIGTHS = torch.ones([OUTPUT_SIZE], dtype=torch.float, device = device)\n","OUTPUT_TOK.VOCAB.compute_weights()\n","for i, weigth in enumerate(OUTPUT_TOK.VOCAB.weights):\n","    LOSS_WEIGTHS[i] = 1 - weigth\n","    print(f'{OUTPUT_TOK.VOCAB.idx2word[i]}: {LOSS_WEIGTHS[i]}')\n","\n","\n","def initialize_model():\n","  # create the model\n","  model = TCN(input_size = INPUT_SIZE,\n","              embedding_size = EMBEDDING_SIZE,\n","              output_size = OUTPUT_SIZE,\n","              num_channels = NUM_CHANNELS,\n","              emphasize_eeg = EMPHASIZE_EEG,\n","              dropout = 0.45,\n","              emb_dropout = 0.25,\n","              kernel_size = 3,\n","              tied_weights = False) # tie encoder and decoder weights (legare)\n","\n","  model.to(device)\n","\n","  # May use adaptive softmax to speed up training\n","  criterion = nn.CrossEntropyLoss(weight = LOSS_WEIGTHS)\n","  optimizer = getattr(optim, 'SGD')(model.parameters(), lr=LEARNING_RATE)\n","\n","  return model, criterion, optimizer\n","\n","model, criterion, optimizer = initialize_model()\n","\n","print(f'\\nModel created: {model}')\n","print(model.encoder.weight[0])\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"tLO23hB8-fCP"},"outputs":[],"source":["def save_parameters():\n","\n","    # plot the losses over the epochs\n","\n","    plt.plot(train_losses, label='train')\n","    plt.plot(eval_losses, label='eval')\n","    plt.legend()\n","    plt.savefig(os.path.join(RESULTS_PATH, 'losses.png'))\n","    plt.clf()\n","\n","    # save the vocabularies\n","    INPUT_TOK.VOCAB.save(os.path.join(RESULTS_PATH, 'input_vocab.txt'))\n","    OUTPUT_TOK.VOCAB.save(os.path.join(RESULTS_PATH, 'output_vocab.txt'))\n","\n","     # save the model hyperparameters in a file txt\n","    with open(os.path.join(RESULTS_PATH, 'model_hyperparameters.txt'), 'w') as f:\n","\n","        f.write(f'DATE: {time.strftime(\"%Y%m%d-%H%M%S\")}\\n\\n')\n","\n","        f.write(f'-----------------DATASET------------------\\n')\n","        f.write(f'DATASET_PATH: {DATASET_PATH}\\n')\n","        f.write(f'TRAIN_SET_SIZE: {len(train_set)}\\n')\n","        f.write(f'EVAL_SET_SIZE: {len(eval_set)}\\n')\n","        f.write(f'TEST_SET_SIZE: {len(test_set)}\\n\\n')\n","\n","\n","        f.write(f'----------OPTIMIZATION PARAMETERS----------\\n')\n","        f.write(f'GRADIENT_CLIP: {GRADIENT_CLIP}\\n')\n","        f.write(f'FEEDBACK: {FEEDBACK}\\n')\n","        f.write(f'EARLY STOPPING: {EARLY_STOP}\\n')\n","        f.write(f'EMPHASIZE_EEG: {EMPHASIZE_EEG}\\n')\n","        f.write(f'LEARNING_RATE: {LEARNING_RATE}\\n')\n","        f.write(f'BATCH_SIZE: {BATCH_SIZE}\\n')\n","        f.write(f'EPOCHS: {EPOCHS}\\n\\n')\n","\n","\n","        f.write(f'------------MODEL PARAMETERS--------------\\n')\n","        f.write(f'SEED: {SEED}\\n')\n","        f.write(f'INPUT_SIZE: {INPUT_SIZE}\\n')\n","        f.write(f'EMBEDDING_SIZE: {EMBEDDING_SIZE}\\n')\n","        f.write(f'LEVELS: {LEVELS}\\n')\n","        f.write(f'HIDDEN_UNITS: {HIDDEN_UNITS}\\n')\n","        f.write(f'NUM_CHANNELS: {NUM_CHANNELS}\\n')\n","        f.write(f'OUTPUT_SIZE: {OUTPUT_SIZE}\\n')\n","        f.write(f'LOSS_WEIGTHS: {LOSS_WEIGTHS}\\n\\n')\n","\n","\n","\n","        f.write(f'-------------------RESULTS----------------\\n')\n","        f.write(f'TRAIN_LOSSES: {best_train_loss}\\n')\n","        f.write(f'BEST_EVAL_LOSS: {best_eval_loss}\\n')\n","        f.write(f'TEST_LOSS: {test_loss}\\n')\n","        f.write(f'BEST_MODEL_EPOCH: {best_model_epoch}\\n')\n","\n","    data = {\n","        'DATE': time.strftime(\"%Y%m%d-%H%M%S\"),\n","        'INPUT_SIZE': INPUT_SIZE,\n","        'EMBEDDING_SIZE': EMBEDDING_SIZE,\n","        'NUM_CHANNELS': NUM_CHANNELS,\n","        'OUTPUT_SIZE': OUTPUT_SIZE,\n","        'KERNEL_SIZE': 3\n","    }\n","\n","    path = os.path.join(RESULTS_PATH, 'config.yaml')\n","    with open(path, 'w') as file:\n","        yaml.safe_dump(data, file)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"8X0pPmwo-fCO"},"outputs":[],"source":["BAR_LENGTH = INPUT_TOK.BAR_LENGTH\n","\n","def epoch_step(dataloader, mode):\n","\n","    if FEEDBACK:\n","        prev_output = torch.zeros([BATCH_SIZE, INPUT_TOK.SEQ_LENGTH], dtype=torch.long, device=device)\n","\n","    if mode == 'train':\n","        model.train()\n","    else:\n","        model.eval() # disable dropout\n","\n","    total_loss = 0\n","\n","    # iterate over the training data\n","    for batch_idx, (data, targets) in enumerate(dataloader):\n","\n","        batch_idx += 1\n","\n","        # mask the last bar of the input data\n","        batch_size = data.size(0)\n","        data_masked = torch.cat((data[:, :BAR_LENGTH*3], torch.ones([batch_size, BAR_LENGTH], dtype=torch.long, device = device)), dim = 1)\n","\n","        if FEEDBACK:\n","            input = torch.cat((data_masked, prev_output[:batch_size, :]), dim = 1)\n","        else:\n","            input = data_masked\n","\n","        # reset model gradients to zero\n","        optimizer.zero_grad()\n","\n","        # make the prediction\n","        output = model(input)[:, :INPUT_TOK.SEQ_LENGTH]\n","        prev_output = torch.argmax(output, 2)# batch, seq_len (hidden units), vocab_size\n","\n","        # flatten the output sequence\n","        # NB: the size -1 is inferred from other dimensions\n","        # NB: contiguous() is used to make sure the tensor is stored in a contiguous chunk of memory, necessary for view() to work\n","\n","        final_target = targets.contiguous().view(-1)\n","        final_output = output.contiguous().view(-1, OUTPUT_SIZE)\n","\n","        # calculate the loss\n","        loss = criterion(final_output, final_target)\n","\n","        if mode == 'train':\n","            # calculate the gradients\n","            loss.backward()\n","\n","            # clip the gradients to avoid exploding gradients\n","            if GRADIENT_CLIP > 0:\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n","\n","            # update the weights\n","            optimizer.step()\n","\n","        total_loss += loss.data.item()\n","\n","    return total_loss / len(dataloader)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"2yimq9Xg-fCP"},"outputs":[],"source":["def train(results_path = None):\n","\n","    global RESULTS_PATH, MODEL_PATH\n","    global best_eval_loss, best_train_loss, best_model_epoch, train_losses, eval_losses\n","\n","    if results_path is None:\n","        RESULTS_PATH = os.path.join('results', time.strftime(\"%Y%m%d_%H%M%S\"))\n","    else:\n","        RESULTS_PATH = results_path\n","    \n","    if not os.path.exists(RESULTS_PATH):\n","        os.makedirs(RESULTS_PATH)\n","\n","    MODEL_PATH = os.path.join(RESULTS_PATH, 'model_state_dict.pth')\n","\n","    best_eval_loss = 1e8\n","    best_train_loss = 1e8\n","    best_model_epoch = 0\n","    eval_losses = []\n","    train_losses = []\n","    lr = LEARNING_RATE\n","\n","    for epoch in range(1, EPOCHS+1):\n","\n","        start_time = time.time()\n","\n","        train_loss = epoch_step(train_dataloader, 'train')\n","\n","        eval_loss = epoch_step(eval_dataloader, 'eval')\n","\n","        # Save the model if the validation loss is the best we've seen so far.\n","        if eval_loss < best_eval_loss:\n","            torch.save(model.state_dict(), MODEL_PATH)\n","            best_eval_loss = eval_loss\n","            best_model_epoch = epoch\n","\n","        if train_loss < best_train_loss:\n","            best_train_loss = train_loss\n","\n","        # # Anneal the learning rate if the validation loss plateaus\n","        # if epoch > 5 and eval_loss >= max(eval_losses[-5:]):\n","        #     lr = lr / 2.\n","        #     if lr < 0.1:\n","        #         lr = 2\n","        #     for param_group in optimizer.param_groups:\n","        #         param_group['lr'] = lr\n","\n","\n","        eval_losses.append(eval_loss)\n","        train_losses.append(train_loss)\n","\n","        # Early stopping\n","        if EARLY_STOP:\n","          if epoch > 15:\n","              if min(eval_losses[-15:]) > best_eval_loss:\n","                  break\n","\n","        # print the loss and the progress\n","        elapsed = time.time() - start_time\n","        print('| epoch {:3d}/{:3d} | lr {:02.5f} | ms/epoch {:5.5f} | train_loss {:5.2f} | eval_loss {:5.2f}' \\\n","                .format(epoch, EPOCHS, lr, elapsed * 1000, train_loss, eval_loss))\n","\n","\n","    print('\\n\\n TRAINING FINISHED:\\n\\n\\tBest Loss: {:5.2f}\\tBest Model saved at epoch: {:3d} \\n\\n' \\\n","            .format(best_eval_loss, best_model_epoch))\n","\n","\n","    # test the model\n","    global test_loss\n","    test_loss = epoch_step(test_dataloader, 'eval')\n","    print(f'\\n\\nTEST LOSS: {test_loss}')\n","\n","    save_parameters()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2641510,"status":"ok","timestamp":1720355202428,"user":{"displayName":"Marco Bortolotti","userId":"16205829590380891051"},"user_tz":-120},"id":"EN4N3Ob3a4Gh","outputId":"e089bc58-d5ba-4738-b140-2a9897a5001a"},"outputs":[{"name":"stdout","output_type":"stream","text":["| epoch   1/500 | lr 2.00000 | ms/epoch 2705.51252 | train_loss  3.48 | eval_loss  3.53\n","| epoch   2/500 | lr 2.00000 | ms/epoch 2687.58941 | train_loss  3.34 | eval_loss  3.28\n","| epoch   3/500 | lr 2.00000 | ms/epoch 2597.70441 | train_loss  3.15 | eval_loss  3.13\n","| epoch   4/500 | lr 2.00000 | ms/epoch 2639.49633 | train_loss  3.01 | eval_loss  3.37\n","| epoch   5/500 | lr 2.00000 | ms/epoch 2740.63635 | train_loss  2.95 | eval_loss  3.10\n","| epoch   6/500 | lr 2.00000 | ms/epoch 2636.67393 | train_loss  2.86 | eval_loss  2.82\n","| epoch   7/500 | lr 2.00000 | ms/epoch 2643.39328 | train_loss  2.75 | eval_loss  2.69\n","| epoch   8/500 | lr 2.00000 | ms/epoch 2591.90536 | train_loss  2.63 | eval_loss  2.79\n","| epoch   9/500 | lr 2.00000 | ms/epoch 2671.51642 | train_loss  2.54 | eval_loss  2.45\n","| epoch  10/500 | lr 2.00000 | ms/epoch 2709.18822 | train_loss  2.47 | eval_loss  2.43\n","| epoch  11/500 | lr 2.00000 | ms/epoch 2692.83223 | train_loss  2.41 | eval_loss  2.26\n","| epoch  12/500 | lr 2.00000 | ms/epoch 2723.71030 | train_loss  2.36 | eval_loss  2.18\n","| epoch  13/500 | lr 2.00000 | ms/epoch 2855.23748 | train_loss  2.31 | eval_loss  2.13\n","| epoch  14/500 | lr 2.00000 | ms/epoch 2618.13450 | train_loss  2.26 | eval_loss  2.14\n","| epoch  15/500 | lr 2.00000 | ms/epoch 2585.46758 | train_loss  2.21 | eval_loss  2.02\n","| epoch  16/500 | lr 2.00000 | ms/epoch 2563.38644 | train_loss  2.16 | eval_loss  2.03\n","| epoch  17/500 | lr 2.00000 | ms/epoch 2639.72735 | train_loss  2.12 | eval_loss  1.96\n","| epoch  18/500 | lr 2.00000 | ms/epoch 2570.96577 | train_loss  2.08 | eval_loss  1.93\n","| epoch  19/500 | lr 2.00000 | ms/epoch 2541.25762 | train_loss  2.03 | eval_loss  1.89\n","| epoch  20/500 | lr 2.00000 | ms/epoch 2606.39787 | train_loss  1.99 | eval_loss  1.81\n","| epoch  21/500 | lr 2.00000 | ms/epoch 2536.01336 | train_loss  1.95 | eval_loss  1.71\n","| epoch  22/500 | lr 2.00000 | ms/epoch 2606.95338 | train_loss  1.90 | eval_loss  1.66\n","| epoch  23/500 | lr 2.00000 | ms/epoch 3315.05942 | train_loss  1.88 | eval_loss  1.62\n","| epoch  24/500 | lr 2.00000 | ms/epoch 4508.08740 | train_loss  1.83 | eval_loss  1.64\n","| epoch  25/500 | lr 2.00000 | ms/epoch 3348.26732 | train_loss  1.79 | eval_loss  1.53\n","| epoch  26/500 | lr 2.00000 | ms/epoch 2574.99623 | train_loss  1.76 | eval_loss  1.49\n","| epoch  27/500 | lr 2.00000 | ms/epoch 2586.16877 | train_loss  1.72 | eval_loss  1.42\n","| epoch  28/500 | lr 2.00000 | ms/epoch 3946.74492 | train_loss  1.69 | eval_loss  1.42\n","| epoch  29/500 | lr 2.00000 | ms/epoch 4590.11865 | train_loss  1.65 | eval_loss  1.46\n","| epoch  30/500 | lr 2.00000 | ms/epoch 4360.66413 | train_loss  1.62 | eval_loss  1.31\n","| epoch  31/500 | lr 2.00000 | ms/epoch 2976.88770 | train_loss  1.60 | eval_loss  1.29\n","| epoch  32/500 | lr 2.00000 | ms/epoch 2561.94878 | train_loss  1.56 | eval_loss  1.28\n","| epoch  33/500 | lr 2.00000 | ms/epoch 2570.16063 | train_loss  1.53 | eval_loss  1.24\n","| epoch  34/500 | lr 2.00000 | ms/epoch 2563.84635 | train_loss  1.50 | eval_loss  1.21\n","| epoch  35/500 | lr 2.00000 | ms/epoch 2592.41223 | train_loss  1.47 | eval_loss  1.19\n","| epoch  36/500 | lr 2.00000 | ms/epoch 2567.34681 | train_loss  1.45 | eval_loss  1.19\n","| epoch  37/500 | lr 2.00000 | ms/epoch 2604.11572 | train_loss  1.43 | eval_loss  1.09\n","| epoch  38/500 | lr 2.00000 | ms/epoch 2579.23555 | train_loss  1.40 | eval_loss  1.09\n","| epoch  39/500 | lr 2.00000 | ms/epoch 2597.11480 | train_loss  1.38 | eval_loss  1.03\n","| epoch  40/500 | lr 2.00000 | ms/epoch 2649.91283 | train_loss  1.35 | eval_loss  1.03\n","| epoch  41/500 | lr 2.00000 | ms/epoch 2587.66723 | train_loss  1.33 | eval_loss  1.00\n","| epoch  42/500 | lr 2.00000 | ms/epoch 2602.72956 | train_loss  1.31 | eval_loss  0.98\n","| epoch  43/500 | lr 2.00000 | ms/epoch 2841.03131 | train_loss  1.29 | eval_loss  0.96\n","| epoch  44/500 | lr 2.00000 | ms/epoch 2615.23080 | train_loss  1.27 | eval_loss  0.94\n","| epoch  45/500 | lr 2.00000 | ms/epoch 2612.01048 | train_loss  1.25 | eval_loss  0.90\n","| epoch  46/500 | lr 2.00000 | ms/epoch 2620.41950 | train_loss  1.24 | eval_loss  0.89\n","| epoch  47/500 | lr 2.00000 | ms/epoch 2618.45040 | train_loss  1.22 | eval_loss  0.93\n","| epoch  48/500 | lr 2.00000 | ms/epoch 2647.94230 | train_loss  1.21 | eval_loss  0.87\n","| epoch  49/500 | lr 2.00000 | ms/epoch 2700.25539 | train_loss  1.20 | eval_loss  0.94\n","| epoch  50/500 | lr 2.00000 | ms/epoch 2574.86439 | train_loss  1.18 | eval_loss  0.81\n","| epoch  51/500 | lr 2.00000 | ms/epoch 2638.63754 | train_loss  1.16 | eval_loss  0.86\n","| epoch  52/500 | lr 2.00000 | ms/epoch 2714.50090 | train_loss  1.14 | eval_loss  0.85\n","| epoch  53/500 | lr 2.00000 | ms/epoch 2640.79976 | train_loss  1.14 | eval_loss  0.82\n","| epoch  54/500 | lr 2.00000 | ms/epoch 2587.47602 | train_loss  1.12 | eval_loss  0.79\n","| epoch  55/500 | lr 2.00000 | ms/epoch 2661.18598 | train_loss  1.11 | eval_loss  0.77\n","| epoch  56/500 | lr 2.00000 | ms/epoch 2641.32166 | train_loss  1.10 | eval_loss  0.76\n","| epoch  57/500 | lr 2.00000 | ms/epoch 2623.14701 | train_loss  1.09 | eval_loss  0.77\n","| epoch  58/500 | lr 2.00000 | ms/epoch 2578.31526 | train_loss  1.08 | eval_loss  0.79\n","| epoch  59/500 | lr 2.00000 | ms/epoch 2572.39151 | train_loss  1.07 | eval_loss  0.81\n","| epoch  60/500 | lr 2.00000 | ms/epoch 2588.24730 | train_loss  1.06 | eval_loss  0.74\n","| epoch  61/500 | lr 2.00000 | ms/epoch 2587.54730 | train_loss  1.04 | eval_loss  0.78\n","| epoch  62/500 | lr 2.00000 | ms/epoch 2597.73231 | train_loss  1.04 | eval_loss  0.72\n","| epoch  63/500 | lr 2.00000 | ms/epoch 2607.28836 | train_loss  1.03 | eval_loss  0.72\n","| epoch  64/500 | lr 2.00000 | ms/epoch 2569.92817 | train_loss  1.01 | eval_loss  0.81\n","| epoch  65/500 | lr 2.00000 | ms/epoch 2596.73524 | train_loss  1.01 | eval_loss  0.72\n","| epoch  66/500 | lr 2.00000 | ms/epoch 2568.98713 | train_loss  1.01 | eval_loss  0.75\n","| epoch  67/500 | lr 2.00000 | ms/epoch 2574.71323 | train_loss  1.00 | eval_loss  0.70\n","| epoch  68/500 | lr 2.00000 | ms/epoch 3983.93822 | train_loss  0.99 | eval_loss  0.69\n","| epoch  69/500 | lr 2.00000 | ms/epoch 3718.46700 | train_loss  0.98 | eval_loss  0.72\n","| epoch  70/500 | lr 2.00000 | ms/epoch 2595.16287 | train_loss  0.97 | eval_loss  0.67\n","| epoch  71/500 | lr 2.00000 | ms/epoch 2591.88294 | train_loss  0.96 | eval_loss  0.69\n","| epoch  72/500 | lr 2.00000 | ms/epoch 2585.46019 | train_loss  0.96 | eval_loss  0.72\n","| epoch  73/500 | lr 2.00000 | ms/epoch 2569.18311 | train_loss  0.95 | eval_loss  0.68\n","| epoch  74/500 | lr 2.00000 | ms/epoch 2672.61362 | train_loss  0.94 | eval_loss  0.66\n","| epoch  75/500 | lr 2.00000 | ms/epoch 2592.45229 | train_loss  0.94 | eval_loss  0.66\n","| epoch  76/500 | lr 2.00000 | ms/epoch 2562.45184 | train_loss  0.93 | eval_loss  0.61\n","| epoch  77/500 | lr 2.00000 | ms/epoch 2610.15081 | train_loss  0.92 | eval_loss  0.64\n","| epoch  78/500 | lr 2.00000 | ms/epoch 2598.08016 | train_loss  0.92 | eval_loss  0.62\n","| epoch  79/500 | lr 2.00000 | ms/epoch 2724.19500 | train_loss  0.92 | eval_loss  0.63\n","| epoch  80/500 | lr 2.00000 | ms/epoch 2539.59250 | train_loss  0.91 | eval_loss  0.62\n","| epoch  81/500 | lr 2.00000 | ms/epoch 2547.74880 | train_loss  0.90 | eval_loss  0.61\n","| epoch  82/500 | lr 2.00000 | ms/epoch 2625.30279 | train_loss  0.90 | eval_loss  0.62\n","| epoch  83/500 | lr 2.00000 | ms/epoch 2612.06269 | train_loss  0.89 | eval_loss  0.60\n","| epoch  84/500 | lr 2.00000 | ms/epoch 2586.25245 | train_loss  0.88 | eval_loss  0.65\n","| epoch  85/500 | lr 2.00000 | ms/epoch 2561.13815 | train_loss  0.89 | eval_loss  0.62\n","| epoch  86/500 | lr 2.00000 | ms/epoch 2590.59739 | train_loss  0.88 | eval_loss  0.59\n","| epoch  87/500 | lr 2.00000 | ms/epoch 2584.40852 | train_loss  0.88 | eval_loss  0.61\n","| epoch  88/500 | lr 2.00000 | ms/epoch 2545.42661 | train_loss  0.87 | eval_loss  0.60\n","| epoch  89/500 | lr 2.00000 | ms/epoch 2547.06144 | train_loss  0.86 | eval_loss  0.61\n","| epoch  90/500 | lr 2.00000 | ms/epoch 2560.04691 | train_loss  0.86 | eval_loss  0.59\n","| epoch  91/500 | lr 2.00000 | ms/epoch 2514.83893 | train_loss  0.86 | eval_loss  0.62\n","| epoch  92/500 | lr 2.00000 | ms/epoch 2496.80710 | train_loss  0.86 | eval_loss  0.57\n","| epoch  93/500 | lr 2.00000 | ms/epoch 2766.86549 | train_loss  0.85 | eval_loss  0.57\n","| epoch  94/500 | lr 2.00000 | ms/epoch 2609.77125 | train_loss  0.85 | eval_loss  0.57\n","| epoch  95/500 | lr 2.00000 | ms/epoch 2565.70745 | train_loss  0.84 | eval_loss  0.55\n","| epoch  96/500 | lr 2.00000 | ms/epoch 2580.30844 | train_loss  0.83 | eval_loss  0.59\n","| epoch  97/500 | lr 2.00000 | ms/epoch 2546.45538 | train_loss  0.84 | eval_loss  0.58\n","| epoch  98/500 | lr 2.00000 | ms/epoch 2568.67266 | train_loss  0.83 | eval_loss  0.56\n","| epoch  99/500 | lr 2.00000 | ms/epoch 2643.39948 | train_loss  0.83 | eval_loss  0.55\n","| epoch 100/500 | lr 2.00000 | ms/epoch 2609.82037 | train_loss  0.82 | eval_loss  0.55\n","| epoch 101/500 | lr 2.00000 | ms/epoch 2552.92153 | train_loss  0.82 | eval_loss  0.55\n","| epoch 102/500 | lr 2.00000 | ms/epoch 2568.67766 | train_loss  0.82 | eval_loss  0.58\n","| epoch 103/500 | lr 2.00000 | ms/epoch 2558.28118 | train_loss  0.81 | eval_loss  0.57\n","| epoch 104/500 | lr 2.00000 | ms/epoch 2534.75714 | train_loss  0.81 | eval_loss  0.55\n","| epoch 105/500 | lr 2.00000 | ms/epoch 2548.06089 | train_loss  0.81 | eval_loss  0.57\n","| epoch 106/500 | lr 2.00000 | ms/epoch 2564.72254 | train_loss  0.80 | eval_loss  0.53\n","| epoch 107/500 | lr 2.00000 | ms/epoch 2562.75249 | train_loss  0.80 | eval_loss  0.51\n","| epoch 108/500 | lr 2.00000 | ms/epoch 2536.24558 | train_loss  0.79 | eval_loss  0.56\n","| epoch 109/500 | lr 2.00000 | ms/epoch 2540.90214 | train_loss  0.79 | eval_loss  0.55\n","| epoch 110/500 | lr 2.00000 | ms/epoch 2576.85685 | train_loss  0.79 | eval_loss  0.53\n","| epoch 111/500 | lr 2.00000 | ms/epoch 2627.90585 | train_loss  0.79 | eval_loss  0.53\n","| epoch 112/500 | lr 2.00000 | ms/epoch 2541.54301 | train_loss  0.78 | eval_loss  0.55\n","| epoch 113/500 | lr 2.00000 | ms/epoch 2553.41673 | train_loss  0.78 | eval_loss  0.56\n","| epoch 114/500 | lr 2.00000 | ms/epoch 2568.54367 | train_loss  0.78 | eval_loss  0.50\n","| epoch 115/500 | lr 2.00000 | ms/epoch 2535.04777 | train_loss  0.77 | eval_loss  0.51\n","| epoch 116/500 | lr 2.00000 | ms/epoch 2562.64234 | train_loss  0.77 | eval_loss  0.53\n","| epoch 117/500 | lr 2.00000 | ms/epoch 2538.68818 | train_loss  0.77 | eval_loss  0.60\n","| epoch 118/500 | lr 2.00000 | ms/epoch 2547.93024 | train_loss  0.77 | eval_loss  0.55\n","| epoch 119/500 | lr 2.00000 | ms/epoch 2537.53877 | train_loss  0.77 | eval_loss  0.51\n","| epoch 120/500 | lr 2.00000 | ms/epoch 2538.32936 | train_loss  0.76 | eval_loss  0.55\n","| epoch 121/500 | lr 2.00000 | ms/epoch 2563.32231 | train_loss  0.76 | eval_loss  0.53\n","| epoch 122/500 | lr 2.00000 | ms/epoch 2614.48812 | train_loss  0.76 | eval_loss  0.53\n","| epoch 123/500 | lr 2.00000 | ms/epoch 2607.77116 | train_loss  0.76 | eval_loss  0.51\n","| epoch 124/500 | lr 2.00000 | ms/epoch 2585.17170 | train_loss  0.75 | eval_loss  0.50\n","| epoch 125/500 | lr 2.00000 | ms/epoch 2554.97003 | train_loss  0.75 | eval_loss  0.51\n","| epoch 126/500 | lr 2.00000 | ms/epoch 2590.77859 | train_loss  0.75 | eval_loss  0.50\n","| epoch 127/500 | lr 2.00000 | ms/epoch 2564.73184 | train_loss  0.75 | eval_loss  0.49\n","| epoch 128/500 | lr 2.00000 | ms/epoch 2557.21140 | train_loss  0.75 | eval_loss  0.49\n","| epoch 129/500 | lr 2.00000 | ms/epoch 2600.24381 | train_loss  0.74 | eval_loss  0.54\n","| epoch 130/500 | lr 2.00000 | ms/epoch 2590.03615 | train_loss  0.74 | eval_loss  0.49\n","| epoch 131/500 | lr 2.00000 | ms/epoch 2541.59021 | train_loss  0.74 | eval_loss  0.53\n","| epoch 132/500 | lr 2.00000 | ms/epoch 2564.48865 | train_loss  0.74 | eval_loss  0.49\n","| epoch 133/500 | lr 2.00000 | ms/epoch 2570.71590 | train_loss  0.74 | eval_loss  0.48\n","| epoch 134/500 | lr 2.00000 | ms/epoch 2563.20596 | train_loss  0.73 | eval_loss  0.51\n","| epoch 135/500 | lr 2.00000 | ms/epoch 2547.21045 | train_loss  0.73 | eval_loss  0.51\n","| epoch 136/500 | lr 2.00000 | ms/epoch 2597.58639 | train_loss  0.73 | eval_loss  0.47\n","| epoch 137/500 | lr 2.00000 | ms/epoch 2612.99038 | train_loss  0.72 | eval_loss  0.49\n","| epoch 138/500 | lr 2.00000 | ms/epoch 3947.26753 | train_loss  0.73 | eval_loss  0.52\n","| epoch 139/500 | lr 2.00000 | ms/epoch 4327.72851 | train_loss  0.72 | eval_loss  0.48\n","| epoch 140/500 | lr 2.00000 | ms/epoch 4171.75961 | train_loss  0.72 | eval_loss  0.48\n","| epoch 141/500 | lr 2.00000 | ms/epoch 2555.28021 | train_loss  0.72 | eval_loss  0.48\n","| epoch 142/500 | lr 2.00000 | ms/epoch 2666.55254 | train_loss  0.71 | eval_loss  0.49\n","| epoch 143/500 | lr 2.00000 | ms/epoch 2560.76932 | train_loss  0.71 | eval_loss  0.47\n","| epoch 144/500 | lr 2.00000 | ms/epoch 2611.66286 | train_loss  0.71 | eval_loss  0.49\n","| epoch 145/500 | lr 2.00000 | ms/epoch 2573.15660 | train_loss  0.71 | eval_loss  0.46\n","| epoch 146/500 | lr 2.00000 | ms/epoch 2558.94613 | train_loss  0.71 | eval_loss  0.52\n","| epoch 147/500 | lr 2.00000 | ms/epoch 2614.58397 | train_loss  0.71 | eval_loss  0.48\n","| epoch 148/500 | lr 2.00000 | ms/epoch 2570.10126 | train_loss  0.71 | eval_loss  0.44\n","| epoch 149/500 | lr 2.00000 | ms/epoch 2593.09840 | train_loss  0.71 | eval_loss  0.47\n","| epoch 150/500 | lr 2.00000 | ms/epoch 2524.83034 | train_loss  0.70 | eval_loss  0.47\n","| epoch 151/500 | lr 2.00000 | ms/epoch 2539.26086 | train_loss  0.70 | eval_loss  0.46\n","| epoch 152/500 | lr 2.00000 | ms/epoch 2566.75839 | train_loss  0.70 | eval_loss  0.49\n","| epoch 153/500 | lr 2.00000 | ms/epoch 2568.17818 | train_loss  0.70 | eval_loss  0.52\n","| epoch 154/500 | lr 2.00000 | ms/epoch 2542.09614 | train_loss  0.70 | eval_loss  0.46\n","| epoch 155/500 | lr 2.00000 | ms/epoch 2638.24534 | train_loss  0.70 | eval_loss  0.49\n","| epoch 156/500 | lr 2.00000 | ms/epoch 2577.75831 | train_loss  0.69 | eval_loss  0.45\n","| epoch 157/500 | lr 2.00000 | ms/epoch 2529.74153 | train_loss  0.69 | eval_loss  0.46\n","| epoch 158/500 | lr 2.00000 | ms/epoch 2551.82648 | train_loss  0.69 | eval_loss  0.45\n","| epoch 159/500 | lr 2.00000 | ms/epoch 2598.39821 | train_loss  0.69 | eval_loss  0.51\n","| epoch 160/500 | lr 2.00000 | ms/epoch 2552.05607 | train_loss  0.69 | eval_loss  0.46\n","| epoch 161/500 | lr 2.00000 | ms/epoch 2519.40989 | train_loss  0.68 | eval_loss  0.50\n","| epoch 162/500 | lr 2.00000 | ms/epoch 4032.82428 | train_loss  0.68 | eval_loss  0.48\n","| epoch 163/500 | lr 2.00000 | ms/epoch 4663.87105 | train_loss  0.68 | eval_loss  0.43\n","| epoch 164/500 | lr 2.00000 | ms/epoch 4681.07033 | train_loss  0.68 | eval_loss  0.45\n","| epoch 165/500 | lr 2.00000 | ms/epoch 4477.57959 | train_loss  0.68 | eval_loss  0.44\n","| epoch 166/500 | lr 2.00000 | ms/epoch 4778.66411 | train_loss  0.68 | eval_loss  0.43\n","| epoch 167/500 | lr 2.00000 | ms/epoch 2711.18069 | train_loss  0.68 | eval_loss  0.45\n","| epoch 168/500 | lr 2.00000 | ms/epoch 2588.81497 | train_loss  0.67 | eval_loss  0.45\n","| epoch 169/500 | lr 2.00000 | ms/epoch 2643.52989 | train_loss  0.67 | eval_loss  0.46\n","| epoch 170/500 | lr 2.00000 | ms/epoch 2626.19472 | train_loss  0.67 | eval_loss  0.47\n","| epoch 171/500 | lr 2.00000 | ms/epoch 2632.35211 | train_loss  0.68 | eval_loss  0.45\n","| epoch 172/500 | lr 2.00000 | ms/epoch 2615.44609 | train_loss  0.67 | eval_loss  0.43\n","| epoch 173/500 | lr 2.00000 | ms/epoch 2619.63892 | train_loss  0.67 | eval_loss  0.47\n","| epoch 174/500 | lr 2.00000 | ms/epoch 2716.83168 | train_loss  0.66 | eval_loss  0.43\n","| epoch 175/500 | lr 2.00000 | ms/epoch 2635.66637 | train_loss  0.67 | eval_loss  0.44\n","| epoch 176/500 | lr 2.00000 | ms/epoch 2558.95638 | train_loss  0.67 | eval_loss  0.42\n","| epoch 177/500 | lr 2.00000 | ms/epoch 2606.89664 | train_loss  0.67 | eval_loss  0.43\n","| epoch 178/500 | lr 2.00000 | ms/epoch 2634.15933 | train_loss  0.67 | eval_loss  0.45\n","| epoch 179/500 | lr 2.00000 | ms/epoch 4300.37761 | train_loss  0.66 | eval_loss  0.43\n","| epoch 180/500 | lr 2.00000 | ms/epoch 4695.63842 | train_loss  0.66 | eval_loss  0.42\n","| epoch 181/500 | lr 2.00000 | ms/epoch 3607.59878 | train_loss  0.66 | eval_loss  0.46\n","| epoch 182/500 | lr 2.00000 | ms/epoch 2609.68828 | train_loss  0.66 | eval_loss  0.45\n","| epoch 183/500 | lr 2.00000 | ms/epoch 2692.86203 | train_loss  0.66 | eval_loss  0.45\n","| epoch 184/500 | lr 2.00000 | ms/epoch 2702.53396 | train_loss  0.65 | eval_loss  0.46\n","| epoch 185/500 | lr 2.00000 | ms/epoch 2579.47445 | train_loss  0.66 | eval_loss  0.44\n","| epoch 186/500 | lr 2.00000 | ms/epoch 2543.15519 | train_loss  0.65 | eval_loss  0.50\n","| epoch 187/500 | lr 2.00000 | ms/epoch 2522.03608 | train_loss  0.65 | eval_loss  0.43\n","| epoch 188/500 | lr 2.00000 | ms/epoch 2544.55614 | train_loss  0.65 | eval_loss  0.41\n","| epoch 189/500 | lr 2.00000 | ms/epoch 2535.88462 | train_loss  0.65 | eval_loss  0.40\n","| epoch 190/500 | lr 2.00000 | ms/epoch 2525.47455 | train_loss  0.65 | eval_loss  0.51\n","| epoch 191/500 | lr 2.00000 | ms/epoch 2511.95097 | train_loss  0.65 | eval_loss  0.47\n","| epoch 192/500 | lr 2.00000 | ms/epoch 2534.78742 | train_loss  0.64 | eval_loss  0.47\n","| epoch 193/500 | lr 2.00000 | ms/epoch 2588.01889 | train_loss  0.64 | eval_loss  0.42\n","| epoch 194/500 | lr 2.00000 | ms/epoch 2620.81623 | train_loss  0.64 | eval_loss  0.40\n","| epoch 195/500 | lr 2.00000 | ms/epoch 2587.20160 | train_loss  0.64 | eval_loss  0.45\n","| epoch 196/500 | lr 2.00000 | ms/epoch 2634.97925 | train_loss  0.64 | eval_loss  0.47\n","| epoch 197/500 | lr 2.00000 | ms/epoch 2562.68287 | train_loss  0.64 | eval_loss  0.40\n","| epoch 198/500 | lr 2.00000 | ms/epoch 2553.10369 | train_loss  0.64 | eval_loss  0.40\n","| epoch 199/500 | lr 2.00000 | ms/epoch 2543.44201 | train_loss  0.64 | eval_loss  0.41\n","| epoch 200/500 | lr 2.00000 | ms/epoch 2724.68543 | train_loss  0.64 | eval_loss  0.41\n","| epoch 201/500 | lr 2.00000 | ms/epoch 2689.26835 | train_loss  0.64 | eval_loss  0.43\n","| epoch 202/500 | lr 2.00000 | ms/epoch 2584.78260 | train_loss  0.64 | eval_loss  0.39\n","| epoch 203/500 | lr 2.00000 | ms/epoch 2653.41592 | train_loss  0.63 | eval_loss  0.46\n","| epoch 204/500 | lr 2.00000 | ms/epoch 2614.07804 | train_loss  0.63 | eval_loss  0.41\n","| epoch 205/500 | lr 2.00000 | ms/epoch 2531.86083 | train_loss  0.63 | eval_loss  0.41\n","| epoch 206/500 | lr 2.00000 | ms/epoch 3513.54790 | train_loss  0.63 | eval_loss  0.42\n","| epoch 207/500 | lr 2.00000 | ms/epoch 4236.82284 | train_loss  0.63 | eval_loss  0.41\n","| epoch 208/500 | lr 2.00000 | ms/epoch 4361.19413 | train_loss  0.63 | eval_loss  0.42\n","| epoch 209/500 | lr 2.00000 | ms/epoch 4190.68789 | train_loss  0.63 | eval_loss  0.41\n","| epoch 210/500 | lr 2.00000 | ms/epoch 4335.02197 | train_loss  0.63 | eval_loss  0.39\n","| epoch 211/500 | lr 2.00000 | ms/epoch 4511.48105 | train_loss  0.62 | eval_loss  0.42\n","| epoch 212/500 | lr 2.00000 | ms/epoch 2808.02274 | train_loss  0.63 | eval_loss  0.40\n","| epoch 213/500 | lr 2.00000 | ms/epoch 2615.64898 | train_loss  0.62 | eval_loss  0.39\n","| epoch 214/500 | lr 2.00000 | ms/epoch 2560.56190 | train_loss  0.62 | eval_loss  0.39\n","| epoch 215/500 | lr 2.00000 | ms/epoch 2530.75624 | train_loss  0.62 | eval_loss  0.44\n","| epoch 216/500 | lr 2.00000 | ms/epoch 2572.02482 | train_loss  0.63 | eval_loss  0.45\n","| epoch 217/500 | lr 2.00000 | ms/epoch 2607.45406 | train_loss  0.62 | eval_loss  0.41\n","| epoch 218/500 | lr 2.00000 | ms/epoch 2546.47398 | train_loss  0.62 | eval_loss  0.42\n","| epoch 219/500 | lr 2.00000 | ms/epoch 2444.55409 | train_loss  0.62 | eval_loss  0.39\n","| epoch 220/500 | lr 2.00000 | ms/epoch 2545.08471 | train_loss  0.62 | eval_loss  0.39\n","| epoch 221/500 | lr 2.00000 | ms/epoch 2599.61081 | train_loss  0.62 | eval_loss  0.38\n","| epoch 222/500 | lr 2.00000 | ms/epoch 2553.92885 | train_loss  0.62 | eval_loss  0.39\n","| epoch 223/500 | lr 2.00000 | ms/epoch 2549.65472 | train_loss  0.62 | eval_loss  0.44\n","| epoch 224/500 | lr 2.00000 | ms/epoch 3010.43391 | train_loss  0.61 | eval_loss  0.40\n","| epoch 225/500 | lr 2.00000 | ms/epoch 4461.33137 | train_loss  0.61 | eval_loss  0.38\n","| epoch 226/500 | lr 2.00000 | ms/epoch 4280.19261 | train_loss  0.61 | eval_loss  0.41\n","| epoch 227/500 | lr 2.00000 | ms/epoch 4330.12962 | train_loss  0.61 | eval_loss  0.38\n","| epoch 228/500 | lr 2.00000 | ms/epoch 4333.45485 | train_loss  0.62 | eval_loss  0.38\n","| epoch 229/500 | lr 2.00000 | ms/epoch 4484.04431 | train_loss  0.61 | eval_loss  0.40\n","| epoch 230/500 | lr 2.00000 | ms/epoch 3747.02787 | train_loss  0.61 | eval_loss  0.44\n","| epoch 231/500 | lr 2.00000 | ms/epoch 2549.41082 | train_loss  0.61 | eval_loss  0.38\n","| epoch 232/500 | lr 2.00000 | ms/epoch 2559.91149 | train_loss  0.61 | eval_loss  0.40\n","| epoch 233/500 | lr 2.00000 | ms/epoch 2540.46965 | train_loss  0.61 | eval_loss  0.39\n","| epoch 234/500 | lr 2.00000 | ms/epoch 2543.91909 | train_loss  0.60 | eval_loss  0.39\n","| epoch 235/500 | lr 2.00000 | ms/epoch 2536.76200 | train_loss  0.61 | eval_loss  0.40\n","| epoch 236/500 | lr 2.00000 | ms/epoch 2537.37783 | train_loss  0.61 | eval_loss  0.38\n","| epoch 237/500 | lr 2.00000 | ms/epoch 2570.48297 | train_loss  0.60 | eval_loss  0.37\n","| epoch 238/500 | lr 2.00000 | ms/epoch 2578.92942 | train_loss  0.60 | eval_loss  0.40\n","| epoch 239/500 | lr 2.00000 | ms/epoch 2531.70967 | train_loss  0.61 | eval_loss  0.39\n","| epoch 240/500 | lr 2.00000 | ms/epoch 2546.80824 | train_loss  0.60 | eval_loss  0.37\n","| epoch 241/500 | lr 2.00000 | ms/epoch 2536.56101 | train_loss  0.60 | eval_loss  0.39\n","| epoch 242/500 | lr 2.00000 | ms/epoch 2544.59953 | train_loss  0.60 | eval_loss  0.38\n","| epoch 243/500 | lr 2.00000 | ms/epoch 2573.40264 | train_loss  0.60 | eval_loss  0.37\n","| epoch 244/500 | lr 2.00000 | ms/epoch 2550.96889 | train_loss  0.60 | eval_loss  0.39\n","| epoch 245/500 | lr 2.00000 | ms/epoch 2534.21998 | train_loss  0.59 | eval_loss  0.37\n","| epoch 246/500 | lr 2.00000 | ms/epoch 2537.00638 | train_loss  0.60 | eval_loss  0.38\n","| epoch 247/500 | lr 2.00000 | ms/epoch 2552.18315 | train_loss  0.59 | eval_loss  0.37\n","| epoch 248/500 | lr 2.00000 | ms/epoch 2592.49878 | train_loss  0.59 | eval_loss  0.37\n","| epoch 249/500 | lr 2.00000 | ms/epoch 2575.06824 | train_loss  0.60 | eval_loss  0.39\n","| epoch 250/500 | lr 2.00000 | ms/epoch 2528.99718 | train_loss  0.59 | eval_loss  0.38\n","| epoch 251/500 | lr 2.00000 | ms/epoch 2530.92027 | train_loss  0.60 | eval_loss  0.38\n","| epoch 252/500 | lr 2.00000 | ms/epoch 2554.74639 | train_loss  0.59 | eval_loss  0.37\n","| epoch 253/500 | lr 2.00000 | ms/epoch 2517.68517 | train_loss  0.59 | eval_loss  0.39\n","| epoch 254/500 | lr 2.00000 | ms/epoch 2554.96526 | train_loss  0.59 | eval_loss  0.40\n","| epoch 255/500 | lr 2.00000 | ms/epoch 2588.22489 | train_loss  0.59 | eval_loss  0.39\n","| epoch 256/500 | lr 2.00000 | ms/epoch 2549.77441 | train_loss  0.59 | eval_loss  0.38\n","| epoch 257/500 | lr 2.00000 | ms/epoch 2536.92079 | train_loss  0.59 | eval_loss  0.37\n","| epoch 258/500 | lr 2.00000 | ms/epoch 2550.36569 | train_loss  0.59 | eval_loss  0.40\n","| epoch 259/500 | lr 2.00000 | ms/epoch 2530.23386 | train_loss  0.59 | eval_loss  0.37\n","| epoch 260/500 | lr 2.00000 | ms/epoch 2563.18617 | train_loss  0.59 | eval_loss  0.36\n","| epoch 261/500 | lr 2.00000 | ms/epoch 2535.66313 | train_loss  0.58 | eval_loss  0.39\n","| epoch 262/500 | lr 2.00000 | ms/epoch 2552.20652 | train_loss  0.58 | eval_loss  0.40\n","| epoch 263/500 | lr 2.00000 | ms/epoch 2540.96222 | train_loss  0.59 | eval_loss  0.37\n","| epoch 264/500 | lr 2.00000 | ms/epoch 2538.38348 | train_loss  0.58 | eval_loss  0.38\n","| epoch 265/500 | lr 2.00000 | ms/epoch 2558.20131 | train_loss  0.58 | eval_loss  0.36\n","| epoch 266/500 | lr 2.00000 | ms/epoch 2561.32770 | train_loss  0.59 | eval_loss  0.37\n","| epoch 267/500 | lr 2.00000 | ms/epoch 2532.74775 | train_loss  0.58 | eval_loss  0.37\n","| epoch 268/500 | lr 2.00000 | ms/epoch 3394.02866 | train_loss  0.58 | eval_loss  0.37\n","| epoch 269/500 | lr 2.00000 | ms/epoch 4392.67087 | train_loss  0.58 | eval_loss  0.36\n","| epoch 270/500 | lr 2.00000 | ms/epoch 4465.18421 | train_loss  0.58 | eval_loss  0.41\n","| epoch 271/500 | lr 2.00000 | ms/epoch 2759.56464 | train_loss  0.59 | eval_loss  0.40\n","| epoch 272/500 | lr 2.00000 | ms/epoch 2570.39428 | train_loss  0.58 | eval_loss  0.38\n","| epoch 273/500 | lr 2.00000 | ms/epoch 2528.74827 | train_loss  0.57 | eval_loss  0.37\n","| epoch 274/500 | lr 2.00000 | ms/epoch 2557.34324 | train_loss  0.58 | eval_loss  0.36\n","| epoch 275/500 | lr 2.00000 | ms/epoch 2541.51988 | train_loss  0.58 | eval_loss  0.39\n","| epoch 276/500 | lr 2.00000 | ms/epoch 2565.74416 | train_loss  0.58 | eval_loss  0.37\n","| epoch 277/500 | lr 2.00000 | ms/epoch 2533.78105 | train_loss  0.58 | eval_loss  0.36\n","| epoch 278/500 | lr 2.00000 | ms/epoch 2514.74929 | train_loss  0.58 | eval_loss  0.35\n","| epoch 279/500 | lr 2.00000 | ms/epoch 2492.63906 | train_loss  0.58 | eval_loss  0.37\n","| epoch 280/500 | lr 2.00000 | ms/epoch 2506.72221 | train_loss  0.57 | eval_loss  0.37\n","| epoch 281/500 | lr 2.00000 | ms/epoch 2532.06253 | train_loss  0.57 | eval_loss  0.38\n","| epoch 282/500 | lr 2.00000 | ms/epoch 2586.38859 | train_loss  0.57 | eval_loss  0.37\n","| epoch 283/500 | lr 2.00000 | ms/epoch 2873.94905 | train_loss  0.57 | eval_loss  0.37\n","| epoch 284/500 | lr 2.00000 | ms/epoch 4121.07825 | train_loss  0.57 | eval_loss  0.36\n","| epoch 285/500 | lr 2.00000 | ms/epoch 4200.87290 | train_loss  0.57 | eval_loss  0.36\n","| epoch 286/500 | lr 2.00000 | ms/epoch 3198.42362 | train_loss  0.57 | eval_loss  0.35\n","| epoch 287/500 | lr 2.00000 | ms/epoch 2505.30624 | train_loss  0.57 | eval_loss  0.40\n","| epoch 288/500 | lr 2.00000 | ms/epoch 2625.74005 | train_loss  0.57 | eval_loss  0.36\n","| epoch 289/500 | lr 2.00000 | ms/epoch 2550.92382 | train_loss  0.57 | eval_loss  0.37\n","| epoch 290/500 | lr 2.00000 | ms/epoch 2527.87066 | train_loss  0.57 | eval_loss  0.37\n","| epoch 291/500 | lr 2.00000 | ms/epoch 2537.04929 | train_loss  0.56 | eval_loss  0.36\n","| epoch 292/500 | lr 2.00000 | ms/epoch 2562.98375 | train_loss  0.57 | eval_loss  0.37\n","| epoch 293/500 | lr 2.00000 | ms/epoch 2541.99553 | train_loss  0.57 | eval_loss  0.34\n","| epoch 294/500 | lr 2.00000 | ms/epoch 2591.07590 | train_loss  0.57 | eval_loss  0.36\n","| epoch 295/500 | lr 2.00000 | ms/epoch 2563.60745 | train_loss  0.56 | eval_loss  0.35\n","| epoch 296/500 | lr 2.00000 | ms/epoch 2546.36765 | train_loss  0.56 | eval_loss  0.34\n","| epoch 297/500 | lr 2.00000 | ms/epoch 2528.60332 | train_loss  0.56 | eval_loss  0.34\n","| epoch 298/500 | lr 2.00000 | ms/epoch 2535.37011 | train_loss  0.57 | eval_loss  0.34\n","| epoch 299/500 | lr 2.00000 | ms/epoch 4155.63130 | train_loss  0.56 | eval_loss  0.36\n","| epoch 300/500 | lr 2.00000 | ms/epoch 4556.62155 | train_loss  0.56 | eval_loss  0.36\n","| epoch 301/500 | lr 2.00000 | ms/epoch 4287.64415 | train_loss  0.56 | eval_loss  0.34\n","| epoch 302/500 | lr 2.00000 | ms/epoch 4202.63433 | train_loss  0.56 | eval_loss  0.35\n","| epoch 303/500 | lr 2.00000 | ms/epoch 2622.48516 | train_loss  0.56 | eval_loss  0.36\n","| epoch 304/500 | lr 2.00000 | ms/epoch 2689.49556 | train_loss  0.56 | eval_loss  0.35\n","| epoch 305/500 | lr 2.00000 | ms/epoch 2704.32067 | train_loss  0.56 | eval_loss  0.35\n","| epoch 306/500 | lr 2.00000 | ms/epoch 2624.65596 | train_loss  0.56 | eval_loss  0.40\n","| epoch 307/500 | lr 2.00000 | ms/epoch 2572.63994 | train_loss  0.56 | eval_loss  0.35\n","| epoch 308/500 | lr 2.00000 | ms/epoch 2735.29077 | train_loss  0.56 | eval_loss  0.40\n","| epoch 309/500 | lr 2.00000 | ms/epoch 2579.09203 | train_loss  0.56 | eval_loss  0.34\n","| epoch 310/500 | lr 2.00000 | ms/epoch 2562.27136 | train_loss  0.55 | eval_loss  0.37\n","| epoch 311/500 | lr 2.00000 | ms/epoch 2559.35192 | train_loss  0.56 | eval_loss  0.38\n","| epoch 312/500 | lr 2.00000 | ms/epoch 2538.26261 | train_loss  0.56 | eval_loss  0.34\n","| epoch 313/500 | lr 2.00000 | ms/epoch 2552.79350 | train_loss  0.55 | eval_loss  0.36\n","| epoch 314/500 | lr 2.00000 | ms/epoch 2538.71202 | train_loss  0.55 | eval_loss  0.36\n","| epoch 315/500 | lr 2.00000 | ms/epoch 3881.43325 | train_loss  0.55 | eval_loss  0.34\n","| epoch 316/500 | lr 2.00000 | ms/epoch 4283.81681 | train_loss  0.56 | eval_loss  0.34\n","| epoch 317/500 | lr 2.00000 | ms/epoch 2692.41142 | train_loss  0.55 | eval_loss  0.37\n","| epoch 318/500 | lr 2.00000 | ms/epoch 2549.82853 | train_loss  0.55 | eval_loss  0.34\n","| epoch 319/500 | lr 2.00000 | ms/epoch 2562.87718 | train_loss  0.56 | eval_loss  0.37\n","| epoch 320/500 | lr 2.00000 | ms/epoch 2532.75728 | train_loss  0.55 | eval_loss  0.37\n","| epoch 321/500 | lr 2.00000 | ms/epoch 2537.65249 | train_loss  0.55 | eval_loss  0.36\n","| epoch 322/500 | lr 2.00000 | ms/epoch 2531.05593 | train_loss  0.55 | eval_loss  0.34\n","| epoch 323/500 | lr 2.00000 | ms/epoch 2545.38965 | train_loss  0.55 | eval_loss  0.34\n","| epoch 324/500 | lr 2.00000 | ms/epoch 2527.66776 | train_loss  0.55 | eval_loss  0.35\n","| epoch 325/500 | lr 2.00000 | ms/epoch 2551.31292 | train_loss  0.55 | eval_loss  0.32\n","| epoch 326/500 | lr 2.00000 | ms/epoch 2531.73089 | train_loss  0.54 | eval_loss  0.34\n","| epoch 327/500 | lr 2.00000 | ms/epoch 2537.35614 | train_loss  0.55 | eval_loss  0.34\n","| epoch 328/500 | lr 2.00000 | ms/epoch 2538.72108 | train_loss  0.54 | eval_loss  0.34\n","| epoch 329/500 | lr 2.00000 | ms/epoch 2752.34175 | train_loss  0.55 | eval_loss  0.35\n","| epoch 330/500 | lr 2.00000 | ms/epoch 4335.36482 | train_loss  0.54 | eval_loss  0.36\n","| epoch 331/500 | lr 2.00000 | ms/epoch 4374.82119 | train_loss  0.55 | eval_loss  0.34\n","| epoch 332/500 | lr 2.00000 | ms/epoch 4264.81819 | train_loss  0.55 | eval_loss  0.32\n","| epoch 333/500 | lr 2.00000 | ms/epoch 4219.74325 | train_loss  0.54 | eval_loss  0.33\n","| epoch 334/500 | lr 2.00000 | ms/epoch 3815.15241 | train_loss  0.55 | eval_loss  0.35\n","| epoch 335/500 | lr 2.00000 | ms/epoch 2530.62367 | train_loss  0.54 | eval_loss  0.34\n","| epoch 336/500 | lr 2.00000 | ms/epoch 2554.67153 | train_loss  0.54 | eval_loss  0.32\n","| epoch 337/500 | lr 2.00000 | ms/epoch 2528.06330 | train_loss  0.54 | eval_loss  0.33\n","| epoch 338/500 | lr 2.00000 | ms/epoch 2585.14118 | train_loss  0.55 | eval_loss  0.34\n","| epoch 339/500 | lr 2.00000 | ms/epoch 2528.37706 | train_loss  0.54 | eval_loss  0.37\n","\n","\n"," TRAINING FINISHED:\n","\n","\tBest Loss:  0.32\tBest Model saved at epoch: 325 \n","\n","\n","\n","\n","TEST LOSS: 0.3728445832928022\n"]},{"name":"stderr","output_type":"stream","text":["/home/marco_bortolotti/miniconda3/envs/virtual_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv1d(input, weight, bias, self.stride,\n"]},{"name":"stdout","output_type":"stream","text":["| epoch   1/500 | lr 2.00000 | ms/epoch 2789.24727 | train_loss  3.46 | eval_loss  3.44\n","| epoch   2/500 | lr 2.00000 | ms/epoch 2625.35381 | train_loss  3.29 | eval_loss  3.40\n","| epoch   3/500 | lr 2.00000 | ms/epoch 2722.38803 | train_loss  3.15 | eval_loss  3.21\n","| epoch   4/500 | lr 2.00000 | ms/epoch 2641.48498 | train_loss  3.00 | eval_loss  3.07\n","| epoch   5/500 | lr 2.00000 | ms/epoch 2584.58400 | train_loss  2.91 | eval_loss  2.83\n","| epoch   6/500 | lr 2.00000 | ms/epoch 2547.05811 | train_loss  2.80 | eval_loss  2.99\n","| epoch   7/500 | lr 2.00000 | ms/epoch 4374.59540 | train_loss  2.73 | eval_loss  2.63\n","| epoch   8/500 | lr 2.00000 | ms/epoch 4579.25010 | train_loss  2.65 | eval_loss  2.55\n","| epoch   9/500 | lr 2.00000 | ms/epoch 4403.08499 | train_loss  2.58 | eval_loss  2.54\n","| epoch  10/500 | lr 2.00000 | ms/epoch 4579.23818 | train_loss  2.52 | eval_loss  2.52\n","| epoch  11/500 | lr 2.00000 | ms/epoch 4430.42421 | train_loss  2.43 | eval_loss  2.29\n","| epoch  12/500 | lr 2.00000 | ms/epoch 2877.72393 | train_loss  2.36 | eval_loss  2.23\n","| epoch  13/500 | lr 2.00000 | ms/epoch 2609.32851 | train_loss  2.29 | eval_loss  2.13\n","| epoch  14/500 | lr 2.00000 | ms/epoch 2573.74430 | train_loss  2.23 | eval_loss  2.05\n","| epoch  15/500 | lr 2.00000 | ms/epoch 2629.40907 | train_loss  2.18 | eval_loss  2.06\n","| epoch  16/500 | lr 2.00000 | ms/epoch 2568.84408 | train_loss  2.12 | eval_loss  1.97\n","| epoch  17/500 | lr 2.00000 | ms/epoch 2575.07873 | train_loss  2.06 | eval_loss  1.95\n","| epoch  18/500 | lr 2.00000 | ms/epoch 2571.90466 | train_loss  2.02 | eval_loss  1.86\n","| epoch  19/500 | lr 2.00000 | ms/epoch 2669.93594 | train_loss  1.96 | eval_loss  1.75\n","| epoch  20/500 | lr 2.00000 | ms/epoch 2611.45425 | train_loss  1.92 | eval_loss  1.83\n","| epoch  21/500 | lr 2.00000 | ms/epoch 2617.31052 | train_loss  1.87 | eval_loss  1.66\n","| epoch  22/500 | lr 2.00000 | ms/epoch 2566.17856 | train_loss  1.83 | eval_loss  1.65\n","| epoch  23/500 | lr 2.00000 | ms/epoch 2670.96615 | train_loss  1.78 | eval_loss  1.52\n","| epoch  24/500 | lr 2.00000 | ms/epoch 2665.43388 | train_loss  1.75 | eval_loss  1.47\n","| epoch  25/500 | lr 2.00000 | ms/epoch 2675.73285 | train_loss  1.71 | eval_loss  1.48\n","| epoch  26/500 | lr 2.00000 | ms/epoch 2770.53142 | train_loss  1.68 | eval_loss  1.40\n","| epoch  27/500 | lr 2.00000 | ms/epoch 2730.85141 | train_loss  1.64 | eval_loss  1.42\n","| epoch  28/500 | lr 2.00000 | ms/epoch 2626.77813 | train_loss  1.61 | eval_loss  1.36\n","| epoch  29/500 | lr 2.00000 | ms/epoch 2593.99319 | train_loss  1.59 | eval_loss  1.30\n","| epoch  30/500 | lr 2.00000 | ms/epoch 2573.60029 | train_loss  1.56 | eval_loss  1.31\n","| epoch  31/500 | lr 2.00000 | ms/epoch 2611.33838 | train_loss  1.53 | eval_loss  1.26\n","| epoch  32/500 | lr 2.00000 | ms/epoch 2617.76423 | train_loss  1.51 | eval_loss  1.27\n","| epoch  33/500 | lr 2.00000 | ms/epoch 2562.66046 | train_loss  1.49 | eval_loss  1.27\n","| epoch  34/500 | lr 2.00000 | ms/epoch 2573.05121 | train_loss  1.47 | eval_loss  1.18\n","| epoch  35/500 | lr 2.00000 | ms/epoch 2597.04375 | train_loss  1.45 | eval_loss  1.14\n","| epoch  36/500 | lr 2.00000 | ms/epoch 2589.52284 | train_loss  1.43 | eval_loss  1.12\n","| epoch  37/500 | lr 2.00000 | ms/epoch 2646.63100 | train_loss  1.41 | eval_loss  1.12\n","| epoch  38/500 | lr 2.00000 | ms/epoch 2632.96676 | train_loss  1.39 | eval_loss  1.10\n","| epoch  39/500 | lr 2.00000 | ms/epoch 2581.14004 | train_loss  1.38 | eval_loss  1.10\n","| epoch  40/500 | lr 2.00000 | ms/epoch 2613.52324 | train_loss  1.36 | eval_loss  1.06\n","| epoch  41/500 | lr 2.00000 | ms/epoch 2537.29343 | train_loss  1.34 | eval_loss  1.08\n","| epoch  42/500 | lr 2.00000 | ms/epoch 2776.18742 | train_loss  1.33 | eval_loss  1.06\n","| epoch  43/500 | lr 2.00000 | ms/epoch 2740.51642 | train_loss  1.31 | eval_loss  1.03\n","| epoch  44/500 | lr 2.00000 | ms/epoch 2743.71862 | train_loss  1.30 | eval_loss  1.06\n","| epoch  45/500 | lr 2.00000 | ms/epoch 2618.58773 | train_loss  1.29 | eval_loss  1.00\n","| epoch  46/500 | lr 2.00000 | ms/epoch 2707.39651 | train_loss  1.27 | eval_loss  1.00\n","| epoch  47/500 | lr 2.00000 | ms/epoch 2702.65698 | train_loss  1.26 | eval_loss  1.00\n","| epoch  48/500 | lr 2.00000 | ms/epoch 2614.52579 | train_loss  1.25 | eval_loss  0.98\n","| epoch  49/500 | lr 2.00000 | ms/epoch 3358.88076 | train_loss  1.24 | eval_loss  0.92\n","| epoch  50/500 | lr 2.00000 | ms/epoch 4574.33200 | train_loss  1.23 | eval_loss  0.91\n","| epoch  51/500 | lr 2.00000 | ms/epoch 4368.52765 | train_loss  1.21 | eval_loss  0.95\n","| epoch  52/500 | lr 2.00000 | ms/epoch 4372.22695 | train_loss  1.21 | eval_loss  0.93\n","| epoch  53/500 | lr 2.00000 | ms/epoch 4761.09552 | train_loss  1.19 | eval_loss  0.89\n","| epoch  54/500 | lr 2.00000 | ms/epoch 5872.07937 | train_loss  1.18 | eval_loss  0.88\n","| epoch  55/500 | lr 2.00000 | ms/epoch 6205.50370 | train_loss  1.17 | eval_loss  0.94\n","| epoch  56/500 | lr 2.00000 | ms/epoch 5911.01527 | train_loss  1.15 | eval_loss  0.92\n","| epoch  57/500 | lr 2.00000 | ms/epoch 5715.80219 | train_loss  1.15 | eval_loss  0.88\n","| epoch  58/500 | lr 2.00000 | ms/epoch 6085.89840 | train_loss  1.14 | eval_loss  0.84\n","| epoch  59/500 | lr 2.00000 | ms/epoch 5902.10032 | train_loss  1.13 | eval_loss  0.87\n","| epoch  60/500 | lr 2.00000 | ms/epoch 6203.37701 | train_loss  1.12 | eval_loss  0.90\n","| epoch  61/500 | lr 2.00000 | ms/epoch 6373.77620 | train_loss  1.11 | eval_loss  0.84\n","| epoch  62/500 | lr 2.00000 | ms/epoch 6623.64960 | train_loss  1.10 | eval_loss  0.81\n","| epoch  63/500 | lr 2.00000 | ms/epoch 5794.31009 | train_loss  1.08 | eval_loss  0.83\n","| epoch  64/500 | lr 2.00000 | ms/epoch 4519.09518 | train_loss  1.08 | eval_loss  0.81\n","| epoch  65/500 | lr 2.00000 | ms/epoch 4495.22901 | train_loss  1.07 | eval_loss  0.81\n","| epoch  66/500 | lr 2.00000 | ms/epoch 4562.45708 | train_loss  1.06 | eval_loss  0.80\n","| epoch  67/500 | lr 2.00000 | ms/epoch 4456.42114 | train_loss  1.05 | eval_loss  0.83\n","| epoch  68/500 | lr 2.00000 | ms/epoch 4678.67231 | train_loss  1.04 | eval_loss  0.81\n","| epoch  69/500 | lr 2.00000 | ms/epoch 4867.62929 | train_loss  1.03 | eval_loss  0.84\n","| epoch  70/500 | lr 2.00000 | ms/epoch 5290.72905 | train_loss  1.02 | eval_loss  0.72\n","| epoch  71/500 | lr 2.00000 | ms/epoch 5869.18020 | train_loss  1.02 | eval_loss  0.73\n","| epoch  72/500 | lr 2.00000 | ms/epoch 5946.28549 | train_loss  1.01 | eval_loss  0.73\n","| epoch  73/500 | lr 2.00000 | ms/epoch 5716.87293 | train_loss  1.00 | eval_loss  0.79\n","| epoch  74/500 | lr 2.00000 | ms/epoch 5839.06245 | train_loss  0.99 | eval_loss  0.74\n","| epoch  75/500 | lr 2.00000 | ms/epoch 6086.55381 | train_loss  0.98 | eval_loss  0.67\n","| epoch  76/500 | lr 2.00000 | ms/epoch 6442.73186 | train_loss  0.97 | eval_loss  0.69\n","| epoch  77/500 | lr 2.00000 | ms/epoch 6398.44537 | train_loss  0.97 | eval_loss  0.72\n","| epoch  78/500 | lr 2.00000 | ms/epoch 6397.44329 | train_loss  0.95 | eval_loss  0.68\n","| epoch  79/500 | lr 2.00000 | ms/epoch 5724.30801 | train_loss  0.95 | eval_loss  0.67\n","| epoch  80/500 | lr 2.00000 | ms/epoch 4773.21172 | train_loss  0.95 | eval_loss  0.63\n","| epoch  81/500 | lr 2.00000 | ms/epoch 4819.65375 | train_loss  0.93 | eval_loss  0.65\n","| epoch  82/500 | lr 2.00000 | ms/epoch 4686.05947 | train_loss  0.92 | eval_loss  0.61\n","| epoch  83/500 | lr 2.00000 | ms/epoch 4554.21376 | train_loss  0.92 | eval_loss  0.69\n","| epoch  84/500 | lr 2.00000 | ms/epoch 4590.22856 | train_loss  0.92 | eval_loss  0.65\n","| epoch  85/500 | lr 2.00000 | ms/epoch 4501.25980 | train_loss  0.91 | eval_loss  0.66\n","| epoch  86/500 | lr 2.00000 | ms/epoch 5162.15181 | train_loss  0.90 | eval_loss  0.67\n","| epoch  87/500 | lr 2.00000 | ms/epoch 6041.52060 | train_loss  0.89 | eval_loss  0.62\n","| epoch  88/500 | lr 2.00000 | ms/epoch 6089.54787 | train_loss  0.89 | eval_loss  0.65\n","| epoch  89/500 | lr 2.00000 | ms/epoch 5673.75469 | train_loss  0.88 | eval_loss  0.59\n","| epoch  90/500 | lr 2.00000 | ms/epoch 5984.27272 | train_loss  0.88 | eval_loss  0.63\n","| epoch  91/500 | lr 2.00000 | ms/epoch 6164.49571 | train_loss  0.88 | eval_loss  0.64\n","| epoch  92/500 | lr 2.00000 | ms/epoch 4984.41648 | train_loss  0.87 | eval_loss  0.58\n","| epoch  93/500 | lr 2.00000 | ms/epoch 4584.56230 | train_loss  0.87 | eval_loss  0.58\n","| epoch  94/500 | lr 2.00000 | ms/epoch 4470.70336 | train_loss  0.86 | eval_loss  0.58\n","| epoch  95/500 | lr 2.00000 | ms/epoch 4395.26844 | train_loss  0.86 | eval_loss  0.61\n","| epoch  96/500 | lr 2.00000 | ms/epoch 4326.38741 | train_loss  0.85 | eval_loss  0.58\n","| epoch  97/500 | lr 2.00000 | ms/epoch 4457.96824 | train_loss  0.85 | eval_loss  0.58\n","| epoch  98/500 | lr 2.00000 | ms/epoch 4373.24905 | train_loss  0.84 | eval_loss  0.57\n","| epoch  99/500 | lr 2.00000 | ms/epoch 5306.42605 | train_loss  0.84 | eval_loss  0.60\n","| epoch 100/500 | lr 2.00000 | ms/epoch 6090.20877 | train_loss  0.83 | eval_loss  0.57\n","| epoch 101/500 | lr 2.00000 | ms/epoch 5866.31179 | train_loss  0.83 | eval_loss  0.58\n","| epoch 102/500 | lr 2.00000 | ms/epoch 5874.01104 | train_loss  0.83 | eval_loss  0.56\n","| epoch 103/500 | lr 2.00000 | ms/epoch 5779.35815 | train_loss  0.82 | eval_loss  0.57\n","| epoch 104/500 | lr 2.00000 | ms/epoch 6226.08995 | train_loss  0.82 | eval_loss  0.54\n","| epoch 105/500 | lr 2.00000 | ms/epoch 5786.84163 | train_loss  0.82 | eval_loss  0.55\n","| epoch 106/500 | lr 2.00000 | ms/epoch 4609.59411 | train_loss  0.81 | eval_loss  0.54\n","| epoch 107/500 | lr 2.00000 | ms/epoch 4233.92534 | train_loss  0.81 | eval_loss  0.52\n","| epoch 108/500 | lr 2.00000 | ms/epoch 4301.22161 | train_loss  0.81 | eval_loss  0.58\n","| epoch 109/500 | lr 2.00000 | ms/epoch 4384.57561 | train_loss  0.80 | eval_loss  0.53\n","| epoch 110/500 | lr 2.00000 | ms/epoch 4289.07180 | train_loss  0.79 | eval_loss  0.55\n","| epoch 111/500 | lr 2.00000 | ms/epoch 4233.41465 | train_loss  0.79 | eval_loss  0.56\n","| epoch 112/500 | lr 2.00000 | ms/epoch 4789.50930 | train_loss  0.79 | eval_loss  0.60\n","| epoch 113/500 | lr 2.00000 | ms/epoch 4655.50041 | train_loss  0.78 | eval_loss  0.54\n","| epoch 114/500 | lr 2.00000 | ms/epoch 5352.70667 | train_loss  0.78 | eval_loss  0.55\n","| epoch 115/500 | lr 2.00000 | ms/epoch 5880.13387 | train_loss  0.78 | eval_loss  0.53\n","| epoch 116/500 | lr 2.00000 | ms/epoch 5616.89663 | train_loss  0.78 | eval_loss  0.50\n","| epoch 117/500 | lr 2.00000 | ms/epoch 5749.99762 | train_loss  0.78 | eval_loss  0.56\n","| epoch 118/500 | lr 2.00000 | ms/epoch 6163.99169 | train_loss  0.77 | eval_loss  0.53\n","| epoch 119/500 | lr 2.00000 | ms/epoch 5974.59579 | train_loss  0.77 | eval_loss  0.54\n","| epoch 120/500 | lr 2.00000 | ms/epoch 6011.48534 | train_loss  0.77 | eval_loss  0.53\n","| epoch 121/500 | lr 2.00000 | ms/epoch 5869.27605 | train_loss  0.76 | eval_loss  0.50\n","| epoch 122/500 | lr 2.00000 | ms/epoch 6136.56139 | train_loss  0.77 | eval_loss  0.53\n","| epoch 123/500 | lr 2.00000 | ms/epoch 5805.85432 | train_loss  0.77 | eval_loss  0.52\n","| epoch 124/500 | lr 2.00000 | ms/epoch 4437.19506 | train_loss  0.76 | eval_loss  0.50\n","| epoch 125/500 | lr 2.00000 | ms/epoch 4566.02407 | train_loss  0.76 | eval_loss  0.53\n","| epoch 126/500 | lr 2.00000 | ms/epoch 4638.19480 | train_loss  0.75 | eval_loss  0.51\n","| epoch 127/500 | lr 2.00000 | ms/epoch 4393.80741 | train_loss  0.75 | eval_loss  0.51\n","| epoch 128/500 | lr 2.00000 | ms/epoch 4621.49763 | train_loss  0.74 | eval_loss  0.49\n","| epoch 129/500 | lr 2.00000 | ms/epoch 4946.08307 | train_loss  0.74 | eval_loss  0.53\n","| epoch 130/500 | lr 2.00000 | ms/epoch 4956.66242 | train_loss  0.75 | eval_loss  0.49\n","| epoch 131/500 | lr 2.00000 | ms/epoch 6137.38036 | train_loss  0.74 | eval_loss  0.52\n","| epoch 132/500 | lr 2.00000 | ms/epoch 6007.88951 | train_loss  0.74 | eval_loss  0.52\n","| epoch 133/500 | lr 2.00000 | ms/epoch 5404.38318 | train_loss  0.74 | eval_loss  0.49\n","| epoch 134/500 | lr 2.00000 | ms/epoch 5524.01376 | train_loss  0.73 | eval_loss  0.47\n","| epoch 135/500 | lr 2.00000 | ms/epoch 5546.94176 | train_loss  0.73 | eval_loss  0.52\n","| epoch 136/500 | lr 2.00000 | ms/epoch 6064.72039 | train_loss  0.73 | eval_loss  0.46\n","| epoch 137/500 | lr 2.00000 | ms/epoch 5977.89168 | train_loss  0.72 | eval_loss  0.48\n","| epoch 138/500 | lr 2.00000 | ms/epoch 6273.14305 | train_loss  0.72 | eval_loss  0.48\n","| epoch 139/500 | lr 2.00000 | ms/epoch 6329.58150 | train_loss  0.72 | eval_loss  0.49\n","| epoch 140/500 | lr 2.00000 | ms/epoch 6457.39985 | train_loss  0.72 | eval_loss  0.48\n","| epoch 141/500 | lr 2.00000 | ms/epoch 6333.89091 | train_loss  0.72 | eval_loss  0.48\n","| epoch 142/500 | lr 2.00000 | ms/epoch 6345.83402 | train_loss  0.72 | eval_loss  0.47\n","| epoch 143/500 | lr 2.00000 | ms/epoch 6257.46346 | train_loss  0.71 | eval_loss  0.46\n","| epoch 144/500 | lr 2.00000 | ms/epoch 5883.15845 | train_loss  0.71 | eval_loss  0.48\n","| epoch 145/500 | lr 2.00000 | ms/epoch 6096.23241 | train_loss  0.71 | eval_loss  0.47\n","| epoch 146/500 | lr 2.00000 | ms/epoch 6153.10907 | train_loss  0.71 | eval_loss  0.46\n","| epoch 147/500 | lr 2.00000 | ms/epoch 6206.41255 | train_loss  0.71 | eval_loss  0.53\n","| epoch 148/500 | lr 2.00000 | ms/epoch 6584.63001 | train_loss  0.70 | eval_loss  0.46\n","| epoch 149/500 | lr 2.00000 | ms/epoch 6552.65903 | train_loss  0.71 | eval_loss  0.48\n","| epoch 150/500 | lr 2.00000 | ms/epoch 6722.62549 | train_loss  0.70 | eval_loss  0.46\n","| epoch 151/500 | lr 2.00000 | ms/epoch 6431.51283 | train_loss  0.70 | eval_loss  0.49\n","| epoch 152/500 | lr 2.00000 | ms/epoch 6438.82084 | train_loss  0.70 | eval_loss  0.44\n","| epoch 153/500 | lr 2.00000 | ms/epoch 6607.93471 | train_loss  0.70 | eval_loss  0.47\n","| epoch 154/500 | lr 2.00000 | ms/epoch 6219.91134 | train_loss  0.70 | eval_loss  0.44\n","| epoch 155/500 | lr 2.00000 | ms/epoch 6766.36982 | train_loss  0.70 | eval_loss  0.49\n","| epoch 156/500 | lr 2.00000 | ms/epoch 6257.42793 | train_loss  0.69 | eval_loss  0.47\n","| epoch 157/500 | lr 2.00000 | ms/epoch 6212.20064 | train_loss  0.69 | eval_loss  0.47\n","| epoch 158/500 | lr 2.00000 | ms/epoch 5934.35645 | train_loss  0.69 | eval_loss  0.47\n","| epoch 159/500 | lr 2.00000 | ms/epoch 6097.92328 | train_loss  0.69 | eval_loss  0.44\n","| epoch 160/500 | lr 2.00000 | ms/epoch 5695.30773 | train_loss  0.69 | eval_loss  0.47\n","| epoch 161/500 | lr 2.00000 | ms/epoch 6053.02691 | train_loss  0.69 | eval_loss  0.53\n","| epoch 162/500 | lr 2.00000 | ms/epoch 5922.55712 | train_loss  0.68 | eval_loss  0.44\n","| epoch 163/500 | lr 2.00000 | ms/epoch 6057.34468 | train_loss  0.68 | eval_loss  0.44\n","| epoch 164/500 | lr 2.00000 | ms/epoch 6202.43073 | train_loss  0.68 | eval_loss  0.45\n","| epoch 165/500 | lr 2.00000 | ms/epoch 6438.06744 | train_loss  0.68 | eval_loss  0.51\n","| epoch 166/500 | lr 2.00000 | ms/epoch 6366.36424 | train_loss  0.68 | eval_loss  0.47\n","| epoch 167/500 | lr 2.00000 | ms/epoch 6652.35329 | train_loss  0.68 | eval_loss  0.47\n","| epoch 168/500 | lr 2.00000 | ms/epoch 6660.51745 | train_loss  0.67 | eval_loss  0.44\n","| epoch 169/500 | lr 2.00000 | ms/epoch 6656.37541 | train_loss  0.67 | eval_loss  0.46\n","| epoch 170/500 | lr 2.00000 | ms/epoch 6252.02990 | train_loss  0.67 | eval_loss  0.43\n","| epoch 171/500 | lr 2.00000 | ms/epoch 6367.68794 | train_loss  0.67 | eval_loss  0.45\n","| epoch 172/500 | lr 2.00000 | ms/epoch 5987.23984 | train_loss  0.67 | eval_loss  0.45\n","| epoch 173/500 | lr 2.00000 | ms/epoch 6314.78119 | train_loss  0.67 | eval_loss  0.45\n","| epoch 174/500 | lr 2.00000 | ms/epoch 5817.79838 | train_loss  0.67 | eval_loss  0.50\n","| epoch 175/500 | lr 2.00000 | ms/epoch 5985.19564 | train_loss  0.67 | eval_loss  0.42\n","| epoch 176/500 | lr 2.00000 | ms/epoch 6513.81207 | train_loss  0.66 | eval_loss  0.44\n","| epoch 177/500 | lr 2.00000 | ms/epoch 6329.38528 | train_loss  0.66 | eval_loss  0.44\n","| epoch 178/500 | lr 2.00000 | ms/epoch 6483.35600 | train_loss  0.66 | eval_loss  0.43\n","| epoch 179/500 | lr 2.00000 | ms/epoch 6446.59114 | train_loss  0.66 | eval_loss  0.43\n","| epoch 180/500 | lr 2.00000 | ms/epoch 6515.51509 | train_loss  0.66 | eval_loss  0.43\n","| epoch 181/500 | lr 2.00000 | ms/epoch 6729.80261 | train_loss  0.66 | eval_loss  0.48\n","| epoch 182/500 | lr 2.00000 | ms/epoch 6717.06915 | train_loss  0.66 | eval_loss  0.47\n","| epoch 183/500 | lr 2.00000 | ms/epoch 6696.31076 | train_loss  0.65 | eval_loss  0.51\n","| epoch 184/500 | lr 2.00000 | ms/epoch 6690.54794 | train_loss  0.65 | eval_loss  0.43\n","| epoch 185/500 | lr 2.00000 | ms/epoch 6776.19886 | train_loss  0.66 | eval_loss  0.41\n","| epoch 186/500 | lr 2.00000 | ms/epoch 6402.40240 | train_loss  0.65 | eval_loss  0.44\n","| epoch 187/500 | lr 2.00000 | ms/epoch 6756.40273 | train_loss  0.65 | eval_loss  0.44\n","| epoch 188/500 | lr 2.00000 | ms/epoch 6239.56513 | train_loss  0.65 | eval_loss  0.45\n","| epoch 189/500 | lr 2.00000 | ms/epoch 6341.36343 | train_loss  0.65 | eval_loss  0.42\n","| epoch 190/500 | lr 2.00000 | ms/epoch 6694.74125 | train_loss  0.65 | eval_loss  0.43\n","| epoch 191/500 | lr 2.00000 | ms/epoch 5515.34033 | train_loss  0.65 | eval_loss  0.42\n","| epoch 192/500 | lr 2.00000 | ms/epoch 6221.13252 | train_loss  0.65 | eval_loss  0.44\n","| epoch 193/500 | lr 2.00000 | ms/epoch 6464.43152 | train_loss  0.64 | eval_loss  0.41\n","| epoch 194/500 | lr 2.00000 | ms/epoch 6744.10105 | train_loss  0.64 | eval_loss  0.44\n","| epoch 195/500 | lr 2.00000 | ms/epoch 6602.50354 | train_loss  0.64 | eval_loss  0.40\n","| epoch 196/500 | lr 2.00000 | ms/epoch 6828.42588 | train_loss  0.64 | eval_loss  0.43\n","| epoch 197/500 | lr 2.00000 | ms/epoch 6642.48419 | train_loss  0.64 | eval_loss  0.43\n","| epoch 198/500 | lr 2.00000 | ms/epoch 6871.65213 | train_loss  0.64 | eval_loss  0.43\n","| epoch 199/500 | lr 2.00000 | ms/epoch 6964.01668 | train_loss  0.64 | eval_loss  0.40\n","| epoch 200/500 | lr 2.00000 | ms/epoch 6766.61134 | train_loss  0.63 | eval_loss  0.48\n","| epoch 201/500 | lr 2.00000 | ms/epoch 6884.11880 | train_loss  0.63 | eval_loss  0.41\n","| epoch 202/500 | lr 2.00000 | ms/epoch 7048.31100 | train_loss  0.63 | eval_loss  0.41\n","| epoch 203/500 | lr 2.00000 | ms/epoch 6911.43894 | train_loss  0.63 | eval_loss  0.44\n","| epoch 204/500 | lr 2.00000 | ms/epoch 6621.85025 | train_loss  0.63 | eval_loss  0.41\n","| epoch 205/500 | lr 2.00000 | ms/epoch 6664.32881 | train_loss  0.63 | eval_loss  0.43\n","| epoch 206/500 | lr 2.00000 | ms/epoch 6820.36328 | train_loss  0.63 | eval_loss  0.40\n","| epoch 207/500 | lr 2.00000 | ms/epoch 7036.43703 | train_loss  0.63 | eval_loss  0.40\n","| epoch 208/500 | lr 2.00000 | ms/epoch 6985.81672 | train_loss  0.63 | eval_loss  0.44\n","| epoch 209/500 | lr 2.00000 | ms/epoch 6928.46775 | train_loss  0.63 | eval_loss  0.41\n","| epoch 210/500 | lr 2.00000 | ms/epoch 7191.33973 | train_loss  0.62 | eval_loss  0.41\n","| epoch 211/500 | lr 2.00000 | ms/epoch 6732.52344 | train_loss  0.63 | eval_loss  0.46\n","| epoch 212/500 | lr 2.00000 | ms/epoch 7037.04762 | train_loss  0.63 | eval_loss  0.40\n","| epoch 213/500 | lr 2.00000 | ms/epoch 6725.99196 | train_loss  0.63 | eval_loss  0.41\n","\n","\n"," TRAINING FINISHED:\n","\n","\tBest Loss:  0.40\tBest Model saved at epoch: 199 \n","\n","\n","\n","\n","TEST LOSS: 0.45578706463178\n","| epoch   1/500 | lr 2.00000 | ms/epoch 7275.85125 | train_loss  3.48 | eval_loss  3.54\n","| epoch   2/500 | lr 2.00000 | ms/epoch 7313.43603 | train_loss  3.34 | eval_loss  3.31\n","| epoch   3/500 | lr 2.00000 | ms/epoch 7311.69415 | train_loss  3.22 | eval_loss  3.33\n","| epoch   4/500 | lr 2.00000 | ms/epoch 6809.17835 | train_loss  3.08 | eval_loss  3.37\n","| epoch   5/500 | lr 2.00000 | ms/epoch 6881.22463 | train_loss  2.97 | eval_loss  2.97\n","| epoch   6/500 | lr 2.00000 | ms/epoch 6948.63772 | train_loss  2.85 | eval_loss  2.82\n","| epoch   7/500 | lr 2.00000 | ms/epoch 6342.91148 | train_loss  2.76 | eval_loss  2.75\n","| epoch   8/500 | lr 2.00000 | ms/epoch 7209.98120 | train_loss  2.67 | eval_loss  2.62\n","| epoch   9/500 | lr 2.00000 | ms/epoch 6168.40124 | train_loss  2.61 | eval_loss  2.51\n","| epoch  10/500 | lr 2.00000 | ms/epoch 6448.24028 | train_loss  2.53 | eval_loss  2.42\n","| epoch  11/500 | lr 2.00000 | ms/epoch 6262.29906 | train_loss  2.45 | eval_loss  2.32\n","| epoch  12/500 | lr 2.00000 | ms/epoch 6758.08311 | train_loss  2.37 | eval_loss  2.30\n","| epoch  13/500 | lr 2.00000 | ms/epoch 7039.36768 | train_loss  2.33 | eval_loss  2.27\n","| epoch  14/500 | lr 2.00000 | ms/epoch 7599.37835 | train_loss  2.28 | eval_loss  2.20\n","| epoch  15/500 | lr 2.00000 | ms/epoch 7114.91585 | train_loss  2.23 | eval_loss  2.13\n","| epoch  16/500 | lr 2.00000 | ms/epoch 6756.01077 | train_loss  2.19 | eval_loss  2.04\n","| epoch  17/500 | lr 2.00000 | ms/epoch 6335.96873 | train_loss  2.14 | eval_loss  2.02\n","| epoch  18/500 | lr 2.00000 | ms/epoch 5737.38623 | train_loss  2.10 | eval_loss  1.92\n","| epoch  19/500 | lr 2.00000 | ms/epoch 5880.46241 | train_loss  2.05 | eval_loss  1.87\n","| epoch  20/500 | lr 2.00000 | ms/epoch 6103.12009 | train_loss  2.00 | eval_loss  1.77\n","| epoch  21/500 | lr 2.00000 | ms/epoch 5998.18897 | train_loss  1.96 | eval_loss  1.76\n","| epoch  22/500 | lr 2.00000 | ms/epoch 6136.24001 | train_loss  1.92 | eval_loss  1.68\n","| epoch  23/500 | lr 2.00000 | ms/epoch 6262.96210 | train_loss  1.88 | eval_loss  1.72\n","| epoch  24/500 | lr 2.00000 | ms/epoch 6030.45273 | train_loss  1.84 | eval_loss  1.62\n","| epoch  25/500 | lr 2.00000 | ms/epoch 6178.31635 | train_loss  1.80 | eval_loss  1.65\n","| epoch  26/500 | lr 2.00000 | ms/epoch 6177.31810 | train_loss  1.77 | eval_loss  1.52\n","| epoch  27/500 | lr 2.00000 | ms/epoch 6097.91231 | train_loss  1.73 | eval_loss  1.52\n","| epoch  28/500 | lr 2.00000 | ms/epoch 6206.69413 | train_loss  1.70 | eval_loss  1.45\n","| epoch  29/500 | lr 2.00000 | ms/epoch 6007.88021 | train_loss  1.66 | eval_loss  1.41\n","| epoch  30/500 | lr 2.00000 | ms/epoch 6098.03510 | train_loss  1.64 | eval_loss  1.37\n","| epoch  31/500 | lr 2.00000 | ms/epoch 6001.86849 | train_loss  1.61 | eval_loss  1.35\n","| epoch  32/500 | lr 2.00000 | ms/epoch 6183.10761 | train_loss  1.57 | eval_loss  1.34\n","| epoch  33/500 | lr 2.00000 | ms/epoch 5839.48541 | train_loss  1.55 | eval_loss  1.29\n","| epoch  34/500 | lr 2.00000 | ms/epoch 5456.24113 | train_loss  1.52 | eval_loss  1.27\n","| epoch  35/500 | lr 2.00000 | ms/epoch 5824.95070 | train_loss  1.50 | eval_loss  1.23\n","| epoch  36/500 | lr 2.00000 | ms/epoch 5885.23889 | train_loss  1.47 | eval_loss  1.19\n","| epoch  37/500 | lr 2.00000 | ms/epoch 5789.33978 | train_loss  1.44 | eval_loss  1.20\n","| epoch  38/500 | lr 2.00000 | ms/epoch 6037.87780 | train_loss  1.42 | eval_loss  1.15\n","| epoch  39/500 | lr 2.00000 | ms/epoch 6408.76317 | train_loss  1.40 | eval_loss  1.16\n","| epoch  40/500 | lr 2.00000 | ms/epoch 5841.80546 | train_loss  1.38 | eval_loss  1.03\n","| epoch  41/500 | lr 2.00000 | ms/epoch 6019.65380 | train_loss  1.36 | eval_loss  1.09\n","| epoch  42/500 | lr 2.00000 | ms/epoch 6485.72850 | train_loss  1.33 | eval_loss  1.02\n","| epoch  43/500 | lr 2.00000 | ms/epoch 5832.48401 | train_loss  1.31 | eval_loss  1.03\n","| epoch  44/500 | lr 2.00000 | ms/epoch 6358.09350 | train_loss  1.29 | eval_loss  1.01\n","| epoch  45/500 | lr 2.00000 | ms/epoch 6055.77040 | train_loss  1.27 | eval_loss  0.95\n","| epoch  46/500 | lr 2.00000 | ms/epoch 5921.09847 | train_loss  1.26 | eval_loss  0.93\n","| epoch  47/500 | lr 2.00000 | ms/epoch 6101.38392 | train_loss  1.24 | eval_loss  0.93\n","| epoch  48/500 | lr 2.00000 | ms/epoch 6115.95035 | train_loss  1.21 | eval_loss  0.86\n","| epoch  49/500 | lr 2.00000 | ms/epoch 5996.13094 | train_loss  1.20 | eval_loss  0.88\n","| epoch  50/500 | lr 2.00000 | ms/epoch 6058.48145 | train_loss  1.19 | eval_loss  0.87\n","| epoch  51/500 | lr 2.00000 | ms/epoch 6016.88528 | train_loss  1.17 | eval_loss  0.86\n","| epoch  52/500 | lr 2.00000 | ms/epoch 5622.39432 | train_loss  1.15 | eval_loss  0.85\n","| epoch  53/500 | lr 2.00000 | ms/epoch 5692.30485 | train_loss  1.15 | eval_loss  0.83\n","| epoch  54/500 | lr 2.00000 | ms/epoch 5852.88262 | train_loss  1.13 | eval_loss  0.81\n","| epoch  55/500 | lr 2.00000 | ms/epoch 6043.57886 | train_loss  1.12 | eval_loss  0.80\n","| epoch  56/500 | lr 2.00000 | ms/epoch 6033.71286 | train_loss  1.10 | eval_loss  0.78\n","| epoch  57/500 | lr 2.00000 | ms/epoch 5965.71779 | train_loss  1.09 | eval_loss  0.78\n","| epoch  58/500 | lr 2.00000 | ms/epoch 5649.14966 | train_loss  1.09 | eval_loss  0.77\n","| epoch  59/500 | lr 2.00000 | ms/epoch 5981.41861 | train_loss  1.08 | eval_loss  0.78\n","| epoch  60/500 | lr 2.00000 | ms/epoch 5718.37878 | train_loss  1.06 | eval_loss  0.78\n","| epoch  61/500 | lr 2.00000 | ms/epoch 6118.04581 | train_loss  1.06 | eval_loss  0.75\n","| epoch  62/500 | lr 2.00000 | ms/epoch 6207.52478 | train_loss  1.04 | eval_loss  0.77\n","| epoch  63/500 | lr 2.00000 | ms/epoch 6283.40912 | train_loss  1.04 | eval_loss  0.75\n","| epoch  64/500 | lr 2.00000 | ms/epoch 5922.58620 | train_loss  1.03 | eval_loss  0.72\n","| epoch  65/500 | lr 2.00000 | ms/epoch 5792.42373 | train_loss  1.02 | eval_loss  0.73\n","| epoch  66/500 | lr 2.00000 | ms/epoch 5854.75612 | train_loss  1.01 | eval_loss  0.71\n","| epoch  67/500 | lr 2.00000 | ms/epoch 5777.84348 | train_loss  1.01 | eval_loss  0.68\n","| epoch  68/500 | lr 2.00000 | ms/epoch 5790.34758 | train_loss  1.00 | eval_loss  0.72\n","| epoch  69/500 | lr 2.00000 | ms/epoch 5773.34094 | train_loss  0.99 | eval_loss  0.69\n","| epoch  70/500 | lr 2.00000 | ms/epoch 5761.09314 | train_loss  0.98 | eval_loss  0.68\n","| epoch  71/500 | lr 2.00000 | ms/epoch 6067.59334 | train_loss  0.97 | eval_loss  0.72\n","| epoch  72/500 | lr 2.00000 | ms/epoch 6060.78219 | train_loss  0.97 | eval_loss  0.68\n","| epoch  73/500 | lr 2.00000 | ms/epoch 6372.85161 | train_loss  0.97 | eval_loss  0.71\n","| epoch  74/500 | lr 2.00000 | ms/epoch 6069.82470 | train_loss  0.96 | eval_loss  0.66\n","| epoch  75/500 | lr 2.00000 | ms/epoch 6021.77954 | train_loss  0.95 | eval_loss  0.67\n","| epoch  76/500 | lr 2.00000 | ms/epoch 6093.59384 | train_loss  0.95 | eval_loss  0.65\n","| epoch  77/500 | lr 2.00000 | ms/epoch 6177.10280 | train_loss  0.94 | eval_loss  0.65\n","| epoch  78/500 | lr 2.00000 | ms/epoch 5809.08680 | train_loss  0.93 | eval_loss  0.64\n","| epoch  79/500 | lr 2.00000 | ms/epoch 5910.68888 | train_loss  0.93 | eval_loss  0.68\n","| epoch  80/500 | lr 2.00000 | ms/epoch 5489.29071 | train_loss  0.92 | eval_loss  0.65\n","| epoch  81/500 | lr 2.00000 | ms/epoch 5985.40545 | train_loss  0.92 | eval_loss  0.64\n","| epoch  82/500 | lr 2.00000 | ms/epoch 5966.29381 | train_loss  0.92 | eval_loss  0.66\n","| epoch  83/500 | lr 2.00000 | ms/epoch 6232.12290 | train_loss  0.91 | eval_loss  0.69\n","| epoch  84/500 | lr 2.00000 | ms/epoch 5720.80994 | train_loss  0.91 | eval_loss  0.62\n","| epoch  85/500 | lr 2.00000 | ms/epoch 5793.72191 | train_loss  0.90 | eval_loss  0.64\n","| epoch  86/500 | lr 2.00000 | ms/epoch 5754.49634 | train_loss  0.90 | eval_loss  0.60\n","| epoch  87/500 | lr 2.00000 | ms/epoch 5525.84910 | train_loss  0.90 | eval_loss  0.61\n","| epoch  88/500 | lr 2.00000 | ms/epoch 6777.43077 | train_loss  0.90 | eval_loss  0.60\n","| epoch  89/500 | lr 2.00000 | ms/epoch 6040.42888 | train_loss  0.89 | eval_loss  0.67\n","| epoch  90/500 | lr 2.00000 | ms/epoch 6597.26715 | train_loss  0.88 | eval_loss  0.62\n","| epoch  91/500 | lr 2.00000 | ms/epoch 7131.24084 | train_loss  0.88 | eval_loss  0.59\n","| epoch  92/500 | lr 2.00000 | ms/epoch 6345.45255 | train_loss  0.88 | eval_loss  0.63\n","| epoch  93/500 | lr 2.00000 | ms/epoch 6258.69226 | train_loss  0.87 | eval_loss  0.62\n","| epoch  94/500 | lr 2.00000 | ms/epoch 6527.40932 | train_loss  0.87 | eval_loss  0.62\n","| epoch  95/500 | lr 2.00000 | ms/epoch 6393.45455 | train_loss  0.86 | eval_loss  0.61\n","| epoch  96/500 | lr 2.00000 | ms/epoch 6708.61363 | train_loss  0.86 | eval_loss  0.58\n","| epoch  97/500 | lr 2.00000 | ms/epoch 6039.10184 | train_loss  0.85 | eval_loss  0.59\n","| epoch  98/500 | lr 2.00000 | ms/epoch 5800.70662 | train_loss  0.85 | eval_loss  0.61\n","| epoch  99/500 | lr 2.00000 | ms/epoch 5030.52378 | train_loss  0.85 | eval_loss  0.64\n","| epoch 100/500 | lr 2.00000 | ms/epoch 4782.64284 | train_loss  0.85 | eval_loss  0.58\n","| epoch 101/500 | lr 2.00000 | ms/epoch 3929.45504 | train_loss  0.84 | eval_loss  0.57\n","| epoch 102/500 | lr 2.00000 | ms/epoch 2663.95426 | train_loss  0.84 | eval_loss  0.59\n","| epoch 103/500 | lr 2.00000 | ms/epoch 2666.77999 | train_loss  0.84 | eval_loss  0.56\n","| epoch 104/500 | lr 2.00000 | ms/epoch 2742.37800 | train_loss  0.84 | eval_loss  0.56\n","| epoch 105/500 | lr 2.00000 | ms/epoch 2696.64121 | train_loss  0.83 | eval_loss  0.59\n","| epoch 106/500 | lr 2.00000 | ms/epoch 2672.41812 | train_loss  0.83 | eval_loss  0.56\n","| epoch 107/500 | lr 2.00000 | ms/epoch 2815.23585 | train_loss  0.82 | eval_loss  0.58\n","| epoch 108/500 | lr 2.00000 | ms/epoch 2690.27066 | train_loss  0.82 | eval_loss  0.60\n","| epoch 109/500 | lr 2.00000 | ms/epoch 3462.75330 | train_loss  0.83 | eval_loss  0.55\n","| epoch 110/500 | lr 2.00000 | ms/epoch 4554.12126 | train_loss  0.82 | eval_loss  0.56\n","| epoch 111/500 | lr 2.00000 | ms/epoch 4887.47621 | train_loss  0.81 | eval_loss  0.62\n","| epoch 112/500 | lr 2.00000 | ms/epoch 4031.14033 | train_loss  0.81 | eval_loss  0.53\n","| epoch 113/500 | lr 2.00000 | ms/epoch 2687.22200 | train_loss  0.81 | eval_loss  0.57\n","| epoch 114/500 | lr 2.00000 | ms/epoch 2913.18393 | train_loss  0.81 | eval_loss  0.54\n","| epoch 115/500 | lr 2.00000 | ms/epoch 4678.41029 | train_loss  0.81 | eval_loss  0.58\n","| epoch 116/500 | lr 2.00000 | ms/epoch 3002.68960 | train_loss  0.81 | eval_loss  0.55\n","| epoch 117/500 | lr 2.00000 | ms/epoch 3260.31184 | train_loss  0.81 | eval_loss  0.58\n","| epoch 118/500 | lr 2.00000 | ms/epoch 4637.25519 | train_loss  0.80 | eval_loss  0.53\n","| epoch 119/500 | lr 2.00000 | ms/epoch 4207.12996 | train_loss  0.79 | eval_loss  0.56\n","| epoch 120/500 | lr 2.00000 | ms/epoch 4618.41559 | train_loss  0.79 | eval_loss  0.55\n","| epoch 121/500 | lr 2.00000 | ms/epoch 4401.65806 | train_loss  0.80 | eval_loss  0.57\n","| epoch 122/500 | lr 2.00000 | ms/epoch 4324.01204 | train_loss  0.79 | eval_loss  0.56\n","| epoch 123/500 | lr 2.00000 | ms/epoch 4249.99571 | train_loss  0.79 | eval_loss  0.56\n","| epoch 124/500 | lr 2.00000 | ms/epoch 4311.00702 | train_loss  0.78 | eval_loss  0.54\n","| epoch 125/500 | lr 2.00000 | ms/epoch 3410.59470 | train_loss  0.78 | eval_loss  0.54\n","| epoch 126/500 | lr 2.00000 | ms/epoch 2584.78141 | train_loss  0.78 | eval_loss  0.51\n","| epoch 127/500 | lr 2.00000 | ms/epoch 2621.10353 | train_loss  0.78 | eval_loss  0.51\n","| epoch 128/500 | lr 2.00000 | ms/epoch 2592.28373 | train_loss  0.78 | eval_loss  0.59\n","| epoch 129/500 | lr 2.00000 | ms/epoch 2615.56435 | train_loss  0.77 | eval_loss  0.54\n","| epoch 130/500 | lr 2.00000 | ms/epoch 2578.90582 | train_loss  0.77 | eval_loss  0.52\n","| epoch 131/500 | lr 2.00000 | ms/epoch 2635.70142 | train_loss  0.76 | eval_loss  0.52\n","| epoch 132/500 | lr 2.00000 | ms/epoch 2651.00908 | train_loss  0.77 | eval_loss  0.50\n","| epoch 133/500 | lr 2.00000 | ms/epoch 2666.33773 | train_loss  0.77 | eval_loss  0.50\n","| epoch 134/500 | lr 2.00000 | ms/epoch 2608.04367 | train_loss  0.76 | eval_loss  0.52\n","| epoch 135/500 | lr 2.00000 | ms/epoch 2604.12908 | train_loss  0.76 | eval_loss  0.50\n","| epoch 136/500 | lr 2.00000 | ms/epoch 2570.96958 | train_loss  0.76 | eval_loss  0.53\n","| epoch 137/500 | lr 2.00000 | ms/epoch 2586.83443 | train_loss  0.76 | eval_loss  0.50\n","| epoch 138/500 | lr 2.00000 | ms/epoch 2606.92263 | train_loss  0.75 | eval_loss  0.49\n","| epoch 139/500 | lr 2.00000 | ms/epoch 2662.85086 | train_loss  0.75 | eval_loss  0.50\n","| epoch 140/500 | lr 2.00000 | ms/epoch 2576.32399 | train_loss  0.75 | eval_loss  0.52\n","| epoch 141/500 | lr 2.00000 | ms/epoch 2590.56616 | train_loss  0.75 | eval_loss  0.48\n","| epoch 142/500 | lr 2.00000 | ms/epoch 2583.86540 | train_loss  0.74 | eval_loss  0.52\n","| epoch 143/500 | lr 2.00000 | ms/epoch 2580.98054 | train_loss  0.75 | eval_loss  0.50\n","| epoch 144/500 | lr 2.00000 | ms/epoch 2597.68414 | train_loss  0.75 | eval_loss  0.48\n","| epoch 145/500 | lr 2.00000 | ms/epoch 2585.12759 | train_loss  0.74 | eval_loss  0.50\n","| epoch 146/500 | lr 2.00000 | ms/epoch 2617.20562 | train_loss  0.74 | eval_loss  0.50\n","| epoch 147/500 | lr 2.00000 | ms/epoch 2655.66802 | train_loss  0.74 | eval_loss  0.51\n","| epoch 148/500 | lr 2.00000 | ms/epoch 2655.59554 | train_loss  0.74 | eval_loss  0.50\n","| epoch 149/500 | lr 2.00000 | ms/epoch 2572.53838 | train_loss  0.73 | eval_loss  0.50\n","| epoch 150/500 | lr 2.00000 | ms/epoch 2613.41763 | train_loss  0.73 | eval_loss  0.51\n","| epoch 151/500 | lr 2.00000 | ms/epoch 2628.01909 | train_loss  0.73 | eval_loss  0.51\n","| epoch 152/500 | lr 2.00000 | ms/epoch 2576.75505 | train_loss  0.73 | eval_loss  0.49\n","| epoch 153/500 | lr 2.00000 | ms/epoch 2660.51459 | train_loss  0.73 | eval_loss  0.48\n","| epoch 154/500 | lr 2.00000 | ms/epoch 2728.91188 | train_loss  0.73 | eval_loss  0.49\n","| epoch 155/500 | lr 2.00000 | ms/epoch 2692.46507 | train_loss  0.73 | eval_loss  0.50\n","| epoch 156/500 | lr 2.00000 | ms/epoch 2675.68374 | train_loss  0.72 | eval_loss  0.51\n","| epoch 157/500 | lr 2.00000 | ms/epoch 2577.39902 | train_loss  0.72 | eval_loss  0.47\n","| epoch 158/500 | lr 2.00000 | ms/epoch 2715.94620 | train_loss  0.72 | eval_loss  0.47\n","| epoch 159/500 | lr 2.00000 | ms/epoch 2785.51602 | train_loss  0.72 | eval_loss  0.48\n","| epoch 160/500 | lr 2.00000 | ms/epoch 2856.37856 | train_loss  0.71 | eval_loss  0.48\n","| epoch 161/500 | lr 2.00000 | ms/epoch 2766.76679 | train_loss  0.72 | eval_loss  0.46\n","| epoch 162/500 | lr 2.00000 | ms/epoch 2732.80454 | train_loss  0.71 | eval_loss  0.56\n","| epoch 163/500 | lr 2.00000 | ms/epoch 3741.52422 | train_loss  0.71 | eval_loss  0.50\n","| epoch 164/500 | lr 2.00000 | ms/epoch 4481.92906 | train_loss  0.71 | eval_loss  0.50\n","| epoch 165/500 | lr 2.00000 | ms/epoch 4414.27779 | train_loss  0.71 | eval_loss  0.49\n","| epoch 166/500 | lr 2.00000 | ms/epoch 4519.31596 | train_loss  0.71 | eval_loss  0.47\n","| epoch 167/500 | lr 2.00000 | ms/epoch 4082.35025 | train_loss  0.70 | eval_loss  0.50\n","| epoch 168/500 | lr 2.00000 | ms/epoch 4456.03037 | train_loss  0.71 | eval_loss  0.49\n","| epoch 169/500 | lr 2.00000 | ms/epoch 4487.49161 | train_loss  0.71 | eval_loss  0.47\n","| epoch 170/500 | lr 2.00000 | ms/epoch 3493.96396 | train_loss  0.71 | eval_loss  0.46\n","| epoch 171/500 | lr 2.00000 | ms/epoch 2740.35215 | train_loss  0.70 | eval_loss  0.48\n","| epoch 172/500 | lr 2.00000 | ms/epoch 2625.37003 | train_loss  0.70 | eval_loss  0.48\n","| epoch 173/500 | lr 2.00000 | ms/epoch 2654.21271 | train_loss  0.70 | eval_loss  0.45\n","| epoch 174/500 | lr 2.00000 | ms/epoch 2639.90498 | train_loss  0.70 | eval_loss  0.48\n","| epoch 175/500 | lr 2.00000 | ms/epoch 2694.55361 | train_loss  0.70 | eval_loss  0.45\n","| epoch 176/500 | lr 2.00000 | ms/epoch 2612.38718 | train_loss  0.69 | eval_loss  0.49\n","| epoch 177/500 | lr 2.00000 | ms/epoch 2645.07055 | train_loss  0.70 | eval_loss  0.46\n","| epoch 178/500 | lr 2.00000 | ms/epoch 2593.42647 | train_loss  0.69 | eval_loss  0.48\n","| epoch 179/500 | lr 2.00000 | ms/epoch 2631.45733 | train_loss  0.69 | eval_loss  0.45\n","| epoch 180/500 | lr 2.00000 | ms/epoch 2656.98576 | train_loss  0.69 | eval_loss  0.46\n","| epoch 181/500 | lr 2.00000 | ms/epoch 2677.96016 | train_loss  0.69 | eval_loss  0.44\n","| epoch 182/500 | lr 2.00000 | ms/epoch 2710.03675 | train_loss  0.69 | eval_loss  0.45\n","| epoch 183/500 | lr 2.00000 | ms/epoch 2665.80272 | train_loss  0.68 | eval_loss  0.44\n","| epoch 184/500 | lr 2.00000 | ms/epoch 2753.42989 | train_loss  0.68 | eval_loss  0.45\n","| epoch 185/500 | lr 2.00000 | ms/epoch 2698.60172 | train_loss  0.68 | eval_loss  0.47\n","| epoch 186/500 | lr 2.00000 | ms/epoch 2619.11607 | train_loss  0.68 | eval_loss  0.49\n","| epoch 187/500 | lr 2.00000 | ms/epoch 2615.55290 | train_loss  0.68 | eval_loss  0.46\n","| epoch 188/500 | lr 2.00000 | ms/epoch 2644.99092 | train_loss  0.68 | eval_loss  0.47\n","| epoch 189/500 | lr 2.00000 | ms/epoch 2629.91452 | train_loss  0.68 | eval_loss  0.46\n","| epoch 190/500 | lr 2.00000 | ms/epoch 2651.08919 | train_loss  0.68 | eval_loss  0.45\n","| epoch 191/500 | lr 2.00000 | ms/epoch 2601.20749 | train_loss  0.67 | eval_loss  0.46\n","| epoch 192/500 | lr 2.00000 | ms/epoch 2634.21392 | train_loss  0.67 | eval_loss  0.47\n","| epoch 193/500 | lr 2.00000 | ms/epoch 2612.13994 | train_loss  0.67 | eval_loss  0.45\n","| epoch 194/500 | lr 2.00000 | ms/epoch 2666.60953 | train_loss  0.68 | eval_loss  0.46\n","| epoch 195/500 | lr 2.00000 | ms/epoch 2630.44238 | train_loss  0.67 | eval_loss  0.46\n","| epoch 196/500 | lr 2.00000 | ms/epoch 2631.56080 | train_loss  0.67 | eval_loss  0.44\n","| epoch 197/500 | lr 2.00000 | ms/epoch 2654.71506 | train_loss  0.67 | eval_loss  0.46\n","\n","\n"," TRAINING FINISHED:\n","\n","\tBest Loss:  0.44\tBest Model saved at epoch: 183 \n","\n","\n","\n","\n","TEST LOSS: 0.5230123629172643\n","| epoch   1/500 | lr 2.00000 | ms/epoch 2793.24198 | train_loss  3.47 | eval_loss  3.69\n","| epoch   2/500 | lr 2.00000 | ms/epoch 2702.35515 | train_loss  3.28 | eval_loss  3.23\n","| epoch   3/500 | lr 2.00000 | ms/epoch 2658.61869 | train_loss  3.10 | eval_loss  3.13\n","| epoch   4/500 | lr 2.00000 | ms/epoch 2673.56610 | train_loss  3.00 | eval_loss  3.05\n","| epoch   5/500 | lr 2.00000 | ms/epoch 2658.74553 | train_loss  2.93 | eval_loss  3.08\n","| epoch   6/500 | lr 2.00000 | ms/epoch 2685.52184 | train_loss  2.86 | eval_loss  2.78\n","| epoch   7/500 | lr 2.00000 | ms/epoch 2695.10460 | train_loss  2.74 | eval_loss  2.69\n","| epoch   8/500 | lr 2.00000 | ms/epoch 3650.88463 | train_loss  2.63 | eval_loss  2.48\n","| epoch   9/500 | lr 2.00000 | ms/epoch 4181.66447 | train_loss  2.53 | eval_loss  2.54\n","| epoch  10/500 | lr 2.00000 | ms/epoch 2653.03802 | train_loss  2.48 | eval_loss  2.38\n","| epoch  11/500 | lr 2.00000 | ms/epoch 2680.19056 | train_loss  2.41 | eval_loss  2.25\n","| epoch  12/500 | lr 2.00000 | ms/epoch 2731.99248 | train_loss  2.36 | eval_loss  2.16\n","| epoch  13/500 | lr 2.00000 | ms/epoch 2797.85275 | train_loss  2.29 | eval_loss  2.13\n","| epoch  14/500 | lr 2.00000 | ms/epoch 2738.25955 | train_loss  2.24 | eval_loss  2.09\n","| epoch  15/500 | lr 2.00000 | ms/epoch 2723.20819 | train_loss  2.18 | eval_loss  2.05\n","| epoch  16/500 | lr 2.00000 | ms/epoch 2672.50514 | train_loss  2.14 | eval_loss  1.99\n","| epoch  17/500 | lr 2.00000 | ms/epoch 2689.67819 | train_loss  2.07 | eval_loss  1.85\n","| epoch  18/500 | lr 2.00000 | ms/epoch 2667.13810 | train_loss  2.01 | eval_loss  1.82\n","| epoch  19/500 | lr 2.00000 | ms/epoch 2707.77869 | train_loss  1.97 | eval_loss  1.74\n","| epoch  20/500 | lr 2.00000 | ms/epoch 2569.77534 | train_loss  1.92 | eval_loss  1.72\n","| epoch  21/500 | lr 2.00000 | ms/epoch 3139.71543 | train_loss  1.87 | eval_loss  1.64\n","| epoch  22/500 | lr 2.00000 | ms/epoch 4536.99994 | train_loss  1.82 | eval_loss  1.62\n","| epoch  23/500 | lr 2.00000 | ms/epoch 4681.89573 | train_loss  1.78 | eval_loss  1.55\n","| epoch  24/500 | lr 2.00000 | ms/epoch 4781.37827 | train_loss  1.73 | eval_loss  1.53\n","| epoch  25/500 | lr 2.00000 | ms/epoch 4759.54652 | train_loss  1.70 | eval_loss  1.48\n","| epoch  26/500 | lr 2.00000 | ms/epoch 3772.33171 | train_loss  1.66 | eval_loss  1.43\n","| epoch  27/500 | lr 2.00000 | ms/epoch 2715.56783 | train_loss  1.63 | eval_loss  1.42\n","| epoch  28/500 | lr 2.00000 | ms/epoch 2663.32746 | train_loss  1.60 | eval_loss  1.38\n","| epoch  29/500 | lr 2.00000 | ms/epoch 2665.44294 | train_loss  1.58 | eval_loss  1.34\n","| epoch  30/500 | lr 2.00000 | ms/epoch 2669.86084 | train_loss  1.54 | eval_loss  1.32\n","| epoch  31/500 | lr 2.00000 | ms/epoch 2652.15945 | train_loss  1.53 | eval_loss  1.25\n","| epoch  32/500 | lr 2.00000 | ms/epoch 2664.14785 | train_loss  1.50 | eval_loss  1.23\n","| epoch  33/500 | lr 2.00000 | ms/epoch 2670.90464 | train_loss  1.47 | eval_loss  1.23\n","| epoch  34/500 | lr 2.00000 | ms/epoch 2673.19155 | train_loss  1.45 | eval_loss  1.17\n","| epoch  35/500 | lr 2.00000 | ms/epoch 2716.78662 | train_loss  1.43 | eval_loss  1.21\n","| epoch  36/500 | lr 2.00000 | ms/epoch 2656.15869 | train_loss  1.41 | eval_loss  1.16\n","| epoch  37/500 | lr 2.00000 | ms/epoch 3004.31824 | train_loss  1.39 | eval_loss  1.16\n","| epoch  38/500 | lr 2.00000 | ms/epoch 2879.29368 | train_loss  1.37 | eval_loss  1.10\n","| epoch  39/500 | lr 2.00000 | ms/epoch 2735.38876 | train_loss  1.35 | eval_loss  1.09\n","| epoch  40/500 | lr 2.00000 | ms/epoch 2663.20944 | train_loss  1.34 | eval_loss  1.12\n","| epoch  41/500 | lr 2.00000 | ms/epoch 2674.37816 | train_loss  1.32 | eval_loss  1.08\n","| epoch  42/500 | lr 2.00000 | ms/epoch 2729.96712 | train_loss  1.30 | eval_loss  1.05\n","| epoch  43/500 | lr 2.00000 | ms/epoch 2704.09226 | train_loss  1.30 | eval_loss  1.03\n","| epoch  44/500 | lr 2.00000 | ms/epoch 2665.85422 | train_loss  1.28 | eval_loss  1.02\n","| epoch  45/500 | lr 2.00000 | ms/epoch 2672.78361 | train_loss  1.26 | eval_loss  1.00\n","| epoch  46/500 | lr 2.00000 | ms/epoch 2593.40763 | train_loss  1.25 | eval_loss  1.02\n","| epoch  47/500 | lr 2.00000 | ms/epoch 2625.80943 | train_loss  1.24 | eval_loss  1.02\n","| epoch  48/500 | lr 2.00000 | ms/epoch 2587.37230 | train_loss  1.22 | eval_loss  0.95\n","| epoch  49/500 | lr 2.00000 | ms/epoch 2760.84089 | train_loss  1.21 | eval_loss  0.93\n","| epoch  50/500 | lr 2.00000 | ms/epoch 2790.60864 | train_loss  1.20 | eval_loss  1.00\n","| epoch  51/500 | lr 2.00000 | ms/epoch 2770.54334 | train_loss  1.19 | eval_loss  0.91\n","| epoch  52/500 | lr 2.00000 | ms/epoch 2776.16858 | train_loss  1.17 | eval_loss  0.92\n","| epoch  53/500 | lr 2.00000 | ms/epoch 2741.07862 | train_loss  1.16 | eval_loss  0.89\n","| epoch  54/500 | lr 2.00000 | ms/epoch 2698.00568 | train_loss  1.15 | eval_loss  0.84\n","| epoch  55/500 | lr 2.00000 | ms/epoch 2686.43403 | train_loss  1.13 | eval_loss  0.92\n","| epoch  56/500 | lr 2.00000 | ms/epoch 2690.30809 | train_loss  1.13 | eval_loss  0.84\n","| epoch  57/500 | lr 2.00000 | ms/epoch 2710.90055 | train_loss  1.11 | eval_loss  0.82\n","| epoch  58/500 | lr 2.00000 | ms/epoch 2665.65132 | train_loss  1.10 | eval_loss  0.83\n","| epoch  59/500 | lr 2.00000 | ms/epoch 2731.71544 | train_loss  1.08 | eval_loss  0.80\n","| epoch  60/500 | lr 2.00000 | ms/epoch 2710.14595 | train_loss  1.08 | eval_loss  0.78\n","| epoch  61/500 | lr 2.00000 | ms/epoch 2678.80201 | train_loss  1.07 | eval_loss  0.82\n","| epoch  62/500 | lr 2.00000 | ms/epoch 4222.94807 | train_loss  1.05 | eval_loss  0.77\n","| epoch  63/500 | lr 2.00000 | ms/epoch 4741.36758 | train_loss  1.05 | eval_loss  0.77\n","| epoch  64/500 | lr 2.00000 | ms/epoch 2764.34469 | train_loss  1.03 | eval_loss  0.76\n","| epoch  65/500 | lr 2.00000 | ms/epoch 2697.85452 | train_loss  1.03 | eval_loss  0.76\n","| epoch  66/500 | lr 2.00000 | ms/epoch 2667.46950 | train_loss  1.02 | eval_loss  0.76\n","| epoch  67/500 | lr 2.00000 | ms/epoch 2688.49564 | train_loss  1.01 | eval_loss  0.72\n","| epoch  68/500 | lr 2.00000 | ms/epoch 2693.85862 | train_loss  1.00 | eval_loss  0.73\n","| epoch  69/500 | lr 2.00000 | ms/epoch 2676.02658 | train_loss  1.00 | eval_loss  0.70\n","| epoch  70/500 | lr 2.00000 | ms/epoch 2696.73014 | train_loss  0.98 | eval_loss  0.76\n","| epoch  71/500 | lr 2.00000 | ms/epoch 2671.48280 | train_loss  0.98 | eval_loss  0.70\n","| epoch  72/500 | lr 2.00000 | ms/epoch 2689.71014 | train_loss  0.97 | eval_loss  0.69\n","| epoch  73/500 | lr 2.00000 | ms/epoch 2674.46041 | train_loss  0.96 | eval_loss  0.68\n","| epoch  74/500 | lr 2.00000 | ms/epoch 2686.93662 | train_loss  0.96 | eval_loss  0.68\n","| epoch  75/500 | lr 2.00000 | ms/epoch 2773.13638 | train_loss  0.96 | eval_loss  0.67\n","| epoch  76/500 | lr 2.00000 | ms/epoch 4942.53922 | train_loss  0.94 | eval_loss  0.66\n","| epoch  77/500 | lr 2.00000 | ms/epoch 4749.89605 | train_loss  0.93 | eval_loss  0.70\n","| epoch  78/500 | lr 2.00000 | ms/epoch 2666.63241 | train_loss  0.93 | eval_loss  0.64\n","| epoch  79/500 | lr 2.00000 | ms/epoch 2658.33735 | train_loss  0.92 | eval_loss  0.63\n","| epoch  80/500 | lr 2.00000 | ms/epoch 2680.58944 | train_loss  0.92 | eval_loss  0.63\n","| epoch  81/500 | lr 2.00000 | ms/epoch 2655.47585 | train_loss  0.91 | eval_loss  0.64\n","| epoch  82/500 | lr 2.00000 | ms/epoch 2655.87950 | train_loss  0.91 | eval_loss  0.62\n","| epoch  83/500 | lr 2.00000 | ms/epoch 2650.63167 | train_loss  0.89 | eval_loss  0.65\n","| epoch  84/500 | lr 2.00000 | ms/epoch 2697.52836 | train_loss  0.88 | eval_loss  0.63\n","| epoch  85/500 | lr 2.00000 | ms/epoch 2600.17204 | train_loss  0.89 | eval_loss  0.60\n","| epoch  86/500 | lr 2.00000 | ms/epoch 2694.94581 | train_loss  0.88 | eval_loss  0.59\n","| epoch  87/500 | lr 2.00000 | ms/epoch 2725.10886 | train_loss  0.87 | eval_loss  0.57\n","| epoch  88/500 | lr 2.00000 | ms/epoch 2715.74044 | train_loss  0.87 | eval_loss  0.60\n","| epoch  89/500 | lr 2.00000 | ms/epoch 2834.51772 | train_loss  0.87 | eval_loss  0.58\n","| epoch  90/500 | lr 2.00000 | ms/epoch 5124.81689 | train_loss  0.86 | eval_loss  0.58\n","| epoch  91/500 | lr 2.00000 | ms/epoch 3874.92728 | train_loss  0.85 | eval_loss  0.58\n","| epoch  92/500 | lr 2.00000 | ms/epoch 2640.42950 | train_loss  0.85 | eval_loss  0.63\n","| epoch  93/500 | lr 2.00000 | ms/epoch 2699.96858 | train_loss  0.85 | eval_loss  0.59\n","| epoch  94/500 | lr 2.00000 | ms/epoch 2648.63920 | train_loss  0.84 | eval_loss  0.59\n","| epoch  95/500 | lr 2.00000 | ms/epoch 2691.04981 | train_loss  0.83 | eval_loss  0.58\n","| epoch  96/500 | lr 2.00000 | ms/epoch 2649.62626 | train_loss  0.83 | eval_loss  0.56\n","| epoch  97/500 | lr 2.00000 | ms/epoch 2699.11218 | train_loss  0.83 | eval_loss  0.64\n","| epoch  98/500 | lr 2.00000 | ms/epoch 2621.15741 | train_loss  0.83 | eval_loss  0.59\n","| epoch  99/500 | lr 2.00000 | ms/epoch 2664.73579 | train_loss  0.82 | eval_loss  0.55\n","| epoch 100/500 | lr 2.00000 | ms/epoch 2606.63247 | train_loss  0.81 | eval_loss  0.56\n","| epoch 101/500 | lr 2.00000 | ms/epoch 2731.35185 | train_loss  0.82 | eval_loss  0.53\n","| epoch 102/500 | lr 2.00000 | ms/epoch 2937.97588 | train_loss  0.82 | eval_loss  0.52\n","| epoch 103/500 | lr 2.00000 | ms/epoch 3006.29139 | train_loss  0.81 | eval_loss  0.56\n","| epoch 104/500 | lr 2.00000 | ms/epoch 2868.51335 | train_loss  0.80 | eval_loss  0.55\n","| epoch 105/500 | lr 2.00000 | ms/epoch 2697.60442 | train_loss  0.80 | eval_loss  0.53\n","| epoch 106/500 | lr 2.00000 | ms/epoch 2664.78992 | train_loss  0.80 | eval_loss  0.57\n","| epoch 107/500 | lr 2.00000 | ms/epoch 2681.98419 | train_loss  0.79 | eval_loss  0.55\n","| epoch 108/500 | lr 2.00000 | ms/epoch 2722.21255 | train_loss  0.80 | eval_loss  0.56\n","| epoch 109/500 | lr 2.00000 | ms/epoch 2638.90481 | train_loss  0.79 | eval_loss  0.52\n","| epoch 110/500 | lr 2.00000 | ms/epoch 2654.42681 | train_loss  0.78 | eval_loss  0.52\n","| epoch 111/500 | lr 2.00000 | ms/epoch 2687.04462 | train_loss  0.79 | eval_loss  0.56\n","| epoch 112/500 | lr 2.00000 | ms/epoch 2683.15649 | train_loss  0.78 | eval_loss  0.53\n","| epoch 113/500 | lr 2.00000 | ms/epoch 2640.37085 | train_loss  0.78 | eval_loss  0.52\n","| epoch 114/500 | lr 2.00000 | ms/epoch 2638.29112 | train_loss  0.77 | eval_loss  0.53\n","| epoch 115/500 | lr 2.00000 | ms/epoch 3879.36735 | train_loss  0.77 | eval_loss  0.52\n","| epoch 116/500 | lr 2.00000 | ms/epoch 4234.77983 | train_loss  0.77 | eval_loss  0.52\n","| epoch 117/500 | lr 2.00000 | ms/epoch 2741.35876 | train_loss  0.76 | eval_loss  0.51\n","| epoch 118/500 | lr 2.00000 | ms/epoch 2737.33950 | train_loss  0.77 | eval_loss  0.53\n","| epoch 119/500 | lr 2.00000 | ms/epoch 2692.79313 | train_loss  0.76 | eval_loss  0.50\n","| epoch 120/500 | lr 2.00000 | ms/epoch 2700.72079 | train_loss  0.76 | eval_loss  0.50\n","| epoch 121/500 | lr 2.00000 | ms/epoch 2671.27562 | train_loss  0.76 | eval_loss  0.55\n","| epoch 122/500 | lr 2.00000 | ms/epoch 2692.62838 | train_loss  0.76 | eval_loss  0.54\n","| epoch 123/500 | lr 2.00000 | ms/epoch 2664.81137 | train_loss  0.75 | eval_loss  0.51\n","| epoch 124/500 | lr 2.00000 | ms/epoch 2680.81284 | train_loss  0.75 | eval_loss  0.52\n","| epoch 125/500 | lr 2.00000 | ms/epoch 2672.26505 | train_loss  0.75 | eval_loss  0.51\n","| epoch 126/500 | lr 2.00000 | ms/epoch 2701.85709 | train_loss  0.74 | eval_loss  0.51\n","| epoch 127/500 | lr 2.00000 | ms/epoch 2677.08731 | train_loss  0.74 | eval_loss  0.49\n","| epoch 128/500 | lr 2.00000 | ms/epoch 3652.56381 | train_loss  0.74 | eval_loss  0.52\n","| epoch 129/500 | lr 2.00000 | ms/epoch 4753.22437 | train_loss  0.74 | eval_loss  0.49\n","| epoch 130/500 | lr 2.00000 | ms/epoch 3213.32145 | train_loss  0.74 | eval_loss  0.52\n","| epoch 131/500 | lr 2.00000 | ms/epoch 2705.47342 | train_loss  0.73 | eval_loss  0.52\n","| epoch 132/500 | lr 2.00000 | ms/epoch 2742.11955 | train_loss  0.73 | eval_loss  0.49\n","| epoch 133/500 | lr 2.00000 | ms/epoch 2697.69287 | train_loss  0.72 | eval_loss  0.55\n","| epoch 134/500 | lr 2.00000 | ms/epoch 2591.51459 | train_loss  0.73 | eval_loss  0.47\n","| epoch 135/500 | lr 2.00000 | ms/epoch 2651.04747 | train_loss  0.73 | eval_loss  0.50\n","| epoch 136/500 | lr 2.00000 | ms/epoch 2813.30371 | train_loss  0.72 | eval_loss  0.48\n","| epoch 137/500 | lr 2.00000 | ms/epoch 2681.68545 | train_loss  0.72 | eval_loss  0.50\n","| epoch 138/500 | lr 2.00000 | ms/epoch 2681.52308 | train_loss  0.72 | eval_loss  0.51\n","| epoch 139/500 | lr 2.00000 | ms/epoch 2653.62787 | train_loss  0.72 | eval_loss  0.49\n","| epoch 140/500 | lr 2.00000 | ms/epoch 4283.60724 | train_loss  0.72 | eval_loss  0.46\n","| epoch 141/500 | lr 2.00000 | ms/epoch 3604.61855 | train_loss  0.72 | eval_loss  0.46\n","| epoch 142/500 | lr 2.00000 | ms/epoch 2662.50873 | train_loss  0.71 | eval_loss  0.46\n","| epoch 143/500 | lr 2.00000 | ms/epoch 2656.20232 | train_loss  0.70 | eval_loss  0.47\n","| epoch 144/500 | lr 2.00000 | ms/epoch 2637.38441 | train_loss  0.70 | eval_loss  0.51\n","| epoch 145/500 | lr 2.00000 | ms/epoch 2658.67949 | train_loss  0.70 | eval_loss  0.47\n","| epoch 146/500 | lr 2.00000 | ms/epoch 2653.28050 | train_loss  0.70 | eval_loss  0.46\n","| epoch 147/500 | lr 2.00000 | ms/epoch 2664.90865 | train_loss  0.70 | eval_loss  0.47\n","| epoch 148/500 | lr 2.00000 | ms/epoch 2644.57607 | train_loss  0.70 | eval_loss  0.46\n","| epoch 149/500 | lr 2.00000 | ms/epoch 2648.47636 | train_loss  0.70 | eval_loss  0.50\n","| epoch 150/500 | lr 2.00000 | ms/epoch 2694.15808 | train_loss  0.70 | eval_loss  0.46\n","| epoch 151/500 | lr 2.00000 | ms/epoch 2743.78777 | train_loss  0.69 | eval_loss  0.44\n","| epoch 152/500 | lr 2.00000 | ms/epoch 2771.53277 | train_loss  0.70 | eval_loss  0.44\n","| epoch 153/500 | lr 2.00000 | ms/epoch 4097.37945 | train_loss  0.69 | eval_loss  0.48\n","| epoch 154/500 | lr 2.00000 | ms/epoch 5456.47764 | train_loss  0.69 | eval_loss  0.46\n","| epoch 155/500 | lr 2.00000 | ms/epoch 4547.88756 | train_loss  0.69 | eval_loss  0.46\n","| epoch 156/500 | lr 2.00000 | ms/epoch 4644.38295 | train_loss  0.69 | eval_loss  0.45\n","| epoch 157/500 | lr 2.00000 | ms/epoch 4899.71256 | train_loss  0.69 | eval_loss  0.44\n","| epoch 158/500 | lr 2.00000 | ms/epoch 4704.48112 | train_loss  0.68 | eval_loss  0.46\n","| epoch 159/500 | lr 2.00000 | ms/epoch 4712.25858 | train_loss  0.69 | eval_loss  0.47\n","| epoch 160/500 | lr 2.00000 | ms/epoch 4676.80693 | train_loss  0.68 | eval_loss  0.45\n","| epoch 161/500 | lr 2.00000 | ms/epoch 5330.80578 | train_loss  0.68 | eval_loss  0.46\n","| epoch 162/500 | lr 2.00000 | ms/epoch 5181.61583 | train_loss  0.68 | eval_loss  0.49\n","| epoch 163/500 | lr 2.00000 | ms/epoch 4716.53843 | train_loss  0.67 | eval_loss  0.46\n","| epoch 164/500 | lr 2.00000 | ms/epoch 4674.54457 | train_loss  0.67 | eval_loss  0.47\n","| epoch 165/500 | lr 2.00000 | ms/epoch 4595.38198 | train_loss  0.68 | eval_loss  0.44\n","| epoch 166/500 | lr 2.00000 | ms/epoch 2901.52216 | train_loss  0.67 | eval_loss  0.42\n","| epoch 167/500 | lr 2.00000 | ms/epoch 2677.06394 | train_loss  0.67 | eval_loss  0.45\n","| epoch 168/500 | lr 2.00000 | ms/epoch 2686.53941 | train_loss  0.67 | eval_loss  0.44\n","| epoch 169/500 | lr 2.00000 | ms/epoch 2615.00502 | train_loss  0.67 | eval_loss  0.47\n","| epoch 170/500 | lr 2.00000 | ms/epoch 2625.11992 | train_loss  0.67 | eval_loss  0.43\n","| epoch 171/500 | lr 2.00000 | ms/epoch 2625.49329 | train_loss  0.66 | eval_loss  0.42\n","| epoch 172/500 | lr 2.00000 | ms/epoch 2677.86670 | train_loss  0.66 | eval_loss  0.42\n","| epoch 173/500 | lr 2.00000 | ms/epoch 2656.75163 | train_loss  0.66 | eval_loss  0.41\n","| epoch 174/500 | lr 2.00000 | ms/epoch 2748.37613 | train_loss  0.66 | eval_loss  0.43\n","| epoch 175/500 | lr 2.00000 | ms/epoch 2749.55845 | train_loss  0.66 | eval_loss  0.42\n","| epoch 176/500 | lr 2.00000 | ms/epoch 2600.46697 | train_loss  0.66 | eval_loss  0.45\n","| epoch 177/500 | lr 2.00000 | ms/epoch 2729.83694 | train_loss  0.66 | eval_loss  0.43\n","| epoch 178/500 | lr 2.00000 | ms/epoch 4486.75275 | train_loss  0.66 | eval_loss  0.45\n","| epoch 179/500 | lr 2.00000 | ms/epoch 4265.05399 | train_loss  0.65 | eval_loss  0.47\n","| epoch 180/500 | lr 2.00000 | ms/epoch 4357.70416 | train_loss  0.66 | eval_loss  0.46\n","| epoch 181/500 | lr 2.00000 | ms/epoch 4370.12124 | train_loss  0.66 | eval_loss  0.42\n","| epoch 182/500 | lr 2.00000 | ms/epoch 4669.09027 | train_loss  0.65 | eval_loss  0.42\n","| epoch 183/500 | lr 2.00000 | ms/epoch 4536.31592 | train_loss  0.65 | eval_loss  0.45\n","| epoch 184/500 | lr 2.00000 | ms/epoch 4565.01865 | train_loss  0.65 | eval_loss  0.43\n","| epoch 185/500 | lr 2.00000 | ms/epoch 5106.18401 | train_loss  0.65 | eval_loss  0.45\n","| epoch 186/500 | lr 2.00000 | ms/epoch 4757.65443 | train_loss  0.65 | eval_loss  0.48\n","| epoch 187/500 | lr 2.00000 | ms/epoch 5002.92563 | train_loss  0.65 | eval_loss  0.42\n","\n","\n"," TRAINING FINISHED:\n","\n","\tBest Loss:  0.41\tBest Model saved at epoch: 173 \n","\n","\n","\n","\n","TEST LOSS: 0.5261727790037791\n"]},{"data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# MODEL PARAMETERS\n","TRAIN_MODEL = True\n","\n","EPOCHS = 500 # 500\n","LEARNING_RATE = 2 # 4\n","BATCH_SIZE = 16 # 16\n","EARLY_STOP = True\n","\n","FEEDBACK = False\n","EMPHASIZE_EEG = False\n","model, criterion, optimizer = initialize_model()\n","train('results/model')\n","\n","FEEDBACK = False\n","EMPHASIZE_EEG = True\n","model, criterion, optimizer = initialize_model()\n","train('results/model_EEG')\n","\n","FEEDBACK = True\n","EMPHASIZE_EEG = False\n","model, criterion, optimizer = initialize_model()\n","train('results/model_feedback')\n","\n","FEEDBACK = True\n","EMPHASIZE_EEG = True\n","model, criterion, optimizer = initialize_model()\n","train('results/model_EEG_feedback')\n","\n","# if TRAIN_MODEL:\n","\n","#   for i in range(2):\n","\n","#     if i == 0:\n","#       FEEDBACK = False\n","#     else:\n","#       FEEDBACK = True\n","\n","#     BATCH_SIZE = 4\n","#     LEARNING_RATE = 1.0\n","#     model, criterion, optimizer = initialize_model()\n","#     train()\n","\n","#     LEARNING_RATE = 2.0\n","#     model, criterion, optimizer = initialize_model()\n","#     train()\n","\n","#     LEARNING_RATE = 4.0\n","#     model, criterion, optimizer = initialize_model()\n","#     train()\n","\n","#     LEARNING_RATE = 1.0\n","#     BATCH_SIZE = 8\n","#     train_dataloader, eval_dataloader, test_dataloader = initialize_dataset()\n","#     model, criterion, optimizer = initialize_model()\n","#     train()\n","\n","#     BATCH_SIZE = 16\n","#     train_dataloader, eval_dataloader, test_dataloader = initialize_dataset()\n","#     model, criterion, optimizer = initialize_model()\n","#     train()\n","\n","#     BATCH_SIZE = 32\n","#     train_dataloader, eval_dataloader, test_dataloader = initialize_dataset()\n","#     model, criterion, optimizer = initialize_model()\n","#     train()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/marc0bortolotti/Affective-AI-Music-Improviser/blob/main/TCN/training.ipynb","timestamp":1720018338190}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
