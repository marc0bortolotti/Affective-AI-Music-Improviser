{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, random_split\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from word_cnn.model import TCN\n",
    "from MIDI.PRETTY_MIDI.pretty_midi_tokenization import PrettyMidiTokenizer, SILENCE_TOKEN\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',504)\n",
    "pd.set_option('display.width',1000)\n",
    "\n",
    "\n",
    "DIRECTORY_PATH = './'\n",
    "DATASET_PATH = os.path.join(DIRECTORY_PATH, 'dataset')\n",
    "MODEL_PATH = os.path.join(DIRECTORY_PATH, 'model')\n",
    "\n",
    "\n",
    "EPOCHS = 500 # 500\n",
    "LEARNING_RATE = 4\n",
    "BATCH_SIZE = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input files: 1\n",
      "Number of output files: 1\n",
      "\n",
      "\n",
      "1: drum_excited.MID -> bass_example.MID\n",
      "\n",
      "Number of input bars: 24\n",
      "Number of input sequences: 20\n",
      "Input sequence length: 192\n",
      "Input vocabulars size: 13\n",
      "\n",
      "Number of output bars: 11\n",
      "Number of output sequences: 7\n",
      "Output sequence length: 192\n",
      "Output vocabulars size: 30\n",
      "\n",
      "Number of sequences after truncation: 7, 7\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Assumptions:\n",
    "Sequences described as input_#.mid and output_#.mid in the corresponding folders\n",
    "'''\n",
    "\n",
    "input_filenames = glob.glob(os.path.join(DATASET_PATH, 'input/*.MID'))\n",
    "print('Number of input files:', len(input_filenames))\n",
    "\n",
    "output_filenames = glob.glob(os.path.join(DATASET_PATH, 'output/*.MID'))\n",
    "print('Number of output files:', len(output_filenames))\n",
    "\n",
    "\n",
    "for i, (in_file, out_file) in enumerate(zip(input_filenames, output_filenames)):\n",
    "\n",
    "    in_file_name = os.path.basename(in_file)\n",
    "    out_file_name = os.path.basename(out_file)\n",
    "    print(f'\\n\\n{i + 1}: {in_file_name} -> {out_file_name}')\n",
    "\n",
    "    input = PrettyMidiTokenizer(in_file)\n",
    "    print(f'\\nNumber of input bars: {input.num_bars}')\n",
    "    print(f'Number of input sequences: {len(input.sequences)}')\n",
    "    print(f'Input sequence length: {len(input.sequences[0])}')\n",
    "    print(f'Input vocabulars size: {len(input.VOCAB)}')\n",
    "\n",
    "    output = PrettyMidiTokenizer(out_file)\n",
    "    print(f'\\nNumber of output bars: {output.num_bars}')\n",
    "    print(f'Number of output sequences: {len(output.sequences)}')\n",
    "    print(f'Output sequence length: {len(output.sequences[0])}')\n",
    "    print(f'Output vocabulars size: {len(output.VOCAB)}')\n",
    "\n",
    "    min_length = min(len(input.sequences), len(output.sequences))\n",
    "    input.sequences = input.sequences[:min_length]\n",
    "    output.sequences = output.sequences[:min_length]\n",
    "    print(f'\\nNumber of sequences after truncation: {len(input.sequences)}, {len(output.sequences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 5\n",
      "Evaluation set size: 1\n",
      "Test set size: 1\n"
     ]
    }
   ],
   "source": [
    "# convert the sequences to LongTensor for PyTorch\n",
    "input_data = torch.LongTensor(input.sequences).to(device)\n",
    "output_data = torch.LongTensor(output.sequences).to(device)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = TensorDataset(input_data, output_data)\n",
    "\n",
    "# Split the dataset into training, evaluation and test sets\n",
    "train_set, eval_set, test_set = random_split(dataset, [0.6, 0.2, 0.2])\n",
    "\n",
    "# Create the dataloaders\n",
    "train_sampler = RandomSampler(train_set)          \n",
    "train_dataloader = DataLoader(train_set, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "eval_sampler = RandomSampler(eval_set)\n",
    "eval_dataloader = DataLoader(eval_set, sampler=eval_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_sampler = RandomSampler(test_set)\n",
    "test_dataloader = DataLoader(test_set, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f'Train set size: {len(train_set)}')\n",
    "print(f'Evaluation set size: {len(eval_set)}')\n",
    "print(f'Test set size: {len(test_set)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192, 192, 192, 192, 192, 192, 20]\n"
     ]
    }
   ],
   "source": [
    "# Set the hyperparameters\n",
    "SEED = 1111 \n",
    "OUTPUT_VOCAB_SIZE = len(output.VOCAB)\n",
    "EMBEDDING_SIZE = 20 # size of word embeddings -> Embedding() is used to encode input token into [192, 20] vectors (see model.py)\n",
    "LEVELS = 7\n",
    "HIDDEN_UNITS = 192\n",
    "NUM_CHANNELS = [HIDDEN_UNITS] * (LEVELS - 1) + [EMBEDDING_SIZE]\n",
    "GRADIENT_CLIP = 0.35\n",
    "\n",
    "\n",
    "# reduce the weights of the silence token since it is overrepresented in the dataset\n",
    "silence_id = output.VOCAB.word2idx[SILENCE_TOKEN]\n",
    "LOSS_WEIGTHS = torch.ones([OUTPUT_VOCAB_SIZE], dtype=torch.float)\n",
    "LOSS_WEIGTHS[silence_id] = 0.3\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = TCN(input_size = EMBEDDING_SIZE, \n",
    "            output_size = OUTPUT_VOCAB_SIZE, \n",
    "            num_channels = NUM_CHANNELS, \n",
    "            dropout = 0.45, \n",
    "            emb_dropout = 0.25, \n",
    "            kernel_size = 3, \n",
    "            tied_weights = False) # tie encoder and decoder weights (legare)\n",
    "\n",
    "\n",
    "# May use adaptive softmax to speed up training\n",
    "torch.manual_seed(SEED)\n",
    "criterion = nn.CrossEntropyLoss(weight = LOSS_WEIGTHS)\n",
    "optimizer = getattr(optim, 'SGD')(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAR_LENGTH = input.BAR_LENGTH\n",
    "LOG_INTERVAL = 1 # report interval\n",
    "\n",
    "\n",
    "def train(dataloader, epoch):\n",
    "    # Turn on training mode which enables dropout.\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # iterate over the training data\n",
    "    for batch_idx, (data, targets) in enumerate(dataloader):\n",
    "\n",
    "        batch_idx += 1\n",
    "\n",
    "        # mask the last bar of the input data \n",
    "        batch_size = data.size(0)\n",
    "        data_masked = torch.cat((data[:, :BAR_LENGTH*3], torch.ones([batch_size, BAR_LENGTH], dtype=torch.long)), dim = 1)\n",
    "\n",
    "        # reset model gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # make the prediction\n",
    "        output = model(data_masked)\n",
    "\n",
    "        # flatten the output sequence\n",
    "        # NB: the size -1 is inferred from other dimensions\n",
    "        # NB: contiguous() is used to make sure the tensor is stored in a contiguous chunk of memory, necessary for view() to work\n",
    "        final_target = targets.contiguous().view(-1)\n",
    "        final_output = output.contiguous().view(-1, OUTPUT_VOCAB_SIZE)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(final_output, final_target)\n",
    "\n",
    "        # calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        if GRADIENT_CLIP > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data.item()\n",
    "\n",
    "        # print the loss and the progress\n",
    "        if batch_idx % LOG_INTERVAL == 0 and batch_idx > 0:\n",
    "            current_loss = total_loss / LOG_INTERVAL\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.5f} | ms/batch {:5.5f} | '\n",
    "                    'loss {:5.2f} | ppl {:8.2f}'.format(epoch, \n",
    "                                                        batch_idx, \n",
    "                                                        len(train_dataloader), \n",
    "                                                        LEARNING_RATE,\n",
    "                                                        elapsed * 1000 / LOG_INTERVAL,\n",
    "                                                        current_loss, \n",
    "                                                        math.exp(current_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'generative_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(dataloader):\n",
    "\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    processed_data_size = 0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(dataloader):\n",
    "\n",
    "        batch_idx += 1\n",
    "\n",
    "        # mask the last bar of the input data \n",
    "        batch_size = data.size(0)\n",
    "        data_masked = torch.cat((data[:, :BAR_LENGTH*3], torch.ones([batch_size, BAR_LENGTH], dtype=torch.long)), dim = 1)\n",
    "\n",
    "        # reset model gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # make the prediction\n",
    "        output = model(data_masked)\n",
    "\n",
    "        # flatten the output sequence\n",
    "        final_target = targets.contiguous().view(-1)\n",
    "        final_output = output.contiguous().view(-1, OUTPUT_VOCAB_SIZE)\n",
    "\n",
    "        loss = criterion(final_output, final_target)\n",
    "\n",
    "        # Note that we don't add TAR loss here\n",
    "        total_loss += (data.size(1)) * loss.data\n",
    "        processed_data_size += data.size(1) - eff_history\n",
    "\n",
    "    return total_loss[0] / processed_data_size\n",
    "\n",
    "\n",
    "train_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_vloss = 1e8\n",
    "\n",
    "if not train_model:\n",
    "    with open(\"model.pt\", 'rb') as f:\n",
    "        model = torch.load(f)\n",
    "\n",
    "    next_in = None\n",
    "    model.eval()\n",
    "\n",
    "else:\n",
    "    all_vloss = []\n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        if args.train:\n",
    "            train()\n",
    "            val_loss = evaluate(val_data)\n",
    "            test_loss = evaluate(test_data)\n",
    "        \n",
    "\n",
    "            print('-' * 89)\n",
    "            print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "                    'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                            val_loss, math.exp(val_loss)))\n",
    "            print('| end of epoch {:3d} | time: {:5.2f}s | test loss {:5.2f} | '\n",
    "                'test ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                            test_loss, math.exp(test_loss)))\n",
    "            print('-' * 89)\n",
    "\n",
    "            # Save the model if the validation loss is the best we've seen so far.\n",
    "            if val_loss < best_vloss:\n",
    "                with open(\"model.pt\", 'wb') as f:\n",
    "                    print('Save model!\\n')\n",
    "                    torch.save(model, f)\n",
    "                best_vloss = val_loss\n",
    "\n",
    "            # Anneal the learning rate if the validation loss plateaus\n",
    "            if epoch > 5 and val_loss >= max(all_vloss[-5:]):\n",
    "                lr = lr / 2.\n",
    "                if lr < 0.1:\n",
    "                    print(\"bump lr\")\n",
    "                    lr = 2\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr\n",
    "            all_vloss.append(val_loss)\n",
    "\n",
    "\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(\"model.pt\", 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "# Run on test data.\n",
    "test_loss = evaluate(test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
