{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from TCN.word_cnn.model import TCN\n",
    "from MIDI.pretty_midi_tokenization import midi_to_tokens\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',504)\n",
    "pd.set_option('display.width',1000)\n",
    "\n",
    "\n",
    "DIRECTORY_PATH = '..'\n",
    "DATASET_PATH = os.path.join(DIRECTORY_PATH, 'dataset')\n",
    "CHECKPOINTS_PATH = os.path.join(DIRECTORY_PATH, 'training_checkpoints')\n",
    "RESULTS_PATH = os.path.join(DIRECTORY_PATH, 'results')\n",
    "\n",
    "import pretty_midi\n",
    "print pm.get_tempo_changes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input files: 1\n",
      "Number of output files: 1\n",
      "\n",
      "\n",
      "1: drum_excited.MID -> bass_example.MID\n",
      "\n",
      "Number of input bars: 24\n",
      "Number of input sequences: 20\n",
      "Input sequence length: 192\n",
      "Input vocabulars size: 13\n",
      "\n",
      "Number of output bars: 11\n",
      "Number of output sequences: 7\n",
      "Output sequence length: 192\n",
      "Output vocabulars size: 30\n",
      "\n",
      "Number of sequences after truncation: 7, 7\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Assumptions:\n",
    "Sequences described as input_#.mid and output_#.mid in the corresponding folders\n",
    "'''\n",
    "\n",
    "input_filenames = glob.glob(os.path.join(DATASET_PATH, 'input/*.MID'))\n",
    "print('Number of input files:', len(input_filenames))\n",
    "\n",
    "output_filenames = glob.glob(os.path.join(DATASET_PATH, 'output/*.MID'))\n",
    "print('Number of output files:', len(output_filenames))\n",
    "\n",
    "for i, (in_file, out_file) in enumerate(zip(input_filenames, output_filenames)):\n",
    "\n",
    "    in_file_name = os.path.basename(in_file)\n",
    "    out_file_name = os.path.basename(out_file)\n",
    "    print(f'\\n\\n{i + 1}: {in_file_name} -> {out_file_name}')\n",
    "    \n",
    "    pm = pretty_midi.PrettyMIDI(out_file_name)\n",
    "\n",
    "    # input_sequences, INPUT_VOCAB, input_notes_df = midi_to_tokens(in_file)\n",
    "    # n_bar = len(input_notes_df['bar'].unique())\n",
    "    # print(f'\\nNumber of input bars: {n_bar}')\n",
    "    # print(f'Number of input sequences: {len(input_sequences)}')\n",
    "    # print(f'Input sequence length: {len(input_sequences[0])}')\n",
    "    # print(f'Input vocabulars size: {len(INPUT_VOCAB)}')\n",
    "\n",
    "    # output_sequences, OUTPUT_VOCAB, output_notes_df = midi_to_tokens(out_file)\n",
    "    # n_bar = len(output_notes_df['bar'].unique())\n",
    "    # print(f'\\nNumber of output bars: {n_bar}')\n",
    "    # print(f'Number of output sequences: {len(output_sequences)}')\n",
    "    # print(f'Output sequence length: {len(output_sequences[0])}')\n",
    "    # print(f'Output vocabulars size: {len(OUTPUT_VOCAB)}')\n",
    "\n",
    "    # min_length = min(len(input_sequences), len(output_sequences))\n",
    "    # input_sequences = input_sequences[:min_length]\n",
    "    # output_sequences = output_sequences[:min_length]\n",
    "    # print(f'\\nNumber of sequences after truncation: {len(input_sequences)}, {len(output_sequences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 5\n",
      "Evaluation set size: 1\n",
      "Test set size: 1\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# convert the sequences to LongTensor for PyTorch\n",
    "input_data = torch.LongTensor(input_sequences).to(device)\n",
    "output_data = torch.LongTensor(output_sequences).to(device)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = TensorDataset(input_data, output_data)\n",
    "\n",
    "# Split the dataset into training, evaluation and test sets\n",
    "train_set, eval_set, test_set = random_split(dataset, [0.6, 0.2, 0.2])\n",
    "\n",
    "# Create the dataloaders\n",
    "train_sampler = RandomSampler(train_set)          \n",
    "train_dataloader = DataLoader(train_set, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "eval_sampler = RandomSampler(eval_set)\n",
    "eval_dataloader = DataLoader(eval_set, sampler=eval_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_sampler = RandomSampler(test_set)\n",
    "test_dataloader = DataLoader(test_set, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f'Train set size: {len(train_set)}')\n",
    "print(f'Evaluation set size: {len(eval_set)}')\n",
    "print(f'Test set size: {len(test_set)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192, 192, 192, 192, 192, 192, 20]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500 # 500\n",
    "LEARNING_RATE = 4\n",
    "\n",
    "\n",
    "SEED = 1111 \n",
    "OUTPUT_VOCAB_SIZE = len(OUTPUT_VOCAB)\n",
    "EMBEDDING_SIZE = 20 # size of word embeddings -> Embedding() is used to encode input token into [192, 20] vectors (see model.py)\n",
    "LEVELS = 7\n",
    "HIDDEN_UNITS = 192\n",
    "NUM_CHANNELS = [HIDDEN_UNITS] * (LEVELS - 1) + [EMBEDDING_SIZE]\n",
    "GRADIENT_CLIP = 0.35\n",
    "LOG_INTERVAL = 1 # report interval\n",
    "\n",
    "\n",
    "# reduce the weights of the silence token since it is overrepresented in the dataset\n",
    "silence_id = OUTPUT_VOCAB.word2idx[SILENCE_TOKEN]\n",
    "LOSS_WEIGTHS = torch.ones([OUTPUT_VOCAB_SIZE], dtype=torch.float)\n",
    "LOSS_WEIGTHS[silence_id] = 0.3\n",
    "\n",
    "\n",
    "model = TCN(input_size = EMBEDDING_SIZE, \n",
    "            output_size = OUTPUT_VOCAB_SIZE, \n",
    "            num_channels = NUM_CHANNELS, \n",
    "            dropout = 0.45, \n",
    "            emb_dropout = 0.25, \n",
    "            kernel_size = 3, \n",
    "            tied_weights = False) # tie encoder and decoder weights (legare)\n",
    "\n",
    "\n",
    "# May use adaptive softmax to speed up training\n",
    "torch.manual_seed(SEED)\n",
    "criterion = nn.CrossEntropyLoss(weight = LOSS_WEIGTHS)\n",
    "optimizer = getattr(optim, 'SGD')(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    " \n",
    "def train(epoch):\n",
    "    # Turn on training mode which enables dropout.\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # iterate over the training data\n",
    "    for batch_idx, (data, targets) in enumerate(train_dataloader):\n",
    "\n",
    "        batch_idx += 1\n",
    "\n",
    "        # mask the last bar of the input data \n",
    "        batch_size = data.size(0)\n",
    "        data_masked = torch.cat((data[:, :BAR_LENGTH*3], torch.ones([batch_size, BAR_LENGTH], dtype=torch.long)), dim = 1)\n",
    "\n",
    "        # reset model gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # make the prediction\n",
    "        output = model(data_masked)\n",
    "\n",
    "        # flatten the output sequence\n",
    "        # NB: the size -1 is inferred from other dimensions\n",
    "        # NB: contiguous() is used to make sure the tensor is stored in a contiguous chunk of memory, necessary for view() to work\n",
    "        final_target = targets.contiguous().view(-1)\n",
    "        final_output = output.contiguous().view(-1, n_words)\n",
    "\n",
    "        loss = criterion(final_output, final_target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if gradient_clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data\n",
    "\n",
    "        if batch_idx % log_interval == 0 and batch_idx > 0:\n",
    "            current_loss = total_loss.item() / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.5f} | ms/batch {:5.5f} | '\n",
    "                    'loss {:5.2f} | ppl {:8.2f}'.format(epoch, \n",
    "                                                        batch_idx, \n",
    "                                                        len(train_dataloader), \n",
    "                                                        LEARNING_RATE,\n",
    "                                                        elapsed * 1000 / log_interval,\n",
    "                                                        current_loss, \n",
    "                                                        math.exp(current_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'generative_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(test_dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    processed_data_size = 0\n",
    "    for batch_idx, (data, targets) in enumerate(test_dataloader):\n",
    "\n",
    "        batch_idx += 1\n",
    "\n",
    "        # mask the last bar of the input data \n",
    "        batch_size = data.size(0)\n",
    "        data_masked = torch.cat((data[:, :BAR_LENGTH*3], torch.ones([batch_size, BAR_LENGTH], dtype=torch.long)), dim = 1)\n",
    "\n",
    "        # reset model gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # make the prediction\n",
    "        output = model(data_masked)\n",
    "\n",
    "        # flatten the output sequence\n",
    "        final_target = targets.contiguous().view(-1)\n",
    "        final_output = output.contiguous().view(-1, n_words)\n",
    "\n",
    "        loss = criterion(final_output, final_target)\n",
    "\n",
    "        # Note that we don't add TAR loss here\n",
    "        total_loss += (data.size(1) - eff_history) * loss.data\n",
    "        processed_data_size += data.size(1) - eff_history\n",
    "\n",
    "    return total_loss[0] / processed_data_size\n",
    "\n",
    "\n",
    "train_model = False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_vloss = 1e8\n",
    "\n",
    "    # At any point you can hit Ctrl + C to break out of training early.\n",
    "    try:\n",
    "        if not train_model:\n",
    "            with open(\"model.pt\", 'rb') as f:\n",
    "                model = torch.load(f)\n",
    "\n",
    "            next_in = None\n",
    "            model.eval()\n",
    "\n",
    "        else:\n",
    "            all_vloss = []\n",
    "            for epoch in range(1, args.epochs+1):\n",
    "                epoch_start_time = time.time()\n",
    "                if args.train:\n",
    "                    train()\n",
    "                    val_loss = evaluate(val_data)\n",
    "                    test_loss = evaluate(test_data)\n",
    "                \n",
    "\n",
    "                    print('-' * 89)\n",
    "                    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "                            'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                                    val_loss, math.exp(val_loss)))\n",
    "                    print('| end of epoch {:3d} | time: {:5.2f}s | test loss {:5.2f} | '\n",
    "                        'test ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                                    test_loss, math.exp(test_loss)))\n",
    "                    print('-' * 89)\n",
    "\n",
    "                    # Save the model if the validation loss is the best we've seen so far.\n",
    "                    if val_loss < best_vloss:\n",
    "                        with open(\"model.pt\", 'wb') as f:\n",
    "                            print('Save model!\\n')\n",
    "                            torch.save(model, f)\n",
    "                        best_vloss = val_loss\n",
    "\n",
    "                    # Anneal the learning rate if the validation loss plateaus\n",
    "                    if epoch > 5 and val_loss >= max(all_vloss[-5:]):\n",
    "                        lr = lr / 2.\n",
    "                        if lr < 0.1:\n",
    "                            print(\"bump lr\")\n",
    "                            lr = 2\n",
    "                        for param_group in optimizer.param_groups:\n",
    "                            param_group['lr'] = lr\n",
    "                    all_vloss.append(val_loss)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('-' * 89)\n",
    "        print('Exiting from training early')\n",
    "\n",
    "    # Load the best saved model.\n",
    "    with open(\"model.pt\", 'rb') as f:\n",
    "        model = torch.load(f)\n",
    "    # Run on test data.\n",
    "    test_loss = evaluate(test_data)\n",
    "    print('=' * 89)\n",
    "    print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "        test_loss, math.exp(test_loss)))\n",
    "    print('=' * 89)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
