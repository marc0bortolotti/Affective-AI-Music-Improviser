{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, random_split\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from word_cnn.model import TCN\n",
    "from MIDI.PRETTY_MIDI.pretty_midi_tokenization import PrettyMidiTokenizer, BCI_TOKENS\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',504)\n",
    "pd.set_option('display.width',1000)\n",
    "\n",
    "\n",
    "DIRECTORY_PATH = ''\n",
    "\n",
    "\n",
    "EPOCHS = 500 # 500\n",
    "LEARNING_RATE = 2 # 4\n",
    "BATCH_SIZE = 4 # 16\n",
    "TRAIN_MODEL = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input files: 1\n",
      "Number of output files: 1\n",
      "\n",
      "\n",
      "1: drum.MID -> bass.MID\n",
      "Number of input sequences: 92\n",
      "Input sequence length: 192\n",
      "Input vocabulars size: 136\n",
      "\n",
      "Number of output sequences: 92\n",
      "Output sequence length: 192\n",
      "Output vocabulars size: 39\n",
      "\n",
      "Input vocab: {'O': 0, '42fS_36fS': 1, '42f_36f': 2, '42fS': 3, '42f': 4, '42fS_38fS': 5, '42f_38f': 6, '38f': 7, '36f': 8, '42pS': 9, '42p': 10, '42p_38fS': 11, '42p_38f_42fS': 12, '42p_38f_42f': 13, '42p_36fS': 14, '42p_36f_42fS': 15, '42p_36f_42f': 16, '42f_36fS': 17, '42fS_36fS_42fS': 18, '42f_36f_42f': 19, '42f_38fS': 20, '42f_38f_42fS': 21, '42f_38f_42f': 22, '42pS_36fS_42fS': 23, '42pS_36fS': 24, '42p_36f': 25, '42p_36f_42fS_38fS': 26, '42p_36f_42f_38f': 27, '38fS': 28, '38f_42fS_36fS': 29, '38f_42f_36f': 30, '42f_36f_42fS_38fS': 31, '42f_36f_42f_38f': 32, '42p_36f_38fS': 33, '42p_36f_38f_42fS': 34, '42p_36f_38f_42f': 35, '38pS': 36, '38p': 37, '38p_42fS_36fS': 38, '38p_42f_36f': 39, '36fS_42fS': 40, '36f_42f': 41, '42f_36f_42fS': 42, '38f_36fS': 43, '38fS_36fS_42fS': 44, '38fS_42fS_36fS': 45, '38f_36f_42f': 46, '42f_36f_38fS': 47, '42f_36f_38f_42fS': 48, '42f_36f_38f_42f': 49, '36fS': 50, '36f_42fS': 51, '36f_42f_38fS': 52, '36f_42f_38f_42fS': 53, '36f_42f_38f_42f': 54, '38fS_36fS': 55, '38f_36f_42fS': 56, '38pS_42fS_36fS': 57, '38f_36fS_42fS': 58, '42f_36f_42f_38fS': 59, '36f_42pS': 60, '36f_42p': 61, '38p_36fS_42fS': 62, '38pS_36fS_42fS': 63, '38p_36f_42f': 64, '36f_38f': 65, '42fS_36fS_38fS': 66, '42f_36f_38f': 67, '42fS_38fS_36fS': 68, '42f_38f_36f': 69, '38f_36f': 70, '42f_36fS_38fS': 71, '36f_38fS': 72, '36f_38f_42fS': 73, '38f_42f': 74, '42fS_44fS_36fS': 75, '42f_44f_36f': 76, '38f_42fS': 77, '36f_36fS': 78, '36f_36f_42fS': 79, '36f_44fS': 80, '44f_38fS': 81, '44f_38f': 82, '46fS_36fS': 83, '46f_36f': 84, '36fS_44fS': 85, '44fS_42fS': 86, '44f_42f': 87, '38fS_42fS': 88, '42f_36f_42pS': 89, '38f_46fS_36fS': 90, '44fS_36fS': 91, '44f_36f': 92, '46fS': 93, '46f': 94, '46fS_42fS_44fS_36fS': 95, '36f_46fS': 96, '36f_46f': 97, '36f_46f_36fS_44fS': 98, '38f_42pS': 99, '36f_42fS_36fS': 100, '38f_36fS_46fS': 101, '46f_44fS_36fS_42fS': 102, '44fS_36fS_42fS': 103, '44f_36f_42f': 104, '44fS': 105, '36f_42fS_38fS': 106, '46f_44fS': 107, '44fS_42fS_36fS': 108, '44f_42f_36f': 109, '38f_46f_36f': 110, '36fS_44pS': 111, '44p_42fS': 112, '44p_42f': 113, '42f_44f_36f_42fS': 114, '38f_46fS': 115, '38f_46f': 116, '46f_36fS_42fS': 117, '46f_44pS': 118, '44pS_42fS_36fS': 119, '44p_42f_36f': 120, '36f_38pS': 121, '36f_38p': 122, '36f_38fS_42fS': 123, '42f_36f_38pS': 124, '42f_36f_38p': 125, '48fS': 126, '48f': 127, '38f_42f_36fS': 128, '38pS_42fS': 129, '38p_42f': 130, '36f_38pS_42fS': 131, '38p_36fS': 132, '38p_36f': 133, '36f_38f_42f': 134, 'C': 135}\n",
      "Output vocab: {'O': 0, '42fS_36fS': 1, '42f_36f': 2, '42fS': 3, '42f': 4, '42fS_38fS': 5, '42f_38f': 6, '38f': 7, '36f': 8, '42pS': 9, '42p': 10, '42p_38fS': 11, '42p_38f_42fS': 12, '42p_38f_42f': 13, '42p_36fS': 14, '42p_36f_42fS': 15, '42p_36f_42f': 16, '42f_36fS': 17, '42fS_36fS_42fS': 18, '42f_36f_42f': 19, '42f_38fS': 20, '42f_38f_42fS': 21, '42f_38f_42f': 22, '42pS_36fS_42fS': 23, '42pS_36fS': 24, '42p_36f': 25, '42p_36f_42fS_38fS': 26, '42p_36f_42f_38f': 27, '38fS': 28, '38f_42fS_36fS': 29, '38f_42f_36f': 30, '42f_36f_42fS_38fS': 31, '42f_36f_42f_38f': 32, '42p_36f_38fS': 33, '42p_36f_38f_42fS': 34, '42p_36f_38f_42f': 35, '38pS': 36, '38p': 37, '38p_42fS_36fS': 38, '38p_42f_36f': 39, '36fS_42fS': 40, '36f_42f': 41, '42f_36f_42fS': 42, '38f_36fS': 43, '38fS_36fS_42fS': 44, '38fS_42fS_36fS': 45, '38f_36f_42f': 46, '42f_36f_38fS': 47, '42f_36f_38f_42fS': 48, '42f_36f_38f_42f': 49, '36fS': 50, '36f_42fS': 51, '36f_42f_38fS': 52, '36f_42f_38f_42fS': 53, '36f_42f_38f_42f': 54, '38fS_36fS': 55, '38f_36f_42fS': 56, '38pS_42fS_36fS': 57, '38f_36fS_42fS': 58, '42f_36f_42f_38fS': 59, '36f_42pS': 60, '36f_42p': 61, '38p_36fS_42fS': 62, '38pS_36fS_42fS': 63, '38p_36f_42f': 64, '36f_38f': 65, '42fS_36fS_38fS': 66, '42f_36f_38f': 67, '42fS_38fS_36fS': 68, '42f_38f_36f': 69, '38f_36f': 70, '42f_36fS_38fS': 71, '36f_38fS': 72, '36f_38f_42fS': 73, '38f_42f': 74, '42fS_44fS_36fS': 75, '42f_44f_36f': 76, '38f_42fS': 77, '36f_36fS': 78, '36f_36f_42fS': 79, '36f_44fS': 80, '44f_38fS': 81, '44f_38f': 82, '46fS_36fS': 83, '46f_36f': 84, '36fS_44fS': 85, '44fS_42fS': 86, '44f_42f': 87, '38fS_42fS': 88, '42f_36f_42pS': 89, '38f_46fS_36fS': 90, '44fS_36fS': 91, '44f_36f': 92, '46fS': 93, '46f': 94, '46fS_42fS_44fS_36fS': 95, '36f_46fS': 96, '36f_46f': 97, '36f_46f_36fS_44fS': 98, '38f_42pS': 99, '36f_42fS_36fS': 100, '38f_36fS_46fS': 101, '46f_44fS_36fS_42fS': 102, '44fS_36fS_42fS': 103, '44f_36f_42f': 104, '44fS': 105, '36f_42fS_38fS': 106, '46f_44fS': 107, '44fS_42fS_36fS': 108, '44f_42f_36f': 109, '38f_46f_36f': 110, '36fS_44pS': 111, '44p_42fS': 112, '44p_42f': 113, '42f_44f_36f_42fS': 114, '38f_46fS': 115, '38f_46f': 116, '46f_36fS_42fS': 117, '46f_44pS': 118, '44pS_42fS_36fS': 119, '44p_42f_36f': 120, '36f_38pS': 121, '36f_38p': 122, '36f_38fS_42fS': 123, '42f_36f_38pS': 124, '42f_36f_38p': 125, '48fS': 126, '48f': 127, '38f_42f_36fS': 128, '38pS_42fS': 129, '38p_42f': 130, '36f_38pS_42fS': 131, '38p_36fS': 132, '38p_36f': 133, '36f_38f_42f': 134, 'C': 135}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Assumptions:\n",
    "Sequences described as input_#.mid and output_#.mid in the corresponding folders\n",
    "'''\n",
    "DATASET_PATH = os.path.join(DIRECTORY_PATH, 'dataset')\n",
    "\n",
    "input_filenames = glob.glob(os.path.join(DATASET_PATH, 'input/*.MID'))\n",
    "print('Number of input files:', len(input_filenames))\n",
    "\n",
    "output_filenames = glob.glob(os.path.join(DATASET_PATH, 'output/*.MID'))\n",
    "print('Number of output files:', len(output_filenames))\n",
    "\n",
    "INPUT_TOK = PrettyMidiTokenizer()\n",
    "OUTPUT_TOK = PrettyMidiTokenizer()\n",
    "\n",
    "for i, (in_file, out_file) in enumerate(zip(input_filenames, output_filenames)):\n",
    "\n",
    "    in_file_name = os.path.basename(in_file)\n",
    "    out_file_name = os.path.basename(out_file)\n",
    "    print(f'\\n\\n{i + 1}: {in_file_name} -> {out_file_name}')\n",
    "\n",
    "    if 'RELAX' in in_file_name:\n",
    "        emotion_token = BCI_TOKENS['relax']\n",
    "    else:\n",
    "        emotion_token = BCI_TOKENS['concentrate']\n",
    "\n",
    "    in_seq, in_df = INPUT_TOK.midi_to_tokens(in_file, update_vocab=True, update_sequences=True, emotion_token = emotion_token)\n",
    "    out_seq, out_df = OUTPUT_TOK.midi_to_tokens(out_file, update_vocab=True, update_sequences=True)\n",
    "\n",
    "print(f'Number of input sequences: {len(INPUT_TOK.sequences)}')\n",
    "print(f'Input sequence length: {len(INPUT_TOK.sequences[0])}')\n",
    "print(f'Input vocabulars size: {len(INPUT_TOK.VOCAB)}')\n",
    "print(f'\\nNumber of output sequences: {len(OUTPUT_TOK.sequences)}')\n",
    "print(f'Output sequence length: {len(OUTPUT_TOK.sequences[0])}')\n",
    "print(f'Output vocabulars size: {len(OUTPUT_TOK.VOCAB)}')\n",
    "\n",
    "print('\\nInput vocab:', INPUT_TOK.VOCAB.word2idx)\n",
    "print('Output vocab:', OUTPUT_TOK.VOCAB.word2idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 56\n",
      "Evaluation set size: 18\n",
      "Test set size: 18\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = TensorDataset(torch.LongTensor(INPUT_TOK.sequences).to(device),\n",
    "                        torch.LongTensor(OUTPUT_TOK.sequences).to(device))\n",
    "\n",
    "# Split the dataset into training, evaluation and test sets\n",
    "train_set, eval_set, test_set = random_split(dataset, [0.6, 0.2, 0.2])\n",
    "\n",
    "# Create the dataloaders\n",
    "train_sampler = RandomSampler(train_set)          \n",
    "train_dataloader = DataLoader(train_set, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "eval_sampler = RandomSampler(eval_set)\n",
    "eval_dataloader = DataLoader(eval_set, sampler=eval_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_sampler = RandomSampler(test_set)\n",
    "test_dataloader = DataLoader(test_set, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f'Train set size: {len(train_set)}')\n",
    "print(f'Evaluation set size: {len(eval_set)}')\n",
    "print(f'Test set size: {len(test_set)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model created: TCN(\n",
      "  (encoder): Embedding(136, 20)\n",
      "  (tcn): TemporalConvNet(\n",
      "    (network): Sequential(\n",
      "      (0): TemporalBlock(\n",
      "        (conv1): Conv1d(20, 192, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.45, inplace=False)\n",
      "        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.45, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(20, 192, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.45, inplace=False)\n",
      "          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.45, inplace=False)\n",
      "        )\n",
      "        (downsample): Conv1d(20, 192, kernel_size=(1,), stride=(1,))\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): TemporalBlock(\n",
      "        (conv1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.45, inplace=False)\n",
      "        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.45, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.45, inplace=False)\n",
      "          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.45, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (2): TemporalBlock(\n",
      "        (conv1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.45, inplace=False)\n",
      "        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.45, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.45, inplace=False)\n",
      "          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.45, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (3): TemporalBlock(\n",
      "        (conv1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.45, inplace=False)\n",
      "        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.45, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.45, inplace=False)\n",
      "          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.45, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (4): TemporalBlock(\n",
      "        (conv1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.45, inplace=False)\n",
      "        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.45, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.45, inplace=False)\n",
      "          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.45, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (5): TemporalBlock(\n",
      "        (conv1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.45, inplace=False)\n",
      "        (conv2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.45, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.45, inplace=False)\n",
      "          (4): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.45, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (6): TemporalBlock(\n",
      "        (conv1): Conv1d(192, 20, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.45, inplace=False)\n",
      "        (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.45, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(192, 20, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.45, inplace=False)\n",
      "          (4): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.45, inplace=False)\n",
      "        )\n",
      "        (downsample): Conv1d(192, 20, kernel_size=(1,), stride=(1,))\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=20, out_features=39, bias=True)\n",
      "  (drop): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set the hyperparameters\n",
    "SEED = 1111 \n",
    "INPUT_VOCAB_SIZE = len(INPUT_TOK.VOCAB)\n",
    "OUTPUT_VOCAB_SIZE = len(OUTPUT_TOK.VOCAB)\n",
    "EMBEDDING_SIZE = 20 # size of word embeddings -> Embedding() is used to encode input token into [192, 20] vectors (see model.py)\n",
    "LEVELS = 7\n",
    "HIDDEN_UNITS = 192\n",
    "NUM_CHANNELS = [HIDDEN_UNITS] * (LEVELS - 1) + [EMBEDDING_SIZE]\n",
    "GRADIENT_CLIP = 0.35\n",
    "\n",
    "\n",
    "# balance the loss function by assigning a weight to each token related to its frequency\n",
    "LOSS_WEIGTHS = torch.ones([OUTPUT_VOCAB_SIZE], dtype=torch.float)\n",
    "OUTPUT_TOK.VOCAB.compute_weights()\n",
    "for i, weigth in enumerate(OUTPUT_TOK.VOCAB.weights):\n",
    "    LOSS_WEIGTHS[i] = 1 - weigth\n",
    "    # print(f'{OUTPUT_TOK.VOCAB.idx2word[i]}: {LOSS_WEIGTHS[i]}')\n",
    "\n",
    "# create the model\n",
    "model = TCN(input_size = INPUT_VOCAB_SIZE,\n",
    "            embedding_size = EMBEDDING_SIZE, \n",
    "            output_size = OUTPUT_VOCAB_SIZE, \n",
    "            num_channels = NUM_CHANNELS, \n",
    "            dropout = 0.45, \n",
    "            emb_dropout = 0.25, \n",
    "            kernel_size = 3, \n",
    "            tied_weights = False) # tie encoder and decoder weights (legare)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# May use adaptive softmax to speed up training\n",
    "torch.manual_seed(SEED)\n",
    "criterion = nn.CrossEntropyLoss(weight = LOSS_WEIGTHS)\n",
    "optimizer = getattr(optim, 'SGD')(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f'\\nModel created: {model}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAR_LENGTH = INPUT_TOK.BAR_LENGTH\n",
    "\n",
    "def epoch_step(dataloader, mode):\n",
    "\n",
    "    if mode == 'train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval() # disable dropout\n",
    "        \n",
    "    total_loss = 0\n",
    "\n",
    "    # iterate over the training data\n",
    "    for batch_idx, (data, targets) in enumerate(dataloader):\n",
    "\n",
    "        batch_idx += 1\n",
    "\n",
    "        # mask the last bar of the input data\n",
    "        batch_size = data.size(0)\n",
    "        data_masked = torch.cat((data[:, :BAR_LENGTH*3], torch.ones([batch_size, BAR_LENGTH], dtype=torch.long)), dim = 1)\n",
    "\n",
    "        # reset model gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # make the prediction\n",
    "        output = model(data_masked)\n",
    "\n",
    "        # flatten the output sequence\n",
    "        # NB: the size -1 is inferred from other dimensions\n",
    "        # NB: contiguous() is used to make sure the tensor is stored in a contiguous chunk of memory, necessary for view() to work\n",
    "        final_target = targets.contiguous().view(-1)\n",
    "        final_output = output.contiguous().view(-1, OUTPUT_VOCAB_SIZE)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(final_output, final_target)\n",
    "\n",
    "        if mode == 'train':\n",
    "            # calculate the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # clip the gradients to avoid exploding gradients\n",
    "            if GRADIENT_CLIP > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "\n",
    "            # update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.data.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1/500 | lr 2.00000 | ms/epoch 8495.29290 | train_loss  3.18 | eval_loss  3.00\n",
      "| epoch   2/500 | lr 2.00000 | ms/epoch 11947.12710 | train_loss  2.94 | eval_loss  2.93\n",
      "| epoch   3/500 | lr 2.00000 | ms/epoch 6996.82736 | train_loss  2.94 | eval_loss  2.94\n",
      "| epoch   4/500 | lr 2.00000 | ms/epoch 7351.02630 | train_loss  2.92 | eval_loss  2.89\n",
      "| epoch   5/500 | lr 2.00000 | ms/epoch 7229.87819 | train_loss  2.91 | eval_loss  2.89\n",
      "| epoch   6/500 | lr 2.00000 | ms/epoch 6712.25381 | train_loss  2.91 | eval_loss  2.89\n",
      "| epoch   7/500 | lr 2.00000 | ms/epoch 6967.66567 | train_loss  2.90 | eval_loss  2.87\n",
      "| epoch   8/500 | lr 2.00000 | ms/epoch 7729.11024 | train_loss  2.90 | eval_loss  2.88\n",
      "| epoch   9/500 | lr 2.00000 | ms/epoch 6936.49864 | train_loss  2.91 | eval_loss  2.89\n",
      "| epoch  10/500 | lr 2.00000 | ms/epoch 6460.79016 | train_loss  2.89 | eval_loss  2.90\n",
      "| epoch  11/500 | lr 2.00000 | ms/epoch 6180.36985 | train_loss  2.90 | eval_loss  2.85\n",
      "| epoch  12/500 | lr 2.00000 | ms/epoch 8025.42281 | train_loss  2.89 | eval_loss  2.86\n",
      "| epoch  13/500 | lr 2.00000 | ms/epoch 7548.88129 | train_loss  2.86 | eval_loss  2.85\n",
      "| epoch  14/500 | lr 2.00000 | ms/epoch 6080.98793 | train_loss  2.87 | eval_loss  2.81\n",
      "| epoch  15/500 | lr 2.00000 | ms/epoch 8341.62140 | train_loss  2.86 | eval_loss  2.82\n",
      "| epoch  16/500 | lr 2.00000 | ms/epoch 7586.24387 | train_loss  2.82 | eval_loss  2.79\n",
      "| epoch  17/500 | lr 2.00000 | ms/epoch 7646.64316 | train_loss  2.82 | eval_loss  2.82\n",
      "| epoch  18/500 | lr 2.00000 | ms/epoch 6980.56269 | train_loss  2.80 | eval_loss  2.79\n",
      "| epoch  19/500 | lr 2.00000 | ms/epoch 6433.51984 | train_loss  2.82 | eval_loss  2.78\n",
      "| epoch  20/500 | lr 2.00000 | ms/epoch 7812.75105 | train_loss  2.78 | eval_loss  2.74\n",
      "| epoch  21/500 | lr 2.00000 | ms/epoch 7289.28757 | train_loss  2.76 | eval_loss  2.72\n",
      "| epoch  22/500 | lr 2.00000 | ms/epoch 6261.75427 | train_loss  2.77 | eval_loss  2.71\n",
      "| epoch  23/500 | lr 2.00000 | ms/epoch 7657.61375 | train_loss  2.76 | eval_loss  2.67\n",
      "| epoch  24/500 | lr 2.00000 | ms/epoch 8643.78262 | train_loss  2.71 | eval_loss  2.71\n",
      "| epoch  25/500 | lr 2.00000 | ms/epoch 9789.93654 | train_loss  2.70 | eval_loss  2.67\n",
      "| epoch  26/500 | lr 2.00000 | ms/epoch 10004.27294 | train_loss  2.69 | eval_loss  2.61\n",
      "| epoch  27/500 | lr 2.00000 | ms/epoch 9779.36649 | train_loss  2.66 | eval_loss  2.53\n",
      "| epoch  28/500 | lr 2.00000 | ms/epoch 7418.15805 | train_loss  2.63 | eval_loss  2.50\n",
      "| epoch  29/500 | lr 2.00000 | ms/epoch 6510.07056 | train_loss  2.60 | eval_loss  2.47\n",
      "| epoch  30/500 | lr 2.00000 | ms/epoch 6519.48547 | train_loss  2.57 | eval_loss  2.39\n",
      "| epoch  31/500 | lr 2.00000 | ms/epoch 8181.01835 | train_loss  2.53 | eval_loss  2.34\n",
      "| epoch  32/500 | lr 2.00000 | ms/epoch 6993.79396 | train_loss  2.50 | eval_loss  2.34\n",
      "| epoch  33/500 | lr 2.00000 | ms/epoch 5786.82542 | train_loss  2.50 | eval_loss  2.33\n",
      "| epoch  34/500 | lr 2.00000 | ms/epoch 6868.96133 | train_loss  2.46 | eval_loss  2.20\n",
      "| epoch  35/500 | lr 2.00000 | ms/epoch 6213.50050 | train_loss  2.45 | eval_loss  2.22\n",
      "| epoch  36/500 | lr 2.00000 | ms/epoch 3975.48676 | train_loss  2.39 | eval_loss  2.11\n",
      "| epoch  37/500 | lr 2.00000 | ms/epoch 3322.33524 | train_loss  2.33 | eval_loss  2.13\n",
      "| epoch  38/500 | lr 2.00000 | ms/epoch 3440.86003 | train_loss  2.31 | eval_loss  2.07\n",
      "| epoch  39/500 | lr 2.00000 | ms/epoch 3948.09532 | train_loss  2.27 | eval_loss  2.04\n",
      "| epoch  40/500 | lr 2.00000 | ms/epoch 5042.70434 | train_loss  2.24 | eval_loss  1.93\n",
      "| epoch  41/500 | lr 2.00000 | ms/epoch 7172.26768 | train_loss  2.21 | eval_loss  1.91\n",
      "| epoch  42/500 | lr 2.00000 | ms/epoch 8759.57489 | train_loss  2.19 | eval_loss  1.87\n",
      "| epoch  43/500 | lr 2.00000 | ms/epoch 7920.42446 | train_loss  2.15 | eval_loss  1.88\n",
      "| epoch  44/500 | lr 2.00000 | ms/epoch 6724.69926 | train_loss  2.11 | eval_loss  1.87\n",
      "| epoch  45/500 | lr 2.00000 | ms/epoch 5772.80688 | train_loss  2.09 | eval_loss  1.76\n",
      "| epoch  46/500 | lr 2.00000 | ms/epoch 7263.53478 | train_loss  2.05 | eval_loss  1.75\n",
      "| epoch  47/500 | lr 2.00000 | ms/epoch 6639.91523 | train_loss  2.06 | eval_loss  1.70\n",
      "| epoch  48/500 | lr 2.00000 | ms/epoch 9857.17964 | train_loss  2.01 | eval_loss  1.69\n",
      "| epoch  49/500 | lr 2.00000 | ms/epoch 7322.16477 | train_loss  1.98 | eval_loss  1.63\n",
      "| epoch  50/500 | lr 2.00000 | ms/epoch 6858.88648 | train_loss  1.96 | eval_loss  1.69\n",
      "| epoch  51/500 | lr 2.00000 | ms/epoch 6466.16268 | train_loss  1.96 | eval_loss  1.61\n",
      "| epoch  52/500 | lr 2.00000 | ms/epoch 6745.74685 | train_loss  1.91 | eval_loss  1.54\n",
      "| epoch  53/500 | lr 2.00000 | ms/epoch 4873.21162 | train_loss  1.89 | eval_loss  1.49\n",
      "| epoch  54/500 | lr 2.00000 | ms/epoch 4074.50199 | train_loss  1.91 | eval_loss  1.55\n",
      "| epoch  55/500 | lr 2.00000 | ms/epoch 3460.81805 | train_loss  1.85 | eval_loss  1.51\n",
      "| epoch  56/500 | lr 2.00000 | ms/epoch 3731.37498 | train_loss  1.85 | eval_loss  1.44\n",
      "| epoch  57/500 | lr 2.00000 | ms/epoch 4275.64621 | train_loss  1.82 | eval_loss  1.41\n",
      "| epoch  58/500 | lr 2.00000 | ms/epoch 6418.41817 | train_loss  1.81 | eval_loss  1.37\n",
      "| epoch  59/500 | lr 2.00000 | ms/epoch 7372.85447 | train_loss  1.76 | eval_loss  1.40\n",
      "| epoch  60/500 | lr 2.00000 | ms/epoch 6964.64419 | train_loss  1.80 | eval_loss  1.32\n",
      "| epoch  61/500 | lr 2.00000 | ms/epoch 7355.03936 | train_loss  1.75 | eval_loss  1.31\n",
      "| epoch  62/500 | lr 2.00000 | ms/epoch 8112.86521 | train_loss  1.74 | eval_loss  1.31\n",
      "| epoch  63/500 | lr 2.00000 | ms/epoch 7139.28080 | train_loss  1.72 | eval_loss  1.24\n",
      "| epoch  64/500 | lr 2.00000 | ms/epoch 6510.80084 | train_loss  1.72 | eval_loss  1.27\n",
      "| epoch  65/500 | lr 2.00000 | ms/epoch 7012.20536 | train_loss  1.70 | eval_loss  1.24\n",
      "| epoch  66/500 | lr 2.00000 | ms/epoch 5632.85518 | train_loss  1.65 | eval_loss  1.20\n",
      "| epoch  67/500 | lr 2.00000 | ms/epoch 4010.73241 | train_loss  1.63 | eval_loss  1.20\n",
      "| epoch  68/500 | lr 2.00000 | ms/epoch 3811.49650 | train_loss  1.63 | eval_loss  1.13\n",
      "| epoch  69/500 | lr 2.00000 | ms/epoch 3196.39444 | train_loss  1.62 | eval_loss  1.20\n",
      "| epoch  70/500 | lr 2.00000 | ms/epoch 3463.77063 | train_loss  1.59 | eval_loss  1.09\n",
      "| epoch  71/500 | lr 2.00000 | ms/epoch 3927.50144 | train_loss  1.58 | eval_loss  1.06\n",
      "| epoch  72/500 | lr 2.00000 | ms/epoch 4574.38612 | train_loss  1.58 | eval_loss  1.12\n",
      "| epoch  73/500 | lr 2.00000 | ms/epoch 6360.54611 | train_loss  1.55 | eval_loss  1.09\n",
      "| epoch  74/500 | lr 2.00000 | ms/epoch 7605.96538 | train_loss  1.56 | eval_loss  0.98\n",
      "| epoch  75/500 | lr 2.00000 | ms/epoch 7801.56803 | train_loss  1.54 | eval_loss  1.11\n",
      "| epoch  76/500 | lr 2.00000 | ms/epoch 7152.16160 | train_loss  1.49 | eval_loss  0.99\n",
      "| epoch  77/500 | lr 2.00000 | ms/epoch 6933.50887 | train_loss  1.50 | eval_loss  1.00\n",
      "| epoch  78/500 | lr 2.00000 | ms/epoch 6501.91641 | train_loss  1.48 | eval_loss  0.91\n",
      "| epoch  79/500 | lr 2.00000 | ms/epoch 7252.89226 | train_loss  1.46 | eval_loss  0.92\n",
      "| epoch  80/500 | lr 2.00000 | ms/epoch 6812.03628 | train_loss  1.44 | eval_loss  0.91\n",
      "| epoch  81/500 | lr 2.00000 | ms/epoch 7901.69191 | train_loss  1.47 | eval_loss  0.99\n",
      "| epoch  82/500 | lr 2.00000 | ms/epoch 7495.92543 | train_loss  1.43 | eval_loss  0.81\n",
      "| epoch  83/500 | lr 2.00000 | ms/epoch 7255.24044 | train_loss  1.42 | eval_loss  0.87\n",
      "| epoch  84/500 | lr 2.00000 | ms/epoch 6887.45666 | train_loss  1.39 | eval_loss  0.85\n",
      "| epoch  85/500 | lr 2.00000 | ms/epoch 6666.10670 | train_loss  1.39 | eval_loss  0.75\n",
      "| epoch  86/500 | lr 2.00000 | ms/epoch 7500.11206 | train_loss  1.39 | eval_loss  0.74\n",
      "| epoch  87/500 | lr 2.00000 | ms/epoch 7935.98771 | train_loss  1.38 | eval_loss  0.74\n",
      "| epoch  88/500 | lr 2.00000 | ms/epoch 6895.96128 | train_loss  1.37 | eval_loss  0.78\n",
      "| epoch  89/500 | lr 2.00000 | ms/epoch 5799.85666 | train_loss  1.33 | eval_loss  0.73\n",
      "| epoch  90/500 | lr 2.00000 | ms/epoch 3766.95561 | train_loss  1.30 | eval_loss  0.68\n",
      "| epoch  91/500 | lr 2.00000 | ms/epoch 3361.78112 | train_loss  1.38 | eval_loss  0.66\n",
      "| epoch  92/500 | lr 2.00000 | ms/epoch 3226.54915 | train_loss  1.30 | eval_loss  0.71\n",
      "| epoch  93/500 | lr 2.00000 | ms/epoch 3388.80324 | train_loss  1.28 | eval_loss  0.60\n",
      "| epoch  94/500 | lr 2.00000 | ms/epoch 3964.35499 | train_loss  1.31 | eval_loss  0.61\n",
      "| epoch  95/500 | lr 2.00000 | ms/epoch 4839.59937 | train_loss  1.28 | eval_loss  0.58\n",
      "| epoch  96/500 | lr 2.00000 | ms/epoch 6338.96708 | train_loss  1.25 | eval_loss  0.61\n",
      "| epoch  97/500 | lr 2.00000 | ms/epoch 6959.40232 | train_loss  1.22 | eval_loss  0.60\n",
      "| epoch  98/500 | lr 2.00000 | ms/epoch 7085.48665 | train_loss  1.23 | eval_loss  0.53\n",
      "| epoch  99/500 | lr 2.00000 | ms/epoch 6864.90345 | train_loss  1.23 | eval_loss  0.61\n",
      "| epoch 100/500 | lr 2.00000 | ms/epoch 7344.40827 | train_loss  1.20 | eval_loss  0.55\n",
      "| epoch 101/500 | lr 2.00000 | ms/epoch 6493.31760 | train_loss  1.22 | eval_loss  0.54\n",
      "| epoch 102/500 | lr 2.00000 | ms/epoch 6809.18360 | train_loss  1.19 | eval_loss  0.55\n",
      "| epoch 103/500 | lr 2.00000 | ms/epoch 7753.86930 | train_loss  1.18 | eval_loss  0.51\n",
      "| epoch 104/500 | lr 2.00000 | ms/epoch 7676.94592 | train_loss  1.14 | eval_loss  0.52\n",
      "| epoch 105/500 | lr 2.00000 | ms/epoch 6896.73543 | train_loss  1.14 | eval_loss  0.47\n",
      "| epoch 106/500 | lr 2.00000 | ms/epoch 7078.17864 | train_loss  1.13 | eval_loss  0.49\n",
      "| epoch 107/500 | lr 2.00000 | ms/epoch 6984.01642 | train_loss  1.12 | eval_loss  0.47\n",
      "| epoch 108/500 | lr 2.00000 | ms/epoch 6787.55045 | train_loss  1.11 | eval_loss  0.45\n",
      "| epoch 109/500 | lr 2.00000 | ms/epoch 7403.27573 | train_loss  1.15 | eval_loss  0.40\n",
      "| epoch 110/500 | lr 2.00000 | ms/epoch 7231.82487 | train_loss  1.10 | eval_loss  0.40\n",
      "| epoch 111/500 | lr 2.00000 | ms/epoch 7345.71695 | train_loss  1.11 | eval_loss  0.36\n",
      "| epoch 112/500 | lr 2.00000 | ms/epoch 6894.37699 | train_loss  1.07 | eval_loss  0.40\n",
      "| epoch 113/500 | lr 2.00000 | ms/epoch 6764.44697 | train_loss  1.11 | eval_loss  0.38\n",
      "| epoch 114/500 | lr 2.00000 | ms/epoch 6953.31597 | train_loss  1.05 | eval_loss  0.37\n",
      "| epoch 115/500 | lr 2.00000 | ms/epoch 6758.39829 | train_loss  1.07 | eval_loss  0.38\n",
      "| epoch 116/500 | lr 2.00000 | ms/epoch 6913.87534 | train_loss  1.08 | eval_loss  0.34\n",
      "| epoch 117/500 | lr 2.00000 | ms/epoch 7574.53442 | train_loss  1.04 | eval_loss  0.29\n",
      "| epoch 118/500 | lr 2.00000 | ms/epoch 4059.92866 | train_loss  1.04 | eval_loss  0.35\n",
      "| epoch 119/500 | lr 2.00000 | ms/epoch 3279.00410 | train_loss  1.06 | eval_loss  0.33\n",
      "| epoch 120/500 | lr 2.00000 | ms/epoch 3414.41751 | train_loss  1.03 | eval_loss  0.31\n",
      "| epoch 121/500 | lr 2.00000 | ms/epoch 3738.79552 | train_loss  1.01 | eval_loss  0.37\n",
      "| epoch 122/500 | lr 2.00000 | ms/epoch 4473.05393 | train_loss  1.00 | eval_loss  0.27\n",
      "| epoch 123/500 | lr 2.00000 | ms/epoch 6561.39112 | train_loss  1.05 | eval_loss  0.29\n",
      "| epoch 124/500 | lr 2.00000 | ms/epoch 6890.90610 | train_loss  1.00 | eval_loss  0.30\n",
      "| epoch 125/500 | lr 2.00000 | ms/epoch 6676.84150 | train_loss  0.99 | eval_loss  0.29\n",
      "| epoch 126/500 | lr 2.00000 | ms/epoch 6752.99692 | train_loss  0.99 | eval_loss  0.25\n",
      "| epoch 127/500 | lr 2.00000 | ms/epoch 7318.06183 | train_loss  0.97 | eval_loss  0.27\n",
      "| epoch 128/500 | lr 2.00000 | ms/epoch 6984.75385 | train_loss  0.92 | eval_loss  0.26\n",
      "| epoch 129/500 | lr 2.00000 | ms/epoch 6787.80365 | train_loss  0.98 | eval_loss  0.24\n",
      "| epoch 130/500 | lr 2.00000 | ms/epoch 7024.28269 | train_loss  0.92 | eval_loss  0.25\n",
      "| epoch 131/500 | lr 2.00000 | ms/epoch 7611.60946 | train_loss  0.91 | eval_loss  0.25\n",
      "| epoch 132/500 | lr 2.00000 | ms/epoch 6824.35608 | train_loss  0.93 | eval_loss  0.22\n",
      "| epoch 133/500 | lr 2.00000 | ms/epoch 6909.46794 | train_loss  0.94 | eval_loss  0.20\n",
      "| epoch 134/500 | lr 2.00000 | ms/epoch 6845.82329 | train_loss  0.92 | eval_loss  0.20\n",
      "| epoch 135/500 | lr 2.00000 | ms/epoch 6709.03468 | train_loss  0.92 | eval_loss  0.25\n",
      "| epoch 136/500 | lr 2.00000 | ms/epoch 7036.55887 | train_loss  0.86 | eval_loss  0.20\n",
      "| epoch 137/500 | lr 2.00000 | ms/epoch 7290.20119 | train_loss  0.90 | eval_loss  0.20\n",
      "| epoch 138/500 | lr 2.00000 | ms/epoch 6561.92327 | train_loss  0.90 | eval_loss  0.21\n",
      "| epoch 139/500 | lr 2.00000 | ms/epoch 6018.32390 | train_loss  0.86 | eval_loss  0.19\n",
      "| epoch 140/500 | lr 2.00000 | ms/epoch 6897.55249 | train_loss  0.86 | eval_loss  0.18\n",
      "| epoch 141/500 | lr 2.00000 | ms/epoch 6577.78788 | train_loss  0.86 | eval_loss  0.18\n",
      "| epoch 142/500 | lr 2.00000 | ms/epoch 4376.56260 | train_loss  0.83 | eval_loss  0.16\n",
      "| epoch 143/500 | lr 2.00000 | ms/epoch 3796.17643 | train_loss  0.84 | eval_loss  0.21\n",
      "| epoch 144/500 | lr 2.00000 | ms/epoch 4049.01266 | train_loss  0.84 | eval_loss  0.17\n",
      "| epoch 145/500 | lr 2.00000 | ms/epoch 4746.83928 | train_loss  0.85 | eval_loss  0.17\n",
      "| epoch 146/500 | lr 2.00000 | ms/epoch 6731.89712 | train_loss  0.83 | eval_loss  0.16\n",
      "| epoch 147/500 | lr 2.00000 | ms/epoch 6883.80933 | train_loss  0.85 | eval_loss  0.16\n",
      "| epoch 148/500 | lr 2.00000 | ms/epoch 6572.09229 | train_loss  0.82 | eval_loss  0.14\n",
      "| epoch 149/500 | lr 2.00000 | ms/epoch 7274.19591 | train_loss  0.83 | eval_loss  0.15\n",
      "| epoch 150/500 | lr 2.00000 | ms/epoch 6630.75161 | train_loss  0.83 | eval_loss  0.18\n",
      "| epoch 151/500 | lr 2.00000 | ms/epoch 6735.52322 | train_loss  0.81 | eval_loss  0.13\n",
      "| epoch 152/500 | lr 2.00000 | ms/epoch 7060.21833 | train_loss  0.81 | eval_loss  0.10\n",
      "| epoch 153/500 | lr 2.00000 | ms/epoch 7515.00130 | train_loss  0.80 | eval_loss  0.12\n",
      "| epoch 154/500 | lr 2.00000 | ms/epoch 7439.11433 | train_loss  0.79 | eval_loss  0.15\n",
      "| epoch 155/500 | lr 2.00000 | ms/epoch 9648.12398 | train_loss  0.79 | eval_loss  0.12\n",
      "| epoch 156/500 | lr 2.00000 | ms/epoch 8385.18357 | train_loss  0.78 | eval_loss  0.13\n",
      "| epoch 157/500 | lr 2.00000 | ms/epoch 4475.42286 | train_loss  0.80 | eval_loss  0.13\n",
      "| epoch 158/500 | lr 2.00000 | ms/epoch 4465.46388 | train_loss  0.76 | eval_loss  0.13\n",
      "| epoch 159/500 | lr 2.00000 | ms/epoch 6351.29046 | train_loss  0.75 | eval_loss  0.12\n",
      "| epoch 160/500 | lr 2.00000 | ms/epoch 8685.63032 | train_loss  0.77 | eval_loss  0.12\n",
      "| epoch 161/500 | lr 2.00000 | ms/epoch 7534.07097 | train_loss  0.76 | eval_loss  0.12\n",
      "| epoch 162/500 | lr 2.00000 | ms/epoch 7407.44710 | train_loss  0.76 | eval_loss  0.10\n",
      "| epoch 163/500 | lr 2.00000 | ms/epoch 7624.29261 | train_loss  0.74 | eval_loss  0.12\n",
      "| epoch 164/500 | lr 2.00000 | ms/epoch 8555.61662 | train_loss  0.73 | eval_loss  0.10\n",
      "| epoch 165/500 | lr 2.00000 | ms/epoch 8876.93977 | train_loss  0.75 | eval_loss  0.09\n",
      "| epoch 166/500 | lr 2.00000 | ms/epoch 8691.42461 | train_loss  0.70 | eval_loss  0.12\n",
      "| epoch 167/500 | lr 2.00000 | ms/epoch 9494.91620 | train_loss  0.74 | eval_loss  0.10\n",
      "| epoch 168/500 | lr 2.00000 | ms/epoch 7038.56826 | train_loss  0.70 | eval_loss  0.09\n",
      "| epoch 169/500 | lr 2.00000 | ms/epoch 6879.64392 | train_loss  0.68 | eval_loss  0.10\n",
      "| epoch 170/500 | lr 2.00000 | ms/epoch 6524.52087 | train_loss  0.71 | eval_loss  0.09\n",
      "| epoch 171/500 | lr 2.00000 | ms/epoch 6957.15141 | train_loss  0.68 | eval_loss  0.08\n",
      "| epoch 172/500 | lr 2.00000 | ms/epoch 6528.09787 | train_loss  0.68 | eval_loss  0.08\n",
      "| epoch 173/500 | lr 2.00000 | ms/epoch 4797.27817 | train_loss  0.70 | eval_loss  0.07\n",
      "| epoch 174/500 | lr 2.00000 | ms/epoch 4555.43780 | train_loss  0.70 | eval_loss  0.10\n",
      "| epoch 175/500 | lr 2.00000 | ms/epoch 5557.61361 | train_loss  0.68 | eval_loss  0.09\n",
      "| epoch 176/500 | lr 2.00000 | ms/epoch 7007.83706 | train_loss  0.69 | eval_loss  0.07\n",
      "| epoch 177/500 | lr 2.00000 | ms/epoch 6994.77291 | train_loss  0.66 | eval_loss  0.09\n",
      "| epoch 178/500 | lr 2.00000 | ms/epoch 6612.57768 | train_loss  0.68 | eval_loss  0.08\n",
      "| epoch 179/500 | lr 2.00000 | ms/epoch 6901.92819 | train_loss  0.65 | eval_loss  0.07\n",
      "| epoch 180/500 | lr 2.00000 | ms/epoch 6590.73210 | train_loss  0.65 | eval_loss  0.07\n",
      "| epoch 181/500 | lr 2.00000 | ms/epoch 7080.94192 | train_loss  0.64 | eval_loss  0.07\n",
      "| epoch 182/500 | lr 2.00000 | ms/epoch 7114.80498 | train_loss  0.66 | eval_loss  0.07\n",
      "| epoch 183/500 | lr 2.00000 | ms/epoch 7200.05155 | train_loss  0.63 | eval_loss  0.06\n",
      "| epoch 184/500 | lr 2.00000 | ms/epoch 7109.59959 | train_loss  0.62 | eval_loss  0.07\n",
      "| epoch 185/500 | lr 2.00000 | ms/epoch 7242.87581 | train_loss  0.67 | eval_loss  0.07\n",
      "| epoch 186/500 | lr 2.00000 | ms/epoch 7147.62521 | train_loss  0.61 | eval_loss  0.08\n",
      "| epoch 187/500 | lr 2.00000 | ms/epoch 7832.99518 | train_loss  0.59 | eval_loss  0.07\n",
      "| epoch 188/500 | lr 2.00000 | ms/epoch 8254.04239 | train_loss  0.62 | eval_loss  0.06\n",
      "| epoch 189/500 | lr 2.00000 | ms/epoch 7874.24922 | train_loss  0.63 | eval_loss  0.06\n",
      "| epoch 190/500 | lr 2.00000 | ms/epoch 6770.13469 | train_loss  0.61 | eval_loss  0.07\n",
      "| epoch 191/500 | lr 2.00000 | ms/epoch 6341.90035 | train_loss  0.62 | eval_loss  0.07\n",
      "| epoch 192/500 | lr 2.00000 | ms/epoch 6563.98845 | train_loss  0.63 | eval_loss  0.06\n",
      "| epoch 193/500 | lr 2.00000 | ms/epoch 5600.41547 | train_loss  0.59 | eval_loss  0.08\n",
      "| epoch 194/500 | lr 2.00000 | ms/epoch 4508.85153 | train_loss  0.60 | eval_loss  0.06\n",
      "| epoch 195/500 | lr 2.00000 | ms/epoch 4595.53146 | train_loss  0.62 | eval_loss  0.08\n",
      "| epoch 196/500 | lr 2.00000 | ms/epoch 5146.32797 | train_loss  0.62 | eval_loss  0.05\n",
      "| epoch 197/500 | lr 2.00000 | ms/epoch 7253.07465 | train_loss  0.56 | eval_loss  0.09\n",
      "| epoch 198/500 | lr 2.00000 | ms/epoch 8595.34788 | train_loss  0.60 | eval_loss  0.07\n",
      "| epoch 199/500 | lr 2.00000 | ms/epoch 8571.59233 | train_loss  0.59 | eval_loss  0.07\n",
      "| epoch 200/500 | lr 2.00000 | ms/epoch 7206.35033 | train_loss  0.57 | eval_loss  0.06\n",
      "| epoch 201/500 | lr 2.00000 | ms/epoch 6418.54835 | train_loss  0.56 | eval_loss  0.07\n",
      "| epoch 202/500 | lr 2.00000 | ms/epoch 6665.84206 | train_loss  0.57 | eval_loss  0.08\n",
      "| epoch 203/500 | lr 2.00000 | ms/epoch 6796.31090 | train_loss  0.57 | eval_loss  0.07\n",
      "| epoch 204/500 | lr 2.00000 | ms/epoch 7036.42535 | train_loss  0.55 | eval_loss  0.05\n",
      "| epoch 205/500 | lr 2.00000 | ms/epoch 7096.44222 | train_loss  0.55 | eval_loss  0.05\n",
      "| epoch 206/500 | lr 2.00000 | ms/epoch 7142.24124 | train_loss  0.53 | eval_loss  0.05\n",
      "| epoch 207/500 | lr 2.00000 | ms/epoch 6810.02259 | train_loss  0.52 | eval_loss  0.06\n",
      "| epoch 208/500 | lr 2.00000 | ms/epoch 6484.59625 | train_loss  0.55 | eval_loss  0.05\n",
      "| epoch 209/500 | lr 2.00000 | ms/epoch 6240.12899 | train_loss  0.56 | eval_loss  0.07\n",
      "| epoch 210/500 | lr 2.00000 | ms/epoch 6132.80725 | train_loss  0.55 | eval_loss  0.05\n",
      "| epoch 211/500 | lr 2.00000 | ms/epoch 6196.49410 | train_loss  0.53 | eval_loss  0.05\n",
      "| epoch 212/500 | lr 2.00000 | ms/epoch 6176.55516 | train_loss  0.53 | eval_loss  0.06\n",
      "| epoch 213/500 | lr 2.00000 | ms/epoch 6642.43054 | train_loss  0.52 | eval_loss  0.05\n",
      "| epoch 214/500 | lr 2.00000 | ms/epoch 6362.05649 | train_loss  0.51 | eval_loss  0.05\n",
      "| epoch 215/500 | lr 2.00000 | ms/epoch 4838.67002 | train_loss  0.52 | eval_loss  0.07\n",
      "| epoch 216/500 | lr 2.00000 | ms/epoch 3856.04358 | train_loss  0.53 | eval_loss  0.05\n",
      "| epoch 217/500 | lr 2.00000 | ms/epoch 4016.62636 | train_loss  0.53 | eval_loss  0.05\n",
      "| epoch 218/500 | lr 2.00000 | ms/epoch 4582.94606 | train_loss  0.53 | eval_loss  0.05\n",
      "| epoch 219/500 | lr 2.00000 | ms/epoch 6966.96138 | train_loss  0.50 | eval_loss  0.06\n",
      "| epoch 220/500 | lr 2.00000 | ms/epoch 7307.75666 | train_loss  0.50 | eval_loss  0.05\n",
      "| epoch 221/500 | lr 2.00000 | ms/epoch 7238.21855 | train_loss  0.52 | eval_loss  0.06\n",
      "| epoch 222/500 | lr 2.00000 | ms/epoch 6802.96779 | train_loss  0.50 | eval_loss  0.05\n",
      "| epoch 223/500 | lr 2.00000 | ms/epoch 7078.26185 | train_loss  0.48 | eval_loss  0.05\n",
      "| epoch 224/500 | lr 2.00000 | ms/epoch 6907.57084 | train_loss  0.50 | eval_loss  0.05\n",
      "| epoch 225/500 | lr 2.00000 | ms/epoch 6856.02546 | train_loss  0.49 | eval_loss  0.05\n",
      "| epoch 226/500 | lr 2.00000 | ms/epoch 6897.72034 | train_loss  0.47 | eval_loss  0.05\n",
      "| epoch 227/500 | lr 2.00000 | ms/epoch 6446.11263 | train_loss  0.51 | eval_loss  0.06\n",
      "| epoch 228/500 | lr 2.00000 | ms/epoch 6785.44903 | train_loss  0.47 | eval_loss  0.05\n",
      "| epoch 229/500 | lr 2.00000 | ms/epoch 6463.55176 | train_loss  0.47 | eval_loss  0.05\n",
      "| epoch 230/500 | lr 2.00000 | ms/epoch 6720.01529 | train_loss  0.49 | eval_loss  0.05\n",
      "| epoch 231/500 | lr 2.00000 | ms/epoch 6811.26761 | train_loss  0.48 | eval_loss  0.05\n",
      "| epoch 232/500 | lr 2.00000 | ms/epoch 7218.81986 | train_loss  0.48 | eval_loss  0.04\n",
      "| epoch 233/500 | lr 2.00000 | ms/epoch 6760.42414 | train_loss  0.48 | eval_loss  0.05\n",
      "| epoch 234/500 | lr 2.00000 | ms/epoch 6766.48188 | train_loss  0.47 | eval_loss  0.04\n",
      "| epoch 235/500 | lr 2.00000 | ms/epoch 6435.22167 | train_loss  0.46 | eval_loss  0.04\n",
      "| epoch 236/500 | lr 2.00000 | ms/epoch 7087.08262 | train_loss  0.45 | eval_loss  0.05\n",
      "| epoch 237/500 | lr 2.00000 | ms/epoch 6406.58426 | train_loss  0.46 | eval_loss  0.05\n",
      "| epoch 238/500 | lr 2.00000 | ms/epoch 6944.08393 | train_loss  0.46 | eval_loss  0.05\n",
      "| epoch 239/500 | lr 2.00000 | ms/epoch 6794.35682 | train_loss  0.49 | eval_loss  0.05\n",
      "| epoch 240/500 | lr 2.00000 | ms/epoch 6675.98295 | train_loss  0.48 | eval_loss  0.04\n",
      "| epoch 241/500 | lr 2.00000 | ms/epoch 7270.05649 | train_loss  0.46 | eval_loss  0.05\n",
      "| epoch 242/500 | lr 2.00000 | ms/epoch 6537.57858 | train_loss  0.44 | eval_loss  0.05\n",
      "| epoch 243/500 | lr 2.00000 | ms/epoch 6296.08631 | train_loss  0.46 | eval_loss  0.05\n",
      "| epoch 244/500 | lr 2.00000 | ms/epoch 6693.22920 | train_loss  0.45 | eval_loss  0.05\n",
      "| epoch 245/500 | lr 2.00000 | ms/epoch 6395.20621 | train_loss  0.44 | eval_loss  0.04\n",
      "| epoch 246/500 | lr 2.00000 | ms/epoch 6475.64459 | train_loss  0.45 | eval_loss  0.05\n",
      "| epoch 247/500 | lr 2.00000 | ms/epoch 6606.77624 | train_loss  0.44 | eval_loss  0.05\n",
      "| epoch 248/500 | lr 2.00000 | ms/epoch 6546.79775 | train_loss  0.44 | eval_loss  0.05\n",
      "| epoch 249/500 | lr 2.00000 | ms/epoch 6052.21605 | train_loss  0.44 | eval_loss  0.04\n",
      "\n",
      "\n",
      " TRAINING FINISHED:\n",
      "\n",
      "\tBest Loss:  0.04\tBest Model saved at epoch: 235\n"
     ]
    }
   ],
   "source": [
    "best_eval_loss = 1e8\n",
    "best_train_loss = 1e8\n",
    "best_model_epoch = 0\n",
    "eval_losses = []\n",
    "train_losses = []\n",
    "lr = LEARNING_RATE\n",
    "early_stop = False\n",
    "\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "\n",
    "    RESULTS_PATH = os.path.join(DIRECTORY_PATH, 'results', time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "    if not os.path.exists(RESULTS_PATH):\n",
    "        os.makedirs(RESULTS_PATH)\n",
    "        \n",
    "    MODEL_PATH = os.path.join(RESULTS_PATH, 'model_state_dict.pth')\n",
    "\n",
    "    \n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = epoch_step(train_dataloader, 'train')\n",
    "\n",
    "        eval_loss = epoch_step(eval_dataloader, 'eval')\n",
    "\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if eval_loss < best_eval_loss:\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            best_eval_loss = eval_loss\n",
    "            best_model_epoch = epoch \n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "\n",
    "        # # Anneal the learning rate if the validation loss plateaus\n",
    "        # if epoch > 5 and eval_loss >= max(eval_losses[-5:]):\n",
    "        #     lr = lr / 2.\n",
    "        #     if lr < 0.1:\n",
    "        #         lr = 2\n",
    "        #     for param_group in optimizer.param_groups:\n",
    "        #         param_group['lr'] = lr\n",
    "\n",
    "\n",
    "        eval_losses.append(eval_loss)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if epoch > 15:\n",
    "            if min(eval_losses[-15:]) > best_eval_loss:\n",
    "                break\n",
    "\n",
    "        # print the loss and the progress\n",
    "        elapsed = time.time() - start_time\n",
    "        print('| epoch {:3d}/{:3d} | lr {:02.5f} | ms/epoch {:5.5f} | train_loss {:5.2f} | eval_loss {:5.2f}' \\\n",
    "                .format(epoch, EPOCHS, lr, elapsed * 1000, train_loss, eval_loss))\n",
    "\n",
    "    print('\\n\\n TRAINING FINISHED:\\n\\n\\tBest Loss: {:5.2f}\\tBest Model saved at epoch: {:3d}' \\\n",
    "            .format(best_eval_loss, best_model_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEST LOSS: 0.08584819696843624\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "test_loss = epoch_step(test_dataloader, 'eval')\n",
    "print(f'\\n\\nTEST LOSS: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN_MODEL:\n",
    "    # plot the losses over the epochs \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.plot(eval_losses, label='eval')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(RESULTS_PATH, 'losses.png'))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # save the vocabularies\n",
    "    INPUT_TOK.VOCAB.save(os.path.join(RESULTS_PATH, 'input_vocab.txt'))\n",
    "    OUTPUT_TOK.VOCAB.save(os.path.join(RESULTS_PATH, 'output_vocab.txt'))\n",
    "\n",
    "     # save the model hyperparameters in a file txt\n",
    "    with open(os.path.join(RESULTS_PATH, 'model_hyperparameters.txt'), 'w') as f:\n",
    "\n",
    "        f.write(f'----------OPTIMIZATION PARAMETERS----------\\n')\n",
    "        f.write(f'DATE: {time.strftime(\"%Y%m%d-%H%M%S\")}\\n')\n",
    "        f.write(f'DATASET_PATH: {DATASET_PATH}\\n')\n",
    "        f.write(f'SEED: {SEED}\\n')\n",
    "        f.write(f'INPUT_SIZE: {INPUT_VOCAB_SIZE}\\n')\n",
    "        f.write(f'EMBEDDING_SIZE: {EMBEDDING_SIZE}\\n')\n",
    "        f.write(f'LEVELS: {LEVELS}\\n')\n",
    "        f.write(f'HIDDEN_UNITS: {HIDDEN_UNITS}\\n')\n",
    "        f.write(f'NUM_CHANNELS: {NUM_CHANNELS}\\n')\n",
    "        f.write(f'OUTPUT_SIZE: {OUTPUT_VOCAB_SIZE}\\n')\n",
    "        f.write(f'LOSS_WEIGTHS: {LOSS_WEIGTHS}\\n')\n",
    "        f.write(f'LEARNING_RATE: {LEARNING_RATE}\\n')\n",
    "        f.write(f'BATCH_SIZE: {BATCH_SIZE}\\n')\n",
    "        f.write(f'EPOCHS: {EPOCHS}\\n')\n",
    "        f.write(f'GRADIENT_CLIP: {GRADIENT_CLIP}\\n')\n",
    "        f.write(f'------------------------------------------\\n')\n",
    "        f.write(f'----------RESULTS----------\\n')\n",
    "        f.write(f'TRAIN_LOSSES: {train_losses}\\n')\n",
    "        f.write(f'BEST_EVAL_LOSS: {best_train_loss}\\n')\n",
    "        f.write(f'TEST_LOSS: {test_loss}\\n')\n",
    "        f.write(f'BEST_MODEL_EPOCH: {best_model_epoch}\\n')\n",
    "        f.write(f'------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 40 41 41 41 41 4 0 0 0 0 0 0 3 4 4 4 4 50 8 8 8 8 8 88 74 74 74 74 74 0\n",
      " 0 0 0 0 3 4 4 4 4 4 20 7 7 7 7 7 50 40 41 41 41 41 4 0 0 0 0 0 3 4 4 4 4\n",
      " 4 50 8 8 8 8 8 88 74 74 74 74 74 4 4 0 0 0 0 0 3 4 4 4 4 4 0 0 0 0 0 0 1\n",
      " 2 2 2 2 2 2 0 0 0 0 0 3 4 4 4 4 4 17 8 8 8 8 8 88 74 74 74 74 74 74 0 0 0\n",
      " 0 3 4 4 4 4 4 20 6 7 7 7 7 1 1 2 2 2 2 124 125 37 37 37 37 0 1 2 2 2 2 2\n",
      " 2 0 0 0 0 0 88 74 74 74 74 74 74 0 0 0 0 0 3 4 4 4 4 4 0 0 0 0 0 0]\n",
      "MIDI file saved at results\\20240628-183038\\predicted_rock_relax.mid\n",
      "['43fS', '55fS', '55f', '55f', '55f', '55f', '50f', '50f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '57fS', '52f', '55fS', '57f', '57f', '57f', '55f', '55f', '64f', '64f', '64f', '64f', '62f', 'O', '57f', '57f', '57f', '57f', '57f', '50fS', '50f', '50f', '50f', '50f', '50f', '50f', '50f', '50f', '50f', 'O', 'O', '48fS', '48f', '48f', '48f', '48f', '48f', '48f', '48f', '48f', '48f', '48f', '48f', '48f', '48f', '48f', '48f', '48f', 'O', '55fS', '55f', '55f', '55f', '55f', '55f', '62fS', '62f', '62f', '62f', '62f', '62f', 'O', '55fS', '55f', '55f', '55f', 'O', 'O', '48fS', '48f', '48f', '48f', '48f', '48f', '48f', '48f', '48f', '48f', 'O', '47fS', '47f', '47f', '47f', '47f', '47f', '47f', '47f', '47f', '47f', '47f', '47f', '47f', '47f', '47f', '47f', '47f', 'O', '54fS', '54f', '54f', '54f', '54f', 'O', '60fS', '60f', '60f', '60f', '60f', '54fS', '54f', '54f', '54f', '54f', '54f', '47fS', '47f', '47f', '47f', '47f', '47f', '47f', '47f', 'O', 'O', 'O', 'O', 'O', '52fS', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', 'O', 'O', '59fS', '59f', '59f', '59f', '59f', 'O', '67fS', '67f', '67f', '67f', '67f', '59fS', '59f', '59f', '59f', '59f', 'O', '52fS', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', '52f', 'O', 'O']\n",
      "[[0, 1, 0], [55, 5, 127], [0, 2, 0], [52, 8, 127], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 3, 0], [0, 2, 0], [64, 4, 127], [0, 1, 0], [0, 1, 0], [57, 5, 127], [50, 10, 127], [0, 2, 0], [48, 17, 127], [0, 1, 0], [55, 6, 127], [62, 6, 127], [0, 1, 0], [55, 4, 127], [0, 2, 0], [48, 10, 127], [0, 1, 0], [47, 17, 127], [0, 1, 0], [54, 5, 127], [0, 1, 0], [60, 5, 127], [54, 6, 127], [47, 8, 127], [0, 5, 0], [52, 17, 127], [0, 2, 0], [59, 5, 127], [0, 1, 0], [67, 5, 127], [59, 5, 127], [0, 1, 0], [52, 11, 127]]\n"
     ]
    }
   ],
   "source": [
    "# Load the best saved model.\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "# select a genere to be predicted\n",
    "generes = ['blues', 'rock_excited', 'rock_relax']\n",
    "\n",
    "for genere in generes:\n",
    "    # get a sample to be predicted\n",
    "    sample_path = os.path.join(DATASET_PATH, f'test/drum_{genere}.mid')\n",
    "    sample = INPUT_TOK.midi_to_tokens(sample_path, update_vocab=False) [0]\n",
    "    print(sample[0])\n",
    "    sample = torch.LongTensor(sample).to(device)\n",
    "\n",
    "    # Get the last sequence from the batch and unsqueeze it to add a batch dimension.\n",
    "    sample = sample[-1].unsqueeze(0)\n",
    "\n",
    "    # Mask the last bar of the input data.\n",
    "    sample = torch.cat((sample[:, :BAR_LENGTH*3], torch.ones([1, BAR_LENGTH], dtype=torch.long)), dim = 1)\n",
    "\n",
    "    # Make the prediction.\n",
    "    prediction = model(sample)\n",
    "    prediction = prediction.contiguous().view(-1, OUTPUT_VOCAB_SIZE)\n",
    "\n",
    "    # Get the predicted tokens.\n",
    "    predicted_tokens = torch.argmax(prediction, 1)\n",
    "\n",
    "    # Get the predicted sequence.\n",
    "    predicted_sequence = predicted_tokens.cpu().numpy().tolist()\n",
    "\n",
    "    # Convert the predicted sequence to MIDI.\n",
    "    out_file_path = os.path.join(RESULTS_PATH, f'predicted_{genere}.mid')\n",
    "    pitch_ticks_list =  OUTPUT_TOK.tokens_to_midi(predicted_sequence, out_file_path) # midi is a pretty midi object\n",
    "\n",
    "# check \n",
    "predicted_sequence_string = []\n",
    "for id in predicted_sequence:\n",
    "    predicted_sequence_string.append(OUTPUT_TOK.VOCAB.idx2word[id])\n",
    "print(predicted_sequence_string)\n",
    "print(pitch_ticks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
